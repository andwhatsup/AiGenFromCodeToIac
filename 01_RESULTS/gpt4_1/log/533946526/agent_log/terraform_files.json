{
  "files": [
    {
      "name": "provider.tf",
      "content": "terraform {\n  required_version = \">= 1.3.0\"\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 6.27.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy resources in.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for the VPC.\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"List of public subnet CIDRs.\"\n  type        = list(string)\n  default     = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n}\n\nvariable \"private_subnet_cidrs\" {\n  description = \"List of private subnet CIDRs.\"\n  type        = list(string)\n  default     = [\"10.0.101.0/24\", \"10.0.102.0/24\"]\n}\n\nvariable \"azs\" {\n  description = \"List of availability zones.\"\n  type        = list(string)\n  default     = [\"us-east-1a\", \"us-east-1b\"]\n}\n\nvariable \"cluster_name\" {\n  description = \"Name of the Kubernetes cluster.\"\n  type        = string\n  default     = \"rke-cluster\"\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type for Kubernetes nodes.\"\n  type        = string\n  default     = \"t3.large\"\n}\n\nvariable \"key_name\" {\n  description = \"Name of the EC2 Key Pair to allow SSH access.\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"desired_capacity\" {\n  description = \"Desired number of EC2 instances in the Auto Scaling Group.\"\n  type        = number\n  default     = 3\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  description = \"The ID of the VPC.\"\n  value       = aws_vpc.main.id\n}\n\noutput \"public_subnet_ids\" {\n  description = \"IDs of the public subnets.\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"private_subnet_ids\" {\n  description = \"IDs of the private subnets.\"\n  value       = aws_subnet.private[*].id\n}\n\noutput \"kubernetes_api_dns\" {\n  description = \"DNS name of the Kubernetes API load balancer.\"\n  value       = aws_lb.k8s_api.dns_name\n}\n"
    },
    {
      "name": "backend.tf",
      "content": "terraform {\n  backend \"s3\" {\n    bucket         = \"<REPLACE_WITH_YOUR_BUCKET>\"\n    key            = \"terraform/state/rke-cluster/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"<REPLACE_WITH_YOUR_DYNAMODB_TABLE>\"\n  }\n}\n"
    },
    {
      "name": "main.tf",
      "content": "resource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n  tags = {\n    Name = \"${var.cluster_name}-vpc\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"gw\" {\n  vpc_id = aws_vpc.main.id\n  tags = {\n    Name = \"${var.cluster_name}-igw\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  count                   = length(var.public_subnet_cidrs)\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = var.azs[count.index]\n  map_public_ip_on_launch = true\n  tags = {\n    Name = \"${var.cluster_name}-public-${count.index + 1}\"\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  count             = length(var.private_subnet_cidrs)\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = var.private_subnet_cidrs[count.index]\n  availability_zone = var.azs[count.index]\n  tags = {\n    Name = \"${var.cluster_name}-private-${count.index + 1}\"\n  }\n}\n\nresource \"aws_nat_gateway\" \"nat\" {\n  count         = length(var.public_subnet_cidrs)\n  allocation_id = aws_eip.nat[count.index].id\n  subnet_id     = aws_subnet.public[count.index].id\n  tags = {\n    Name = \"${var.cluster_name}-nat-${count.index + 1}\"\n  }\n  depends_on = [aws_internet_gateway.gw]\n}\n\nresource \"aws_eip\" \"nat\" {\n  count = length(var.public_subnet_cidrs)\n  vpc   = true\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n  tags = {\n    Name = \"${var.cluster_name}-public-rt\"\n  }\n}\n\nresource \"aws_route\" \"public_internet_access\" {\n  route_table_id         = aws_route_table.public.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  gateway_id             = aws_internet_gateway.gw.id\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  count          = length(var.public_subnet_cidrs)\n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_route_table\" \"private\" {\n  count  = length(var.private_subnet_cidrs)\n  vpc_id = aws_vpc.main.id\n  tags = {\n    Name = \"${var.cluster_name}-private-rt-${count.index + 1}\"\n  }\n}\n\nresource \"aws_route\" \"private_nat_gateway\" {\n  count                  = length(var.private_subnet_cidrs)\n  route_table_id         = aws_route_table.private[count.index].id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.nat[count.index % length(aws_nat_gateway.nat)].id\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  count          = length(var.private_subnet_cidrs)\n  subnet_id      = aws_subnet.private[count.index].id\n  route_table_id = aws_route_table.private[count.index].id\n}\n\nresource \"aws_security_group\" \"k8s_nodes\" {\n  name        = \"${var.cluster_name}-nodes\"\n  description = \"Security group for Kubernetes nodes\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"SSH access (restrict in production)\"\n  }\n\n  ingress {\n    from_port   = 6443\n    to_port     = 6443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"Kubernetes API access (restrict in production)\"\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${var.cluster_name}-nodes\"\n  }\n}\n\nresource \"aws_lb\" \"k8s_api\" {\n  name               = \"${var.cluster_name}-api\"\n  internal           = false\n  load_balancer_type = \"network\"\n  subnets            = aws_subnet.public[*].id\n  tags = {\n    Name = \"${var.cluster_name}-api\"\n  }\n}\n\nresource \"aws_lb_target_group\" \"k8s_api\" {\n  name     = \"${var.cluster_name}-api-tg\"\n  port     = 6443\n  protocol = \"TCP\"\n  vpc_id   = aws_vpc.main.id\n  target_type = \"instance\"\n  health_check {\n    protocol = \"TCP\"\n    port     = \"6443\"\n  }\n}\n\nresource \"aws_lb_listener\" \"k8s_api\" {\n  load_balancer_arn = aws_lb.k8s_api.arn\n  port              = 6443\n  protocol          = \"TCP\"\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.k8s_api.arn\n  }\n}\n\nresource \"aws_launch_template\" \"k8s_nodes\" {\n  name_prefix   = \"${var.cluster_name}-lt-\"\n  image_id      = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n  key_name      = var.key_name != \"\" ? var.key_name : null\n  network_interfaces {\n    associate_public_ip_address = false\n    security_groups             = [aws_security_group.k8s_nodes.id]\n  }\n  block_device_mappings {\n    device_name = \"/dev/xvda\"\n    ebs {\n      volume_size = 50\n      volume_type = \"gp3\"\n      encrypted   = true\n    }\n  }\n  tag_specifications {\n    resource_type = \"instance\"\n    tags = {\n      Name = \"${var.cluster_name}-node\"\n    }\n  }\n}\n\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n  owners      = [\"099720109477\"] # Canonical\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"]\n  }\n}\n\nresource \"aws_autoscaling_group\" \"k8s_nodes\" {\n  name                      = \"${var.cluster_name}-asg\"\n  min_size                  = var.desired_capacity\n  max_size                  = var.desired_capacity\n  desired_capacity          = var.desired_capacity\n  vpc_zone_identifier       = aws_subnet.private[*].id\n  launch_template {\n    id      = aws_launch_template.k8s_nodes.id\n    version = \"$Latest\"\n  }\n  tag {\n    key                 = \"Name\"\n    value               = \"${var.cluster_name}-node\"\n    propagate_at_launch = true\n  }\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_lb_target_group_attachment\" \"k8s_api\" {\n  count            = var.desired_capacity\n  target_group_arn = aws_lb_target_group.k8s_api.arn\n  target_id        = aws_autoscaling_group.k8s_nodes.instances[count.index].id\n  port             = 6443\n  depends_on       = [aws_autoscaling_group.k8s_nodes]\n}\n"
    },
    {
      "name": "iam.tf",
      "content": "resource \"aws_iam_role\" \"ec2_ssm\" {\n  name = \"${var.cluster_name}-ec2-ssm-role\"\n  assume_role_policy = data.aws_iam_policy_document.ec2_assume_role.json\n  tags = {\n    Name = \"${var.cluster_name}-ec2-ssm-role\"\n  }\n}\n\ndata \"aws_iam_policy_document\" \"ec2_assume_role\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ec2.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ssm\" {\n  role       = aws_iam_role.ec2_ssm.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n}\n\nresource \"aws_iam_instance_profile\" \"ec2_ssm\" {\n  name = \"${var.cluster_name}-ec2-ssm-profile\"\n  role = aws_iam_role.ec2_ssm.name\n}\n"
    }
  ]
}