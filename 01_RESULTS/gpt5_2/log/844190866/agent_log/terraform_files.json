{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = merge(\n      {\n        Project     = var.project_name\n        Environment = var.environment\n        ManagedBy   = \"terraform\"\n      },\n      var.tags\n    )\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"project_name\" {\n  description = \"Project/name prefix used for resources.\"\n  type        = string\n  default     = \"calculator-flask\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod).\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"tags\" {\n  description = \"Additional tags to apply to all resources.\"\n  type        = map(string)\n  default     = {}\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for the VPC.\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use (2 or 3 recommended).\"\n  type        = number\n  default     = 2\n  validation {\n    condition     = var.az_count >= 2 && var.az_count <= 3\n    error_message = \"az_count must be 2 or 3.\"\n  }\n}\n\nvariable \"single_nat_gateway\" {\n  description = \"Use a single NAT gateway to reduce cost (true) or one per AZ (false).\"\n  type        = bool\n  default     = true\n}\n\nvariable \"cluster_version\" {\n  description = \"EKS Kubernetes version.\"\n  type        = string\n  default     = \"1.29\"\n}\n\nvariable \"node_instance_types\" {\n  description = \"Instance types for the EKS managed node group.\"\n  type        = list(string)\n  default     = [\"t3.medium\"]\n}\n\nvariable \"node_desired_size\" {\n  description = \"Desired number of worker nodes.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_min_size\" {\n  description = \"Minimum number of worker nodes.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_max_size\" {\n  description = \"Maximum number of worker nodes.\"\n  type        = number\n  default     = 6\n}\n\nvariable \"enable_cluster_creator_admin_permissions\" {\n  description = \"Whether to grant the Terraform caller admin access to the EKS cluster via access entries.\"\n  type        = bool\n  default     = true\n}\n\nvariable \"app_image\" {\n  description = \"Container image for the Flask app.\"\n  type        = string\n  default     = \"yash5090/calculator-flask:latest\"\n}\n\nvariable \"app_replicas\" {\n  description = \"Number of replicas for the Flask deployment.\"\n  type        = number\n  default     = 6\n}\n\nvariable \"app_port\" {\n  description = \"Container and service port for the Flask app.\"\n  type        = number\n  default     = 5000\n}\n"
    },
    {
      "name": "main.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  name = \"${var.project_name}-${var.environment}\"\n  azs  = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n\n  # /20 per subnet gives room for EKS + pods; adjust if needed.\n  public_subnet_cidrs  = [for i in range(var.az_count) : cidrsubnet(var.vpc_cidr, 4, i)]\n  private_subnet_cidrs = [for i in range(var.az_count) : cidrsubnet(var.vpc_cidr, 4, i + var.az_count)]\n}\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = var.vpc_cidr\n\n  azs             = local.azs\n  public_subnets  = local.public_subnet_cidrs\n  private_subnets = local.private_subnet_cidrs\n\n  enable_nat_gateway     = true\n  single_nat_gateway     = var.single_nat_gateway\n  one_nat_gateway_per_az = !var.single_nat_gateway\n\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  # Required for EKS + AWS Load Balancer Controller / Service LB\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = \"1\"\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = \"1\"\n  }\n}\n\nmodule \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 20.0\"\n\n  cluster_name    = local.name\n  cluster_version = var.cluster_version\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  cluster_endpoint_public_access = true\n\n  enable_cluster_creator_admin_permissions = var.enable_cluster_creator_admin_permissions\n\n  cluster_addons = {\n    coredns    = {}\n    kube-proxy = {}\n    vpc-cni    = {}\n  }\n\n  eks_managed_node_groups = {\n    default = {\n      name           = \"default\"\n      instance_types = var.node_instance_types\n      min_size       = var.node_min_size\n      max_size       = var.node_max_size\n      desired_size   = var.node_desired_size\n\n      subnet_ids = module.vpc.private_subnets\n\n      # Keep defaults for simplicity; can be extended with taints/labels.\n    }\n  }\n}\n\n# --- Kubernetes manifests (rendered as YAML) ---\n# We intentionally do not apply them here because that would require the Kubernetes\n# provider and cluster auth. This repo already contains the manifests.\n#\n# After apply, configure kubectl and run:\n#   kubectl apply -f deployment.yaml\n#   kubectl apply -f service.yaml\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  description = \"VPC ID\"\n  value       = module.vpc.vpc_id\n}\n\noutput \"private_subnet_ids\" {\n  description = \"Private subnet IDs\"\n  value       = module.vpc.private_subnets\n}\n\noutput \"public_subnet_ids\" {\n  description = \"Public subnet IDs\"\n  value       = module.vpc.public_subnets\n}\n\noutput \"eks_cluster_name\" {\n  description = \"EKS cluster name\"\n  value       = module.eks.cluster_name\n}\n\noutput \"eks_cluster_endpoint\" {\n  description = \"EKS cluster API endpoint\"\n  value       = module.eks.cluster_endpoint\n}\n\noutput \"eks_cluster_certificate_authority_data\" {\n  description = \"Base64 encoded certificate data required to communicate with the cluster\"\n  value       = module.eks.cluster_certificate_authority_data\n  sensitive   = true\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region  = \"us-east-1\"\nproject_name = \"calculator-flask\"\nenvironment  = \"dev\"\n\n# Cost-optimized defaults\nsingle_nat_gateway = true\n\n# App settings (used for documentation/consistency)\napp_image    = \"yash5090/calculator-flask:latest\"\napp_replicas = 6\napp_port     = 5000\n"
    },
    {
      "name": "README.md",
      "content": "# Terraform (EKS) for calculator-flask\n\nThis Terraform creates the AWS infrastructure required to run the existing Kubernetes manifests in this repo:\n- `deployment.yaml` (replicas=6, image `yash5090/calculator-flask:latest`)\n- `service.yaml` (Service type `LoadBalancer`, port 5000)\n\n## What it provisions\n- VPC (public + private subnets across 2 AZs, NAT)\n- EKS cluster\n- EKS managed node group\n- Core EKS add-ons (vpc-cni, coredns, kube-proxy)\n\n## Apply\n```bash\ncd ai_tf\nterraform init\nterraform apply\n```\n\n## Configure kubectl\n```bash\naws eks update-kubeconfig --region <region> --name <cluster_name>\n```\n\n## Deploy the app\n```bash\nkubectl apply -f ../deployment.yaml\nkubectl apply -f ../service.yaml\n```\n\n## Notes\n- Your `service.yaml` uses annotations for an ALB, but a Service of type `LoadBalancer` typically provisions an NLB/CLB. For ALB, the recommended approach is to use an Ingress with the AWS Load Balancer Controller.\n- This Terraform intentionally keeps things minimal and does not install the AWS Load Balancer Controller.\n"
    }
  ]
}