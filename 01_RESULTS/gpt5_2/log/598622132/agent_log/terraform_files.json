{
  "files": [
    {
      "name": "provider.tf",
      "content": "terraform {\n  required_version = \">= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"name\" {\n  description = \"Name prefix for resources\"\n  type        = string\n  default     = \"phantosio-minecraft\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR for the VPC\"\n  type        = string\n  default     = \"10.20.0.0/16\"\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"Two public subnet CIDRs (in two AZs)\"\n  type        = list(string)\n  default     = [\"10.20.0.0/24\", \"10.20.1.0/24\"]\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t3a.medium\"\n}\n\nvariable \"ssh_key_name\" {\n  description = \"Optional EC2 key pair name for SSH. Leave null to use SSM only.\"\n  type        = string\n  default     = null\n}\n\nvariable \"admin_cidr_allowlist\" {\n  description = \"CIDR blocks allowed to access admin UI (rcon web) and SSH (if enabled).\"\n  type        = list(string)\n  default     = []\n}\n\nvariable \"enable_ssh\" {\n  description = \"Whether to open inbound SSH (22). Prefer SSM and keep this false.\"\n  type        = bool\n  default     = false\n}\n\nvariable \"minecraft_port\" {\n  description = \"Public Minecraft port (proxy entrypoint)\"\n  type        = number\n  default     = 25565\n}\n\nvariable \"rcon_web_port\" {\n  description = \"RCON web admin port exposed on the instance\"\n  type        = number\n  default     = 4326\n}\n\nvariable \"data_volume_size_gb\" {\n  description = \"Size of the dedicated EBS data volume mounted at /srv/minecraft\"\n  type        = number\n  default     = 50\n}\n\nvariable \"backup_bucket_force_destroy\" {\n  description = \"Allow Terraform to destroy the S3 backup bucket even if it contains objects (useful for dev).\"\n  type        = bool\n  default     = false\n}\n\nvariable \"minecraft_motd\" {\n  description = \"Minecraft server MOTD\"\n  type        = string\n  default     = \"Vanilla Minecraft, Chill Vibes Only\"\n}\n\nvariable \"minecraft_version\" {\n  description = \"Minecraft version\"\n  type        = string\n  default     = \"1.19.2\"\n}\n\nvariable \"minecraft_memory\" {\n  description = \"Memory for the Paper server container\"\n  type        = string\n  default     = \"2G\"\n}\n\nvariable \"rcon_password\" {\n  description = \"RCON password for the Minecraft server\"\n  type        = string\n  sensitive   = true\n}\n\nvariable \"rcon_web_username\" {\n  description = \"RCON web admin username\"\n  type        = string\n  default     = \"admin\"\n}\n\nvariable \"rcon_web_password\" {\n  description = \"RCON web admin password\"\n  type        = string\n  sensitive   = true\n}\n"
    },
    {
      "name": "locals.tf",
      "content": "locals {\n  tags = {\n    Project = var.name\n    Managed = \"terraform\"\n  }\n\n  # Where persistent data lives on the EC2 instance\n  base_dir = \"/srv/minecraft\"\n}\n"
    },
    {
      "name": "network.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nresource \"aws_vpc\" \"this\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = merge(local.tags, { Name = \"${var.name}-vpc\" })\n}\n\nresource \"aws_internet_gateway\" \"this\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(local.tags, { Name = \"${var.name}-igw\" })\n}\n\nresource \"aws_subnet\" \"public\" {\n  count                   = 2\n  vpc_id                  = aws_vpc.this.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = data.aws_availability_zones.available.names[count.index]\n  map_public_ip_on_launch = true\n\n  tags = merge(local.tags, { Name = \"${var.name}-public-${count.index + 1}\" })\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(local.tags, { Name = \"${var.name}-public-rt\" })\n}\n\nresource \"aws_route\" \"public_internet\" {\n  route_table_id         = aws_route_table.public.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  gateway_id             = aws_internet_gateway.this.id\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  count          = 2\n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public.id\n}\n"
    },
    {
      "name": "security.tf",
      "content": "resource \"aws_security_group\" \"ec2\" {\n  name        = \"${var.name}-ec2\"\n  description = \"Security group for Minecraft EC2 host\"\n  vpc_id      = aws_vpc.this.id\n\n  # Players connect to the proxy on 25565\n  ingress {\n    description = \"Minecraft (proxy)\"\n    from_port   = var.minecraft_port\n    to_port     = var.minecraft_port\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  # Admin UI (itzg/rcon) - restrict by allowlist\n  dynamic \"ingress\" {\n    for_each = length(var.admin_cidr_allowlist) > 0 ? [1] : []\n    content {\n      description = \"RCON web admin\"\n      from_port   = var.rcon_web_port\n      to_port     = var.rcon_web_port\n      protocol    = \"tcp\"\n      cidr_blocks = var.admin_cidr_allowlist\n    }\n  }\n\n  # Optional SSH (prefer SSM)\n  dynamic \"ingress\" {\n    for_each = var.enable_ssh && length(var.admin_cidr_allowlist) > 0 ? [1] : []\n    content {\n      description = \"SSH\"\n      from_port   = 22\n      to_port     = 22\n      protocol    = \"tcp\"\n      cidr_blocks = var.admin_cidr_allowlist\n    }\n  }\n\n  egress {\n    description = \"All outbound\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = merge(local.tags, { Name = \"${var.name}-ec2\" })\n}\n"
    },
    {
      "name": "iam.tf",
      "content": "data \"aws_iam_policy_document\" \"ec2_assume\" {\n  statement {\n    effect = \"Allow\"\n    actions = [\n      \"sts:AssumeRole\",\n    ]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ec2.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"ec2\" {\n  name               = \"${var.name}-ec2-role\"\n  assume_role_policy = data.aws_iam_policy_document.ec2_assume.json\n\n  tags = local.tags\n}\n\n# SSM core (Session Manager, inventory, etc.)\nresource \"aws_iam_role_policy_attachment\" \"ssm\" {\n  role       = aws_iam_role.ec2.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n}\n\n# CloudWatch agent (optional but useful)\nresource \"aws_iam_role_policy_attachment\" \"cw_agent\" {\n  role       = aws_iam_role.ec2.name\n  policy_arn = \"arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy\"\n}\n\ndata \"aws_iam_policy_document\" \"s3_backup\" {\n  statement {\n    sid    = \"ListBucket\"\n    effect = \"Allow\"\n    actions = [\n      \"s3:ListBucket\",\n      \"s3:GetBucketLocation\"\n    ]\n    resources = [aws_s3_bucket.backups.arn]\n  }\n\n  statement {\n    sid    = \"ObjectRW\"\n    effect = \"Allow\"\n    actions = [\n      \"s3:PutObject\",\n      \"s3:AbortMultipartUpload\",\n      \"s3:ListMultipartUploadParts\",\n      \"s3:ListBucketMultipartUploads\",\n      \"s3:GetObject\",\n      \"s3:DeleteObject\"\n    ]\n    resources = [\"${aws_s3_bucket.backups.arn}/*\"]\n  }\n}\n\nresource \"aws_iam_policy\" \"s3_backup\" {\n  name   = \"${var.name}-s3-backup\"\n  policy = data.aws_iam_policy_document.s3_backup.json\n\n  tags = local.tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"s3_backup\" {\n  role       = aws_iam_role.ec2.name\n  policy_arn = aws_iam_policy.s3_backup.arn\n}\n\nresource \"aws_iam_instance_profile\" \"ec2\" {\n  name = \"${var.name}-ec2-profile\"\n  role = aws_iam_role.ec2.name\n\n  tags = local.tags\n}\n"
    },
    {
      "name": "s3.tf",
      "content": "resource \"aws_s3_bucket\" \"backups\" {\n  bucket_prefix = \"${var.name}-backups-\"\n  force_destroy = var.backup_bucket_force_destroy\n\n  tags = merge(local.tags, { Name = \"${var.name}-backups\" })\n}\n\nresource \"aws_s3_bucket_versioning\" \"backups\" {\n  bucket = aws_s3_bucket.backups.id\n\n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"backups\" {\n  bucket = aws_s3_bucket.backups.id\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm = \"AES256\"\n    }\n  }\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"backups\" {\n  bucket = aws_s3_bucket.backups.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource \"aws_s3_bucket_lifecycle_configuration\" \"backups\" {\n  bucket = aws_s3_bucket.backups.id\n\n  rule {\n    id     = \"transition-to-glacier\"\n    status = \"Enabled\"\n\n    filter {}\n\n    transition {\n      days          = 30\n      storage_class = \"GLACIER\"\n    }\n\n    expiration {\n      days = 365\n    }\n\n    noncurrent_version_expiration {\n      noncurrent_days = 30\n    }\n  }\n}\n"
    },
    {
      "name": "compute.tf",
      "content": "data \"aws_ami\" \"al2023\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"al2023-ami-*-x86_64\"]\n  }\n\n  filter {\n    name   = \"architecture\"\n    values = [\"x86_64\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\nresource \"aws_eip\" \"this\" {\n  domain = \"vpc\"\n\n  tags = merge(local.tags, { Name = \"${var.name}-eip\" })\n}\n\nresource \"aws_instance\" \"this\" {\n  ami                    = data.aws_ami.al2023.id\n  instance_type          = var.instance_type\n  subnet_id              = aws_subnet.public[0].id\n  vpc_security_group_ids = [aws_security_group.ec2.id]\n  iam_instance_profile   = aws_iam_instance_profile.ec2.name\n\n  key_name = var.ssh_key_name\n\n  metadata_options {\n    http_endpoint               = \"enabled\"\n    http_tokens                 = \"required\"\n    http_put_response_hop_limit = 2\n  }\n\n  root_block_device {\n    encrypted   = true\n    volume_type = \"gp3\"\n    volume_size = 20\n  }\n\n  user_data = templatefile(\"${path.module}/user_data.sh.tftpl\", {\n    base_dir          = local.base_dir\n    bucket_name       = aws_s3_bucket.backups.bucket\n    minecraft_motd    = var.minecraft_motd\n    minecraft_version = var.minecraft_version\n    minecraft_memory  = var.minecraft_memory\n    rcon_password     = var.rcon_password\n    rwa_username      = var.rcon_web_username\n    rwa_password      = var.rcon_web_password\n  })\n\n  tags = merge(local.tags, { Name = \"${var.name}-ec2\" })\n}\n\nresource \"aws_eip_association\" \"this\" {\n  instance_id   = aws_instance.this.id\n  allocation_id = aws_eip.this.id\n}\n\nresource \"aws_ebs_volume\" \"data\" {\n  availability_zone = aws_instance.this.availability_zone\n  size              = var.data_volume_size_gb\n  type              = \"gp3\"\n  encrypted         = true\n\n  tags = merge(local.tags, { Name = \"${var.name}-data\" })\n}\n\nresource \"aws_volume_attachment\" \"data\" {\n  device_name = \"/dev/xvdf\"\n  volume_id   = aws_ebs_volume.data.id\n  instance_id = aws_instance.this.id\n}\n"
    },
    {
      "name": "user_data.sh.tftpl",
      "content": "#!/bin/bash\nset -euo pipefail\n\nBASE_DIR=\"${base_dir}\"\nDEVICE=\"/dev/xvdf\"\nMOUNT_POINT=\"$BASE_DIR\"\n\n# Install packages\n# Amazon Linux 2023 uses dnf\n\ndnf -y update\n\ndnf -y install docker jq amazon-ssm-agent\nsystemctl enable --now amazon-ssm-agent\nsystemctl enable --now docker\n\n# Install docker compose plugin\nmkdir -p /usr/local/lib/docker/cli-plugins\ncurl -sSL -o /usr/local/lib/docker/cli-plugins/docker-compose \\\n  https://github.com/docker/compose/releases/latest/download/docker-compose-linux-x86_64\nchmod +x /usr/local/lib/docker/cli-plugins/docker-compose\n\n# Prepare and mount EBS data volume\nmkdir -p \"$MOUNT_POINT\"\n\nif ! blkid \"$DEVICE\"; then\n  mkfs -t xfs \"$DEVICE\"\nfi\n\n# Use UUID in fstab\nUUID=$(blkid -s UUID -o value \"$DEVICE\")\nif ! grep -q \"$UUID\" /etc/fstab; then\n  echo \"UUID=$UUID  $MOUNT_POINT  xfs  defaults,nofail  0  2\" >> /etc/fstab\nfi\n\nmount -a\n\n# Create directories for bind mounts\nmkdir -p \\\n  \"$BASE_DIR/data/lobby\" \\\n  \"$BASE_DIR/plugins/lobby\" \\\n  \"$BASE_DIR/data/proxy\" \\\n  \"$BASE_DIR/plugins/proxy\" \\\n  \"$BASE_DIR/data/rcon\" \\\n  \"$BASE_DIR/mc-backups\"\n\n# Write docker-compose.yml\ncat > \"$BASE_DIR/docker-compose.yml\" <<'YAML'\nversion: '3.8'\n\nservices:\n  lobby:\n    image: itzg/minecraft-server\n    container_name: lobby\n    ports:\n      - 25575:25575\n    environment:\n      MOTD: \"${minecraft_motd}\"\n      EULA: \"TRUE\"\n      RCON_PASSWORD: \"${rcon_password}\"\n      TYPE: PAPER\n      VERSION: \"${minecraft_version}\"\n      MEMORY: \"${minecraft_memory}\"\n    restart: always\n    volumes:\n      - ${base_dir}/data/lobby:/data\n      - ${base_dir}/plugins/lobby:/plugins\n    healthcheck:\n      test: mc-health\n      start_period: 1m\n      interval: 5s\n      retries: 20\n\n  rcon:\n    image: itzg/rcon\n    container_name: rcon\n    ports:\n      - 4326:4326\n    environment:\n      RWA_USERNAME: \"${rwa_username}\"\n      RWA_PASSWORD: \"${rwa_password}\"\n      RWA_ADMIN: \"TRUE\"\n      RWA_RCON_HOST: lobby\n      RWA_RCON_PASSWORD: \"${rcon_password}\"\n    volumes:\n      - ${base_dir}/data/rcon:/opt/rcon-web-admin/db\n    depends_on:\n      - lobby\n\n  proxy:\n    image: itzg/bungeecord\n    container_name: proxy\n    ports:\n      - 25565:25565\n    environment:\n      TYPE: WATERFALL\n    volumes:\n      - ${base_dir}/plugins/proxy:/plugins\n      - ${base_dir}/data/proxy:/config\n    depends_on:\n      - lobby\n\n  lobby_backup:\n    image: itzg/mc-backup\n    container_name: lobby_backup\n    environment:\n      BACKUP_INTERVAL: \"2h\"\n      RCON_HOST: lobby\n      RCON_PASSWORD: \"${rcon_password}\"\n    volumes:\n      - ${base_dir}/data/lobby:/data:ro\n      - ${base_dir}/mc-backups:/backups\n    depends_on:\n      - lobby\nYAML\n\n# Start services\ncd \"$BASE_DIR\"\ndocker compose up -d\n\n# Install awscli for S3 sync\nif ! command -v aws >/dev/null 2>&1; then\n  dnf -y install awscli\nfi\n\n# Create a simple backup sync script and cron\ncat > /usr/local/bin/mc-backup-sync.sh <<EOF\n#!/bin/bash\nset -euo pipefail\naws s3 sync \"${base_dir}/mc-backups\" \"s3://${bucket_name}/mc-backups\" --only-show-errors\nEOF\nchmod +x /usr/local/bin/mc-backup-sync.sh\n\ncat > /etc/cron.d/mc-backup-sync <<'EOF'\n*/15 * * * * root /usr/local/bin/mc-backup-sync.sh\nEOF\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"instance_id\" {\n  value = aws_instance.this.id\n}\n\noutput \"public_ip\" {\n  value = aws_eip.this.public_ip\n}\n\noutput \"minecraft_address\" {\n  value = \"${aws_eip.this.public_ip}:${var.minecraft_port}\"\n}\n\noutput \"rcon_web_url\" {\n  value = \"http://${aws_eip.this.public_ip}:${var.rcon_web_port}\"\n}\n\noutput \"backup_bucket_name\" {\n  value = aws_s3_bucket.backups.bucket\n}\n"
    },
    {
      "name": "terraform.tfvars.example",
      "content": "aws_region = \"us-east-1\"\nname       = \"phantosio-minecraft\"\n\n# Restrict admin UI and (optional) SSH to your IP(s)\nadmin_cidr_allowlist = [\"203.0.113.10/32\"]\n\n# Prefer SSM; keep SSH closed unless you need it\nenable_ssh   = false\nssh_key_name = null\n\n# Secrets\nrcon_password      = \"CHANGE_ME\"\nrcon_web_password  = \"CHANGE_ME\"\n"
    },
    {
      "name": "README_TERRAFORM.md",
      "content": "# Terraform (AWS) - Phantosio Minecraft\n\nThis Terraform deploys a **single EC2 host** running Docker + Docker Compose to run:\n- `itzg/minecraft-server` (Paper) as `lobby`\n- `itzg/bungeecord` (Waterfall) as `proxy` (public entrypoint on TCP 25565)\n- `itzg/rcon` as `rcon` (admin UI on TCP 4326)\n- `itzg/mc-backup` as `lobby_backup` (writes backups to disk)\n\nIt also provisions an **S3 bucket** and a cron job on the instance to sync `/srv/minecraft/mc-backups` to S3.\n\n## Usage\n\n1. Copy tfvars:\n\n```bash\ncp terraform.tfvars.example terraform.tfvars\n```\n\n2. Edit `terraform.tfvars` and set:\n- `admin_cidr_allowlist` to your IP(s)\n- `rcon_password` and `rcon_web_password`\n\n3. Run:\n\n```bash\nterraform init\nterraform validate\nterraform plan\nterraform apply\n```\n\n## Notes\n- RCON port 25575 is **not opened** to the internet by default.\n- SSH is disabled by default; use **SSM Session Manager**.\n- The admin UI is plain HTTP on port 4326; for production, put it behind TLS (ALB/ACM or on-instance reverse proxy).\n"
    }
  ]
}