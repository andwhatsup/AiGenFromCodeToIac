{
  "aws_architecture_description": "## Proposed high-level AWS architecture (Python ETL -> S3)\n\n### 1) Execution model (recommended)\nRun the Python ETL as a **scheduled, serverless batch job**:\n- Package the ETL code (Python 3.9 + `awswrangler==3.4.2`) into a container image.\n- Execute it on **AWS Batch on Fargate** (no EC2 management) on a schedule via **Amazon EventBridge**.\n- The job writes outputs to an **S3 “landing” bucket** (optionally partitioned by date/source) using `awswrangler`.\n\nWhy this fits your repo:\n- Your code is a standalone ETL script (not a web service) and only needs AWS access to write to S3.\n- Batch/Fargate provides repeatable runs, retries, logs, and avoids long-lived servers.\n\n### 2) Networking\n- Create a **VPC** with **private subnets** for the Batch/Fargate tasks.\n- Add **VPC endpoints** so the job can reach AWS services without public internet:\n  - **S3 Gateway Endpoint** for S3 access.\n  - **ECR (api + dkr) interface endpoints** to pull the container image.\n  - **CloudWatch Logs interface endpoint** to push logs.\n- If the ETL must call external/public APIs, add a **NAT Gateway** (or run in public subnets with tight egress controls; NAT is usually preferred for private compute).\n\n### 3) Data storage in S3\n- One S3 bucket (or two, if you want separation):\n  - **Landing bucket** for raw ingested data.\n  - Optional **curated bucket/prefix** for cleaned/processed outputs.\n- Enable:\n  - **SSE-KMS** encryption.\n  - **Versioning**.\n  - **Block Public Access**.\n  - Lifecycle rules (e.g., transition older objects to Glacier).\n\n### 4) Identity, secrets, and least privilege\n- The Batch job runs with an **IAM task/job role** granting only what it needs:\n  - `s3:PutObject`, `s3:AbortMultipartUpload`, `s3:ListBucket` on the target bucket/prefix.\n  - `kms:Encrypt/Decrypt` for the KMS key used by S3.\n  - `logs:CreateLogStream/PutLogEvents` for CloudWatch Logs.\n- If the ETL needs API keys/DB creds, store them in **AWS Secrets Manager** (or SSM Parameter Store) and grant read access only to the job role.\n\n### 5) CI/CD and IaC\n- Keep GitHub Actions for linting.\n- Add a deployment workflow:\n  - Build and push the container image to **Amazon ECR**.\n  - Apply Terraform to provision/update AWS resources.\n- Use an **IAM role for GitHub OIDC** (no long-lived AWS access keys in GitHub) to:\n  - Push to ECR.\n  - Run Terraform plan/apply (scoped permissions).\n\n### 6) Observability and operations\n- Send application logs to **CloudWatch Logs**.\n- Create **CloudWatch Alarms** on job failures (and optionally duration).\n- Notify via **SNS** (email/Slack integration via HTTPS endpoint) on failures.\n- Use **CloudTrail** for audit of API activity.\n\n### 7) Security posture\n- Private subnets + endpoints reduce exposure.\n- KMS encryption for S3 and secrets.\n- Least-privilege IAM roles.\n- S3 bucket policy restricting access to the job role (and optionally to your AWS Organization/account).\n\n---\n\n## Notes / alternatives (if you prefer simpler)\n- **EventBridge + Lambda**: only if the ETL is short-running and fits Lambda limits; `awswrangler` workloads can exceed Lambda constraints depending on data size.\n- **ECS Scheduled Task (Fargate)**: similar to Batch; good if you don’t need Batch features like job queues/array jobs.\n- **EC2 + cron**: simplest but least managed; not recommended unless you need persistent host-level dependencies.\n",
  "aws_resources": [
    "VPC",
    "Public subnets (for NAT Gateway, if needed)",
    "Private subnets (for Batch/Fargate tasks)",
    "Route tables (public/private)",
    "Internet Gateway (if NAT or public subnets are used)",
    "NAT Gateway + Elastic IP (only if ETL needs outbound internet)",
    "Security groups (for Batch/Fargate tasks and VPC endpoints)",
    "VPC Gateway Endpoint: Amazon S3",
    "VPC Interface Endpoints: Amazon ECR (api)",
    "VPC Interface Endpoints: Amazon ECR (dkr)",
    "VPC Interface Endpoints: Amazon CloudWatch Logs",
    "Amazon ECR repository (container image for ETL)",
    "AWS Batch Compute Environment (Fargate)",
    "AWS Batch Job Queue",
    "AWS Batch Job Definition",
    "Amazon EventBridge rule (schedule/cron)",
    "EventBridge target (Batch job submission)",
    "Amazon S3 bucket (landing/data lake)",
    "S3 bucket policy (restrict access)",
    "S3 bucket versioning configuration",
    "S3 lifecycle rules (optional)",
    "AWS KMS key (for S3 SSE-KMS and optionally secrets)",
    "KMS key policy",
    "IAM role for AWS Batch job execution/task role (least privilege to S3/KMS/Logs/Secrets)",
    "IAM role for GitHub Actions via OIDC (deploy role)",
    "IAM OIDC identity provider for GitHub (if not already configured)",
    "AWS Secrets Manager secret(s) (optional, for API keys/credentials)",
    "CloudWatch Log Group (for ETL job logs)",
    "CloudWatch Alarms (job failure, optional duration)",
    "Amazon SNS topic + subscription(s) (alerting)",
    "AWS CloudTrail (account-level audit trail)"
  ]
}