{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~> 2.25\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~> 2.12\"\n    }\n    tls = {\n      source  = \"hashicorp/tls\"\n      version = \"~> 4.0\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Project     = var.project_name\n      Environment = var.environment\n      ManagedBy   = \"terraform\"\n    }\n  }\n}\n\n# These are configured after the EKS cluster exists.\nprovider \"kubernetes\" {\n  host                   = data.aws_eks_cluster.this.endpoint\n  cluster_ca_certificate = base64decode(data.aws_eks_cluster.this.certificate_authority[0].data)\n  token                  = data.aws_eks_cluster_auth.this.token\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = data.aws_eks_cluster.this.endpoint\n    cluster_ca_certificate = base64decode(data.aws_eks_cluster.this.certificate_authority[0].data)\n    token                  = data.aws_eks_cluster_auth.this.token\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region\"\n  type        = string\n  default     = \"ap-south-1\"\n}\n\nvariable \"project_name\" {\n  description = \"Project name used for naming/tagging\"\n  type        = string\n  default     = \"devops-challenge\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod)\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"VPC CIDR\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use\"\n  type        = number\n  default     = 2\n}\n\nvariable \"cluster_name\" {\n  description = \"EKS cluster name\"\n  type        = string\n  default     = \"devops-challenge\"\n}\n\nvariable \"kubernetes_version\" {\n  description = \"EKS Kubernetes version\"\n  type        = string\n  default     = \"1.29\"\n}\n\nvariable \"node_instance_types\" {\n  description = \"Instance types for the managed node group\"\n  type        = list(string)\n  default     = [\"t3.large\"]\n}\n\nvariable \"node_desired_size\" {\n  description = \"Desired node count\"\n  type        = number\n  default     = 3\n}\n\nvariable \"node_min_size\" {\n  description = \"Minimum node count\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_max_size\" {\n  description = \"Maximum node count\"\n  type        = number\n  default     = 6\n}\n\nvariable \"energi_namespace\" {\n  description = \"Kubernetes namespace for Energi\"\n  type        = string\n  default     = \"energi\"\n}\n\nvariable \"energi_image\" {\n  description = \"Energi node container image\"\n  type        = string\n  default     = \"awskanojia/devops-challenge:latest\"\n}\n\nvariable \"energi_replicas\" {\n  description = \"Number of Energi node replicas\"\n  type        = number\n  default     = 3\n}\n\nvariable \"pvc_size\" {\n  description = \"PVC size for each Energi replica\"\n  type        = string\n  default     = \"1Gi\"\n}\n\nvariable \"rpc_port\" {\n  description = \"Energi RPC port\"\n  type        = number\n  default     = 39797\n}\n\nvariable \"p2p_port\" {\n  description = \"Energi P2P port\"\n  type        = number\n  default     = 39798\n}\n\nvariable \"rpc_allowed_cidrs\" {\n  description = \"CIDR blocks allowed to access the RPC NLB (if enabled). Keep restrictive.\"\n  type        = list(string)\n  default     = [\"10.0.0.0/8\"]\n}\n\nvariable \"enable_public_p2p\" {\n  description = \"Whether to expose P2P port via an internet-facing NLB\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_internal_rpc\" {\n  description = \"Whether to expose RPC port via an internal NLB\"\n  type        = bool\n  default     = true\n}\n\nvariable \"dockerconfigjson\" {\n  description = \"Optional Docker Hub pull secret in .dockerconfigjson format (base64 NOT required). If empty, no imagePullSecret is created.\"\n  type        = string\n  sensitive   = true\n  default     = \"\"\n}\n"
    },
    {
      "name": "locals.tf",
      "content": "locals {\n  name_prefix = \"${var.project_name}-${var.environment}\"\n\n  tags = {\n    Project     = var.project_name\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n  }\n}\n"
    },
    {
      "name": "network.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n}\n\nresource \"aws_vpc\" \"this\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-vpc\"\n  })\n}\n\nresource \"aws_internet_gateway\" \"this\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-igw\"\n  })\n}\n\nresource \"aws_subnet\" \"public\" {\n  for_each = { for idx, az in local.azs : az => idx }\n\n  vpc_id                  = aws_vpc.this.id\n  availability_zone       = each.key\n  cidr_block              = cidrsubnet(var.vpc_cidr, 8, each.value)\n  map_public_ip_on_launch = true\n\n  tags = merge(local.tags, {\n    Name                     = \"${local.name_prefix}-public-${each.key}\"\n    \"kubernetes.io/role/elb\" = \"1\"\n  })\n}\n\nresource \"aws_subnet\" \"private\" {\n  for_each = { for idx, az in local.azs : az => idx }\n\n  vpc_id            = aws_vpc.this.id\n  availability_zone = each.key\n  cidr_block        = cidrsubnet(var.vpc_cidr, 8, each.value + 10)\n\n  tags = merge(local.tags, {\n    Name                              = \"${local.name_prefix}-private-${each.key}\"\n    \"kubernetes.io/role/internal-elb\" = \"1\"\n  })\n}\n\nresource \"aws_eip\" \"nat\" {\n  for_each = aws_subnet.public\n\n  domain = \"vpc\"\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-nat-eip-${each.key}\"\n  })\n}\n\nresource \"aws_nat_gateway\" \"this\" {\n  for_each = aws_subnet.public\n\n  allocation_id = aws_eip.nat[each.key].id\n  subnet_id     = each.value.id\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-nat-${each.key}\"\n  })\n\n  depends_on = [aws_internet_gateway.this]\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-public-rt\"\n  })\n}\n\nresource \"aws_route\" \"public_internet\" {\n  route_table_id         = aws_route_table.public.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  gateway_id             = aws_internet_gateway.this.id\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  for_each = aws_subnet.public\n\n  subnet_id      = each.value.id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_route_table\" \"private\" {\n  for_each = aws_subnet.private\n\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-private-rt-${each.key}\"\n  })\n}\n\nresource \"aws_route\" \"private_nat\" {\n  for_each = aws_route_table.private\n\n  route_table_id         = each.value.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.this[each.key].id\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  for_each = aws_subnet.private\n\n  subnet_id      = each.value.id\n  route_table_id = aws_route_table.private[each.key].id\n}\n\n# S3 gateway endpoint (reduces NAT usage for S3)\nresource \"aws_vpc_endpoint\" \"s3\" {\n  vpc_id            = aws_vpc.this.id\n  service_name      = \"com.amazonaws.${var.aws_region}.s3\"\n  vpc_endpoint_type = \"Gateway\"\n\n  route_table_ids = concat(\n    [aws_route_table.public.id],\n    [for rt in aws_route_table.private : rt.id]\n  )\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-s3-endpoint\"\n  })\n}\n"
    },
    {
      "name": "eks.tf",
      "content": "resource \"aws_security_group\" \"eks_cluster\" {\n  name        = \"${local.name_prefix}-eks-cluster-sg\"\n  description = \"EKS cluster security group\"\n  vpc_id      = aws_vpc.this.id\n\n  tags = merge(local.tags, { Name = \"${local.name_prefix}-eks-cluster-sg\" })\n}\n\nresource \"aws_security_group\" \"eks_nodes\" {\n  name        = \"${local.name_prefix}-eks-nodes-sg\"\n  description = \"EKS node security group\"\n  vpc_id      = aws_vpc.this.id\n\n  tags = merge(local.tags, { Name = \"${local.name_prefix}-eks-nodes-sg\" })\n}\n\n# Allow nodes to communicate with each other (required for Kubernetes networking)\nresource \"aws_security_group_rule\" \"nodes_all_self\" {\n  type              = \"ingress\"\n  security_group_id = aws_security_group.eks_nodes.id\n  from_port         = 0\n  to_port           = 0\n  protocol          = \"-1\"\n  self              = true\n  description       = \"Node to node all traffic\"\n}\n\n# Allow cluster to talk to nodes\nresource \"aws_security_group_rule\" \"nodes_from_cluster\" {\n  type                     = \"ingress\"\n  security_group_id        = aws_security_group.eks_nodes.id\n  from_port                = 0\n  to_port                  = 0\n  protocol                 = \"-1\"\n  source_security_group_id = aws_security_group.eks_cluster.id\n  description              = \"Cluster to node all traffic\"\n}\n\n# Allow nodes to talk to cluster\nresource \"aws_security_group_rule\" \"cluster_from_nodes\" {\n  type                     = \"ingress\"\n  security_group_id        = aws_security_group.eks_cluster.id\n  from_port                = 0\n  to_port                  = 0\n  protocol                 = \"-1\"\n  source_security_group_id = aws_security_group.eks_nodes.id\n  description              = \"Node to cluster all traffic\"\n}\n\n# Egress for nodes\nresource \"aws_security_group_rule\" \"nodes_egress_all\" {\n  type              = \"egress\"\n  security_group_id = aws_security_group.eks_nodes.id\n  from_port         = 0\n  to_port           = 0\n  protocol          = \"-1\"\n  cidr_blocks       = [\"0.0.0.0/0\"]\n  description       = \"Allow all egress\"\n}\n\n# Egress for cluster\nresource \"aws_security_group_rule\" \"cluster_egress_all\" {\n  type              = \"egress\"\n  security_group_id = aws_security_group.eks_cluster.id\n  from_port         = 0\n  to_port           = 0\n  protocol          = \"-1\"\n  cidr_blocks       = [\"0.0.0.0/0\"]\n  description       = \"Allow all egress\"\n}\n\nresource \"aws_iam_role\" \"eks_cluster\" {\n  name = \"${local.name_prefix}-eks-cluster-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"eks.amazonaws.com\"\n        }\n        Action = \"sts:AssumeRole\"\n      }\n    ]\n  })\n\n  tags = local.tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"eks_cluster_AmazonEKSClusterPolicy\" {\n  role       = aws_iam_role.eks_cluster.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"eks_cluster_AmazonEKSServicePolicy\" {\n  role       = aws_iam_role.eks_cluster.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSServicePolicy\"\n}\n\nresource \"aws_eks_cluster\" \"this\" {\n  name     = var.cluster_name\n  role_arn = aws_iam_role.eks_cluster.arn\n  version  = var.kubernetes_version\n\n  vpc_config {\n    subnet_ids              = concat([for s in aws_subnet.private : s.id], [for s in aws_subnet.public : s.id])\n    security_group_ids      = [aws_security_group.eks_cluster.id]\n    endpoint_private_access = true\n    endpoint_public_access  = true\n  }\n\n  enabled_cluster_log_types = [\"api\", \"audit\", \"authenticator\", \"controllerManager\", \"scheduler\"]\n\n  tags = merge(local.tags, {\n    Name = var.cluster_name\n  })\n\n  depends_on = [\n    aws_iam_role_policy_attachment.eks_cluster_AmazonEKSClusterPolicy,\n    aws_iam_role_policy_attachment.eks_cluster_AmazonEKSServicePolicy\n  ]\n}\n\nresource \"aws_iam_role\" \"eks_node\" {\n  name = \"${local.name_prefix}-eks-node-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"ec2.amazonaws.com\"\n        }\n        Action = \"sts:AssumeRole\"\n      }\n    ]\n  })\n\n  tags = local.tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"node_AmazonEKSWorkerNodePolicy\" {\n  role       = aws_iam_role.eks_node.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"node_AmazonEKS_CNI_Policy\" {\n  role       = aws_iam_role.eks_node.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"node_AmazonEC2ContainerRegistryReadOnly\" {\n  role       = aws_iam_role.eks_node.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\"\n}\n\nresource \"aws_eks_node_group\" \"default\" {\n  cluster_name    = aws_eks_cluster.this.name\n  node_group_name = \"${local.name_prefix}-ng\"\n  node_role_arn   = aws_iam_role.eks_node.arn\n  subnet_ids      = [for s in aws_subnet.private : s.id]\n\n  instance_types = var.node_instance_types\n\n  scaling_config {\n    desired_size = var.node_desired_size\n    min_size     = var.node_min_size\n    max_size     = var.node_max_size\n  }\n\n  update_config {\n    max_unavailable = 1\n  }\n\n  # Use the custom node SG\n  remote_access {\n    ec2_ssh_key               = null\n    source_security_group_ids = []\n  }\n\n  tags = merge(local.tags, {\n    Name = \"${local.name_prefix}-ng\"\n  })\n\n  depends_on = [\n    aws_iam_role_policy_attachment.node_AmazonEKSWorkerNodePolicy,\n    aws_iam_role_policy_attachment.node_AmazonEKS_CNI_Policy,\n    aws_iam_role_policy_attachment.node_AmazonEC2ContainerRegistryReadOnly\n  ]\n}\n\n# Data sources for Kubernetes/Helm providers\ndata \"aws_eks_cluster\" \"this\" {\n  name = aws_eks_cluster.this.name\n}\n\ndata \"aws_eks_cluster_auth\" \"this\" {\n  name = aws_eks_cluster.this.name\n}\n"
    },
    {
      "name": "irsa.tf",
      "content": "# OIDC provider for IRSA\nresource \"aws_iam_openid_connect_provider\" \"eks\" {\n  url = aws_eks_cluster.this.identity[0].oidc[0].issuer\n\n  client_id_list = [\"sts.amazonaws.com\"]\n\n  thumbprint_list = [\n    data.tls_certificate.oidc.certificates[0].sha1_fingerprint\n  ]\n\n  tags = local.tags\n}\n\ndata \"tls_certificate\" \"oidc\" {\n  url = aws_eks_cluster.this.identity[0].oidc[0].issuer\n}\n\nlocals {\n  oidc_provider_arn = aws_iam_openid_connect_provider.eks.arn\n  oidc_provider_url = replace(aws_eks_cluster.this.identity[0].oidc[0].issuer, \"https://\", \"\")\n}\n"
    },
    {
      "name": "addons.tf",
      "content": "# Core EKS add-ons\nresource \"aws_eks_addon\" \"vpc_cni\" {\n  cluster_name = aws_eks_cluster.this.name\n  addon_name   = \"vpc-cni\"\n\n  depends_on = [aws_eks_node_group.default]\n}\n\nresource \"aws_eks_addon\" \"coredns\" {\n  cluster_name = aws_eks_cluster.this.name\n  addon_name   = \"coredns\"\n\n  depends_on = [aws_eks_node_group.default]\n}\n\nresource \"aws_eks_addon\" \"kube_proxy\" {\n  cluster_name = aws_eks_cluster.this.name\n  addon_name   = \"kube-proxy\"\n\n  depends_on = [aws_eks_node_group.default]\n}\n\n# EBS CSI driver add-on (for StatefulSet PVCs)\nresource \"aws_iam_role\" \"ebs_csi\" {\n  name = \"${local.name_prefix}-ebs-csi-irsa\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          Federated = local.oidc_provider_arn\n        }\n        Action = \"sts:AssumeRoleWithWebIdentity\"\n        Condition = {\n          StringEquals = {\n            \"${local.oidc_provider_url}:sub\" = \"system:serviceaccount:kube-system:ebs-csi-controller-sa\"\n            \"${local.oidc_provider_url}:aud\" = \"sts.amazonaws.com\"\n          }\n        }\n      }\n    ]\n  })\n\n  tags = local.tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ebs_csi_policy\" {\n  role       = aws_iam_role.ebs_csi.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy\"\n}\n\nresource \"aws_eks_addon\" \"ebs_csi\" {\n  cluster_name             = aws_eks_cluster.this.name\n  addon_name               = \"aws-ebs-csi-driver\"\n  service_account_role_arn = aws_iam_role.ebs_csi.arn\n\n  depends_on = [\n    aws_iam_role_policy_attachment.ebs_csi_policy,\n    aws_eks_node_group.default\n  ]\n}\n"
    },
    {
      "name": "k8s-workload.tf",
      "content": "resource \"kubernetes_namespace\" \"energi\" {\n  metadata {\n    name = var.energi_namespace\n\n    labels = {\n      \"app.kubernetes.io/name\" = \"energi\"\n    }\n  }\n\n  depends_on = [aws_eks_node_group.default]\n}\n\n# Optional Docker Hub pull secret (only if dockerconfigjson is provided)\nresource \"kubernetes_secret\" \"dockersecret\" {\n  count = length(trimspace(var.dockerconfigjson)) > 0 ? 1 : 0\n\n  metadata {\n    name      = \"dockersecret\"\n    namespace = kubernetes_namespace.energi.metadata[0].name\n  }\n\n  type = \"kubernetes.io/dockerconfigjson\"\n\n  data = {\n    \".dockerconfigjson\" = var.dockerconfigjson\n  }\n}\n\n# Headless service for StatefulSet stable DNS\nresource \"kubernetes_service\" \"energi_headless\" {\n  metadata {\n    name      = \"energi-node\"\n    namespace = kubernetes_namespace.energi.metadata[0].name\n\n    labels = {\n      app = \"energi-node\"\n    }\n  }\n\n  spec {\n    cluster_ip = \"None\"\n\n    selector = {\n      app = \"energi-node\"\n    }\n\n    port {\n      name        = \"rpc\"\n      port        = var.rpc_port\n      target_port = var.rpc_port\n      protocol    = \"TCP\"\n    }\n\n    port {\n      name        = \"p2p\"\n      port        = var.p2p_port\n      target_port = var.p2p_port\n      protocol    = \"TCP\"\n    }\n  }\n}\n\n# StorageClass for encrypted gp3 EBS volumes\nresource \"kubernetes_storage_class\" \"gp3_encrypted\" {\n  metadata {\n    name = \"gp3-encrypted\"\n\n    annotations = {\n      \"storageclass.kubernetes.io/is-default-class\" = \"true\"\n    }\n  }\n\n  storage_provisioner = \"ebs.csi.aws.com\"\n  reclaim_policy      = \"Delete\"\n  volume_binding_mode = \"WaitForFirstConsumer\"\n\n  parameters = {\n    type      = \"gp3\"\n    encrypted = \"true\"\n    fsType    = \"ext4\"\n  }\n\n  depends_on = [aws_eks_addon.ebs_csi]\n}\n\nresource \"kubernetes_stateful_set\" \"energi\" {\n  metadata {\n    name      = \"energi-node\"\n    namespace = kubernetes_namespace.energi.metadata[0].name\n\n    labels = {\n      app = \"energi-node\"\n    }\n  }\n\n  spec {\n    replicas     = var.energi_replicas\n    service_name = kubernetes_service.energi_headless.metadata[0].name\n\n    selector {\n      match_labels = {\n        app = \"energi-node\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"energi-node\"\n        }\n      }\n\n      spec {\n        dynamic \"image_pull_secrets\" {\n          for_each = length(trimspace(var.dockerconfigjson)) > 0 ? [1] : []\n          content {\n            name = kubernetes_secret.dockersecret[0].metadata[0].name\n          }\n        }\n\n        container {\n          name  = \"energi-node\"\n          image = var.energi_image\n\n          port {\n            name           = \"rpc\"\n            container_port = var.rpc_port\n          }\n\n          port {\n            name           = \"p2p\"\n            container_port = var.p2p_port\n          }\n\n          resources {\n            requests = {\n              cpu    = \"500m\"\n              memory = \"512Mi\"\n            }\n            limits = {\n              cpu    = \"1\"\n              memory = \"1Gi\"\n            }\n          }\n\n          volume_mount {\n            name       = \"data\"\n            mount_path = \"/opt\"\n          }\n        }\n      }\n    }\n\n    volume_claim_template {\n      metadata {\n        name = \"data\"\n      }\n\n      spec {\n        access_modes       = [\"ReadWriteOnce\"]\n        storage_class_name = kubernetes_storage_class.gp3_encrypted.metadata[0].name\n\n        resources {\n          requests = {\n            storage = var.pvc_size\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [\n    kubernetes_storage_class.gp3_encrypted,\n    kubernetes_service.energi_headless\n  ]\n}\n\n# Expose P2P via NLB (internet-facing by default)\nresource \"kubernetes_service\" \"energi_p2p_lb\" {\n  count = var.enable_public_p2p ? 1 : 0\n\n  metadata {\n    name      = \"energi-p2p\"\n    namespace = kubernetes_namespace.energi.metadata[0].name\n\n    annotations = {\n      \"service.beta.kubernetes.io/aws-load-balancer-type\" = \"nlb\"\n      \"service.beta.kubernetes.io/aws-load-balancer-scheme\" = \"internet-facing\"\n      \"service.beta.kubernetes.io/aws-load-balancer-nlb-target-type\" = \"ip\"\n    }\n\n    labels = {\n      app = \"energi-node\"\n    }\n  }\n\n  spec {\n    type = \"LoadBalancer\"\n\n    selector = {\n      app = \"energi-node\"\n    }\n\n    port {\n      name        = \"p2p\"\n      port        = var.p2p_port\n      target_port = var.p2p_port\n      protocol    = \"TCP\"\n    }\n  }\n\n  depends_on = [kubernetes_stateful_set.energi]\n}\n\n# Expose RPC via internal NLB (recommended)\nresource \"kubernetes_service\" \"energi_rpc_lb\" {\n  count = var.enable_internal_rpc ? 1 : 0\n\n  metadata {\n    name      = \"energi-rpc\"\n    namespace = kubernetes_namespace.energi.metadata[0].name\n\n    annotations = {\n      \"service.beta.kubernetes.io/aws-load-balancer-type\" = \"nlb\"\n      \"service.beta.kubernetes.io/aws-load-balancer-scheme\" = \"internal\"\n      \"service.beta.kubernetes.io/aws-load-balancer-nlb-target-type\" = \"ip\"\n      # Restrict who can reach the internal NLB\n      \"service.beta.kubernetes.io/load-balancer-source-ranges\" = join(\",\", var.rpc_allowed_cidrs)\n    }\n\n    labels = {\n      app = \"energi-node\"\n    }\n  }\n\n  spec {\n    type = \"LoadBalancer\"\n\n    selector = {\n      app = \"energi-node\"\n    }\n\n    port {\n      name        = \"rpc\"\n      port        = var.rpc_port\n      target_port = var.rpc_port\n      protocol    = \"TCP\"\n    }\n  }\n\n  depends_on = [kubernetes_stateful_set.energi]\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  value       = aws_vpc.this.id\n  description = \"VPC ID\"\n}\n\noutput \"eks_cluster_name\" {\n  value       = aws_eks_cluster.this.name\n  description = \"EKS cluster name\"\n}\n\noutput \"eks_cluster_endpoint\" {\n  value       = aws_eks_cluster.this.endpoint\n  description = \"EKS cluster endpoint\"\n}\n\noutput \"energi_namespace\" {\n  value       = kubernetes_namespace.energi.metadata[0].name\n  description = \"Namespace where Energi is deployed\"\n}\n\noutput \"p2p_service_hostname\" {\n  description = \"DNS name of the P2P NLB (if enabled)\"\n  value = try(\n    kubernetes_service.energi_p2p_lb[0].status[0].load_balancer[0].ingress[0].hostname,\n    null\n  )\n}\n\noutput \"rpc_service_hostname\" {\n  description = \"DNS name of the RPC internal NLB (if enabled)\"\n  value = try(\n    kubernetes_service.energi_rpc_lb[0].status[0].load_balancer[0].ingress[0].hostname,\n    null\n  )\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region          = \"ap-south-1\"\nproject_name        = \"devops-challenge\"\nenvironment         = \"dev\"\ncluster_name        = \"devops-challenge\"\n\n# Provide this only if you need to pull from a private Docker Hub repo.\n# dockerconfigjson = <<EOT\n# {\"auths\":{\"https://index.docker.io/v1/\":{\"auth\":\"<base64(user:pass)>\"}}}\n# EOT\n\n# Keep RPC internal and restricted\nrpc_allowed_cidrs = [\"10.0.0.0/8\"]\n"
    },
    {
      "name": "README_TERRAFORM.md",
      "content": "# Terraform - Energi node on EKS\n\nThis Terraform creates:\n- VPC (public/private subnets across `az_count` AZs) + IGW + per-AZ NAT gateways\n- EKS cluster + managed node group\n- EKS add-ons: vpc-cni, coredns, kube-proxy, aws-ebs-csi-driver (with IRSA)\n- Kubernetes resources:\n  - Namespace\n  - (Optional) Docker Hub imagePullSecret `dockersecret`\n  - Headless Service `energi-node`\n  - Encrypted gp3 StorageClass (default)\n  - StatefulSet `energi-node` with per-pod PVCs\n  - Optional NLB Services for P2P (internet-facing) and RPC (internal)\n\n## Usage\n\n```bash\ncd ai_tf\nterraform init\nterraform validate\nterraform plan\n```\n\nNotes:\n- The original repo StatefulSet YAML had a PVC template name `node-data-energi-node-0` and a fixed claimName; that pattern is not correct for StatefulSets. This Terraform uses a standard `volumeClaimTemplate` named `data`.\n- RPC is exposed via an internal NLB by default; restrict `rpc_allowed_cidrs`.\n"
    }
  ]
}