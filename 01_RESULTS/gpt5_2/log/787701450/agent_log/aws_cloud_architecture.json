{
  "aws_architecture_description": "### Proposed high-level AWS architecture (secure, scalable, lean)\n\nThis system is a **serverless, event-driven NLP pipeline** built around **S3 → EventBridge → SQS → Step Functions → (S3/Comprehend) → Glue**. There is no application server to deploy; the “deployment” is primarily provisioning AWS managed services, IAM, and configuration.\n\n#### 1) Data ingestion and event routing\n- **Amazon S3 (data lake storage)**\n  - Use either **three buckets** (recommended for clearer security boundaries) or **one bucket with three prefixes**:\n    - `s3://<input-bucket>/text/` for raw text uploads\n    - `s3://<intermediate-bucket>/comprehend/` for enrichment outputs\n    - `s3://<datalake-bucket>/datalake/...` for curated outputs\n  - Enable **S3 Block Public Access**, **bucket versioning** (at least for intermediate + datalake), and **SSE-KMS** encryption.\n\n- **Amazon EventBridge**\n  - Configure **EventBridge rules** to match **S3 Object Created** events for the relevant bucket/prefix.\n  - Each rule targets an **SQS queue** (Queue A for `/text/`, Queue B for `/comprehend/`).\n\n- **Amazon SQS (decoupling + backpressure)**\n  - **Queue A** buffers ingestion events for the first workflow.\n  - **Queue B** buffers intermediate events for the second workflow.\n  - Add a **dead-letter queue (DLQ)** for each queue to isolate poison messages and prevent infinite retries.\n\n#### 2) Workflow orchestration and NLP enrichment\n- **AWS Step Functions (2 state machines)**\n  - **State machine 1: `S3ObjectCreatedText`**\n    - Triggered by messages from **Queue A**.\n    - Reads the uploaded object from the input S3 location.\n    - Calls **Amazon Comprehend Detect*** APIs via **Step Functions AWS SDK service integrations**.\n    - Writes enrichment JSON to the intermediate S3 location (`/comprehend/`).\n  - **State machine 2: `S3ObjectCreatedComprehend`**\n    - Triggered by messages from **Queue B**.\n    - Reads intermediate enrichment output.\n    - Writes curated/normalized output to the datalake S3 location (`/datalake/...`).\n\n- **Amazon Comprehend**\n  - Invoked directly from Step Functions (no Lambda required).\n  - Use IAM least-privilege so the Step Functions execution role can only call the required Comprehend APIs.\n\n#### 3) Analytics enablement (catalog/ETL)\n- **AWS Glue**\n  - Use **Glue Crawlers** to infer schema and populate the **Glue Data Catalog** from the datalake S3 paths.\n  - Use **Glue Jobs** (Spark or Python shell) if transformations/partitioning are required beyond what Step Functions writes.\n\n#### 4) Security, observability, and operations\n- **IAM**\n  - Separate IAM roles for:\n    - Step Functions execution (S3 read/write + Comprehend + CloudWatch Logs)\n    - EventBridge to SQS delivery\n    - Glue job/crawler access to S3 + Data Catalog\n  - Use **KMS key policies** and IAM policies to enforce encryption and least privilege.\n\n- **Logging/Monitoring**\n  - **CloudWatch Logs** for Step Functions execution logs.\n  - **CloudWatch metrics/alarms** for:\n    - SQS queue depth / age of oldest message\n    - Step Functions execution failures/throttles\n    - DLQ message count > 0\n  - **CloudTrail** enabled for auditability of API calls.\n\n#### 5) Networking (minimal)\n- This architecture can run **without a VPC** because S3, EventBridge, SQS, Step Functions, Comprehend, and Glue are managed services.\n- If you have strict egress controls or private connectivity requirements, add a VPC and use **VPC endpoints** (Gateway endpoint for S3; Interface endpoints for SQS/Step Functions/Glue where applicable). Otherwise, keep it lean and omit VPC.\n\n---\n\n## AWS resources to provision\n\n### Storage\n- **Amazon S3 Buckets** (either 3 buckets or 1 bucket with prefixes)\n  - Input bucket (prefix `/text/`)\n  - Intermediate bucket (prefix `/comprehend/`)\n  - Datalake bucket (prefix `/datalake/...`)\n- **S3 Bucket Notifications / EventBridge integration** (enable “send events to EventBridge” on the relevant buckets)\n\n### Eventing and queues\n- **Amazon EventBridge Rules**\n  - Rule for ObjectCreated on `/text/` → target SQS Queue A\n  - Rule for ObjectCreated on `/comprehend/` → target SQS Queue B\n- **Amazon SQS Queues**\n  - Queue A (text pipeline trigger)\n  - Queue B (comprehend pipeline trigger)\n  - DLQ for Queue A\n  - DLQ for Queue B\n- **SQS Queue Policies** allowing EventBridge to `SendMessage`\n\n### Orchestration and NLP\n- **AWS Step Functions State Machines**\n  - `S3ObjectCreatedText`\n  - `S3ObjectCreatedComprehend`\n- **Step Functions Logging Configuration** (CloudWatch Logs)\n- **Amazon Comprehend** (no “resource” to create, but IAM permissions and quotas/limits awareness are required)\n\n### Data catalog / ETL\n- **AWS Glue Data Catalog Database**\n- **AWS Glue Crawler(s)** for datalake paths\n- **AWS Glue Job(s)** (if transformations are required)\n- **Glue Connections** (only if you later add JDBC sources/sinks)\n\n### Security and encryption\n- **AWS KMS Customer Managed Key (CMK)** for S3 encryption (and optionally SQS)\n- **IAM Roles**\n  - Step Functions execution role (S3 + Comprehend + Logs)\n  - EventBridge delivery role (to SQS) if needed by your target configuration\n  - Glue service role (S3 + Data Catalog + Logs)\n- **IAM Policies** (least privilege) attached to the above roles\n\n### Observability and audit\n- **Amazon CloudWatch Log Groups**\n  - Step Functions execution logs\n  - Glue job/crawler logs\n- **Amazon CloudWatch Alarms**\n  - SQS `ApproximateNumberOfMessagesVisible` / `ApproximateAgeOfOldestMessage`\n  - DLQ message count\n  - Step Functions `ExecutionsFailed` / `ExecutionsTimedOut`\n- **AWS CloudTrail Trail** (org/account standard) with delivery to an S3 bucket\n\n### Optional (only if you require private networking controls)\n- **Amazon VPC**\n- **Private Subnets** (across 2+ AZs)\n- **Route Tables / NACLs**\n- **VPC Endpoints**\n  - Gateway endpoint: S3\n  - Interface endpoints (as needed): SQS, Step Functions, Glue, CloudWatch Logs\n- **Security Groups** (for endpoint ENIs)\n\nThis set of resources is sufficient to deploy the pipeline as described, while keeping the design serverless and avoiding unnecessary compute services (e.g., Lambda/EC2) unless you later add custom processing steps.",
  "aws_resources": [
    "Amazon S3 Bucket (Input)",
    "Amazon S3 Bucket (Intermediate)",
    "Amazon S3 Bucket (Datalake)",
    "S3 EventBridge Notifications (bucket-level setting)",
    "Amazon EventBridge Rule (S3 ObjectCreated for /text/)",
    "Amazon EventBridge Rule (S3 ObjectCreated for /comprehend/)",
    "Amazon SQS Queue (Queue A - text trigger)",
    "Amazon SQS Queue (Queue B - comprehend trigger)",
    "Amazon SQS Dead-Letter Queue (DLQ for Queue A)",
    "Amazon SQS Dead-Letter Queue (DLQ for Queue B)",
    "SQS Queue Policy (allow EventBridge to SendMessage)",
    "AWS Step Functions State Machine (S3ObjectCreatedText)",
    "AWS Step Functions State Machine (S3ObjectCreatedComprehend)",
    "AWS IAM Role (Step Functions execution role)",
    "AWS IAM Role (Glue service role)",
    "AWS IAM Policy (least-privilege for Step Functions)",
    "AWS IAM Policy (least-privilege for Glue)",
    "AWS KMS Key (CMK for S3 encryption; optional for SQS)",
    "Amazon CloudWatch Log Group (Step Functions logs)",
    "Amazon CloudWatch Log Group (Glue logs)",
    "Amazon CloudWatch Alarm (SQS queue depth/age)",
    "Amazon CloudWatch Alarm (DLQ messages)",
    "Amazon CloudWatch Alarm (Step Functions failures/timeouts)",
    "AWS Glue Data Catalog Database",
    "AWS Glue Crawler (datalake schema discovery)",
    "AWS Glue Job (optional transformations)",
    "AWS CloudTrail Trail (audit logging)",
    "(Optional) Amazon VPC",
    "(Optional) VPC Subnets (private, multi-AZ)",
    "(Optional) VPC Route Tables / NACLs",
    "(Optional) VPC Endpoint (Gateway - S3)",
    "(Optional) VPC Endpoint (Interface - SQS)",
    "(Optional) VPC Endpoint (Interface - Step Functions)",
    "(Optional) VPC Endpoint (Interface - Glue)",
    "(Optional) VPC Endpoint (Interface - CloudWatch Logs)",
    "(Optional) Security Group (for VPC endpoints)"
  ]
}