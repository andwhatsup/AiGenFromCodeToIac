{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = merge(\n      {\n        Project     = var.project_name\n        Environment = var.environment\n        ManagedBy   = \"terraform\"\n      },\n      var.tags\n    )\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"project_name\" {\n  description = \"Project/name prefix used for resource naming.\"\n  type        = string\n  default     = \"rust-cobol-toolchain\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod).\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"tags\" {\n  description = \"Additional tags to apply to all resources.\"\n  type        = map(string)\n  default     = {}\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for the VPC.\"\n  type        = string\n  default     = \"10.20.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use (2 recommended).\"\n  type        = number\n  default     = 2\n}\n\nvariable \"enable_nat_gateway\" {\n  description = \"Whether to create a NAT Gateway for private subnets outbound internet access (needed for CodeBuild to download packages if not using VPC endpoints only).\"\n  type        = bool\n  default     = true\n}\n\nvariable \"artifact_bucket_name\" {\n  description = \"Optional explicit S3 bucket name for artifacts. Leave null to auto-generate.\"\n  type        = string\n  default     = null\n}\n\nvariable \"codebuild_source_type\" {\n  description = \"CodeBuild source type. Use CODECOMMIT if you create a CodeCommit repo, or GITHUB if using GitHub (requires additional setup not included).\"\n  type        = string\n  default     = \"CODECOMMIT\"\n  validation {\n    condition     = contains([\"CODECOMMIT\"], var.codebuild_source_type)\n    error_message = \"This configuration currently supports only CODECOMMIT.\"\n  }\n}\n\nvariable \"codecommit_repository_name\" {\n  description = \"Name of the CodeCommit repository to create.\"\n  type        = string\n  default     = \"rust-cobol-toolchain\"\n}\n\nvariable \"batch_vcpu\" {\n  description = \"vCPU for the AWS Batch job (Fargate).\"\n  type        = number\n  default     = 1\n}\n\nvariable \"batch_memory\" {\n  description = \"Memory (MiB) for the AWS Batch job (Fargate).\"\n  type        = number\n  default     = 2048\n}\n\nvariable \"batch_command\" {\n  description = \"Command to run in the container for the Batch job. Leave empty to use image default CMD/ENTRYPOINT.\"\n  type        = list(string)\n  default     = []\n}\n\nvariable \"schedule_expression\" {\n  description = \"EventBridge schedule expression to trigger the Step Functions state machine.\"\n  type        = string\n  default     = \"rate(1 day)\"\n}\n\nvariable \"notification_email\" {\n  description = \"Optional email address to subscribe to SNS notifications. Leave null to skip subscription.\"\n  type        = string\n  default     = null\n}\n"
    },
    {
      "name": "locals.tf",
      "content": "data \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_partition\" \"current\" {}\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  name_prefix = \"${var.project_name}-${var.environment}\"\n\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n\n  # Private subnets: 10.20.0.0/16 -> /20 blocks\n  private_subnet_cidrs = [\n    for i in range(var.az_count) : cidrsubnet(var.vpc_cidr, 4, i)\n  ]\n\n  public_subnet_cidrs = [\n    for i in range(var.az_count) : cidrsubnet(var.vpc_cidr, 4, i + 8)\n  ]\n}\n"
    },
    {
      "name": "network.tf",
      "content": "resource \"aws_vpc\" \"this\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n\n  tags = {\n    Name = \"${local.name_prefix}-vpc\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"this\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name_prefix}-igw\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  for_each = { for idx, az in local.azs : az => idx }\n\n  vpc_id                  = aws_vpc.this.id\n  availability_zone       = each.key\n  cidr_block              = local.public_subnet_cidrs[each.value]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"${local.name_prefix}-public-${each.key}\"\n    Tier = \"public\"\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  for_each = { for idx, az in local.azs : az => idx }\n\n  vpc_id                  = aws_vpc.this.id\n  availability_zone       = each.key\n  cidr_block              = local.private_subnet_cidrs[each.value]\n  map_public_ip_on_launch = false\n\n  tags = {\n    Name = \"${local.name_prefix}-private-${each.key}\"\n    Tier = \"private\"\n  }\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name_prefix}-public-rt\"\n  }\n}\n\nresource \"aws_route\" \"public_internet\" {\n  route_table_id         = aws_route_table.public.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  gateway_id             = aws_internet_gateway.this.id\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  for_each = aws_subnet.public\n\n  subnet_id      = each.value.id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_eip\" \"nat\" {\n  count  = var.enable_nat_gateway ? 1 : 0\n  domain = \"vpc\"\n\n  tags = {\n    Name = \"${local.name_prefix}-nat-eip\"\n  }\n}\n\nresource \"aws_nat_gateway\" \"this\" {\n  count         = var.enable_nat_gateway ? 1 : 0\n  allocation_id = aws_eip.nat[0].id\n  subnet_id     = values(aws_subnet.public)[0].id\n\n  tags = {\n    Name = \"${local.name_prefix}-nat\"\n  }\n\n  depends_on = [aws_internet_gateway.this]\n}\n\nresource \"aws_route_table\" \"private\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name_prefix}-private-rt\"\n  }\n}\n\nresource \"aws_route\" \"private_default\" {\n  count                  = var.enable_nat_gateway ? 1 : 0\n  route_table_id         = aws_route_table.private.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.this[0].id\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  for_each = aws_subnet.private\n\n  subnet_id      = each.value.id\n  route_table_id = aws_route_table.private.id\n}\n\n# VPC endpoints to reduce/avoid public egress for runtime.\nresource \"aws_vpc_endpoint\" \"s3\" {\n  vpc_id            = aws_vpc.this.id\n  service_name      = \"com.amazonaws.${var.aws_region}.s3\"\n  vpc_endpoint_type = \"Gateway\"\n\n  route_table_ids = [aws_route_table.private.id]\n\n  tags = {\n    Name = \"${local.name_prefix}-vpce-s3\"\n  }\n}\n\nresource \"aws_security_group\" \"endpoints\" {\n  name        = \"${local.name_prefix}-vpce-sg\"\n  description = \"Security group for interface VPC endpoints\"\n  vpc_id      = aws_vpc.this.id\n\n  ingress {\n    description = \"HTTPS from VPC\"\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [aws_vpc.this.cidr_block]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-vpce-sg\"\n  }\n}\n\nresource \"aws_vpc_endpoint\" \"ecr_api\" {\n  vpc_id              = aws_vpc.this.id\n  service_name        = \"com.amazonaws.${var.aws_region}.ecr.api\"\n  vpc_endpoint_type   = \"Interface\"\n  private_dns_enabled = true\n\n  subnet_ids         = [for s in aws_subnet.private : s.id]\n  security_group_ids = [aws_security_group.endpoints.id]\n\n  tags = {\n    Name = \"${local.name_prefix}-vpce-ecr-api\"\n  }\n}\n\nresource \"aws_vpc_endpoint\" \"ecr_dkr\" {\n  vpc_id              = aws_vpc.this.id\n  service_name        = \"com.amazonaws.${var.aws_region}.ecr.dkr\"\n  vpc_endpoint_type   = \"Interface\"\n  private_dns_enabled = true\n\n  subnet_ids         = [for s in aws_subnet.private : s.id]\n  security_group_ids = [aws_security_group.endpoints.id]\n\n  tags = {\n    Name = \"${local.name_prefix}-vpce-ecr-dkr\"\n  }\n}\n\nresource \"aws_vpc_endpoint\" \"logs\" {\n  vpc_id              = aws_vpc.this.id\n  service_name        = \"com.amazonaws.${var.aws_region}.logs\"\n  vpc_endpoint_type   = \"Interface\"\n  private_dns_enabled = true\n\n  subnet_ids         = [for s in aws_subnet.private : s.id]\n  security_group_ids = [aws_security_group.endpoints.id]\n\n  tags = {\n    Name = \"${local.name_prefix}-vpce-logs\"\n  }\n}\n"
    },
    {
      "name": "kms_s3_ecr.tf",
      "content": "resource \"aws_kms_key\" \"main\" {\n  description             = \"KMS key for ${local.name_prefix} (S3 artifacts, logs, etc.)\"\n  deletion_window_in_days = 10\n  enable_key_rotation     = true\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid      = \"EnableRootPermissions\"\n        Effect   = \"Allow\"\n        Principal = {\n          AWS = \"arn:${data.aws_partition.current.partition}:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action   = \"kms:*\"\n        Resource = \"*\"\n      }\n    ]\n  })\n\n  tags = {\n    Name = \"${local.name_prefix}-kms\"\n  }\n}\n\nresource \"aws_kms_alias\" \"main\" {\n  name          = \"alias/${local.name_prefix}\"\n  target_key_id = aws_kms_key.main.key_id\n}\n\nresource \"aws_s3_bucket\" \"artifacts\" {\n  bucket        = var.artifact_bucket_name\n  force_destroy = false\n\n  tags = {\n    Name = \"${local.name_prefix}-artifacts\"\n  }\n}\n\nresource \"aws_s3_bucket_versioning\" \"artifacts\" {\n  bucket = aws_s3_bucket.artifacts.id\n\n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"artifacts\" {\n  bucket = aws_s3_bucket.artifacts.id\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm     = \"aws:kms\"\n      kms_master_key_id = aws_kms_key.main.arn\n    }\n  }\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"artifacts\" {\n  bucket = aws_s3_bucket.artifacts.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource \"aws_s3_bucket_ownership_controls\" \"artifacts\" {\n  bucket = aws_s3_bucket.artifacts.id\n\n  rule {\n    object_ownership = \"BucketOwnerEnforced\"\n  }\n}\n\nresource \"aws_s3_bucket_lifecycle_configuration\" \"artifacts\" {\n  bucket = aws_s3_bucket.artifacts.id\n\n  rule {\n    id     = \"expire-noncurrent\"\n    status = \"Enabled\"\n\n    filter {}\n\n    noncurrent_version_expiration {\n      noncurrent_days = 30\n    }\n\n    abort_incomplete_multipart_upload {\n      days_after_initiation = 7\n    }\n  }\n}\n\nresource \"aws_ecr_repository\" \"toolchain\" {\n  name                 = \"${local.name_prefix}\"\n  image_tag_mutability = \"IMMUTABLE\"\n\n  encryption_configuration {\n    encryption_type = \"KMS\"\n    kms_key         = aws_kms_key.main.arn\n  }\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}\"\n  }\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"toolchain\" {\n  repository = aws_ecr_repository.toolchain.name\n\n  policy = jsonencode({\n    rules = [\n      {\n        rulePriority = 1\n        description  = \"Keep last 30 images\"\n        selection = {\n          tagStatus   = \"any\"\n          countType   = \"imageCountMoreThan\"\n          countNumber = 30\n        }\n        action = {\n          type = \"expire\"\n        }\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "iam.tf",
      "content": "data \"aws_iam_policy_document\" \"assume_codebuild\" {\n  statement {\n    effect = \"Allow\"\n    principals {\n      type        = \"Service\"\n      identifiers = [\"codebuild.amazonaws.com\"]\n    }\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nresource \"aws_iam_role\" \"codebuild\" {\n  name               = \"${local.name_prefix}-codebuild-role\"\n  assume_role_policy = data.aws_iam_policy_document.assume_codebuild.json\n}\n\nresource \"aws_iam_role_policy\" \"codebuild\" {\n  name = \"${local.name_prefix}-codebuild-policy\"\n  role = aws_iam_role.codebuild.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"Logs\"\n        Effect = \"Allow\"\n        Action = [\n          \"logs:CreateLogGroup\",\n          \"logs:CreateLogStream\",\n          \"logs:PutLogEvents\"\n        ]\n        Resource = \"*\"\n      },\n      {\n        Sid    = \"ECRAuth\"\n        Effect = \"Allow\"\n        Action = [\n          \"ecr:GetAuthorizationToken\"\n        ]\n        Resource = \"*\"\n      },\n      {\n        Sid    = \"ECRPushPull\"\n        Effect = \"Allow\"\n        Action = [\n          \"ecr:BatchCheckLayerAvailability\",\n          \"ecr:CompleteLayerUpload\",\n          \"ecr:InitiateLayerUpload\",\n          \"ecr:PutImage\",\n          \"ecr:UploadLayerPart\",\n          \"ecr:BatchGetImage\",\n          \"ecr:GetDownloadUrlForLayer\"\n        ]\n        Resource = aws_ecr_repository.toolchain.arn\n      },\n      {\n        Sid    = \"S3Artifacts\"\n        Effect = \"Allow\"\n        Action = [\n          \"s3:PutObject\",\n          \"s3:GetObject\",\n          \"s3:ListBucket\"\n        ]\n        Resource = [\n          aws_s3_bucket.artifacts.arn,\n          \"${aws_s3_bucket.artifacts.arn}/*\"\n        ]\n      },\n      {\n        Sid    = \"KMS\"\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Encrypt\",\n          \"kms:Decrypt\",\n          \"kms:GenerateDataKey\",\n          \"kms:DescribeKey\"\n        ]\n        Resource = aws_kms_key.main.arn\n      },\n      {\n        Sid    = \"VPC\"\n        Effect = \"Allow\"\n        Action = [\n          \"ec2:CreateNetworkInterface\",\n          \"ec2:DescribeNetworkInterfaces\",\n          \"ec2:DeleteNetworkInterface\",\n          \"ec2:DescribeSubnets\",\n          \"ec2:DescribeSecurityGroups\",\n          \"ec2:DescribeVpcs\"\n        ]\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n\ndata \"aws_iam_policy_document\" \"assume_ecs_tasks\" {\n  statement {\n    effect = \"Allow\"\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ecs-tasks.amazonaws.com\"]\n    }\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nresource \"aws_iam_role\" \"batch_execution\" {\n  name               = \"${local.name_prefix}-batch-exec-role\"\n  assume_role_policy = data.aws_iam_policy_document.assume_ecs_tasks.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"batch_execution\" {\n  role       = aws_iam_role.batch_execution.name\n  policy_arn = \"arn:${data.aws_partition.current.partition}:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\n}\n\nresource \"aws_iam_role_policy\" \"batch_execution_extra\" {\n  name = \"${local.name_prefix}-batch-exec-extra\"\n  role = aws_iam_role.batch_execution.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"ECRAuth\"\n        Effect = \"Allow\"\n        Action = [\"ecr:GetAuthorizationToken\"]\n        Resource = \"*\"\n      },\n      {\n        Sid    = \"KMS\"\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Decrypt\",\n          \"kms:GenerateDataKey\",\n          \"kms:DescribeKey\"\n        ]\n        Resource = aws_kms_key.main.arn\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role\" \"batch_job\" {\n  name               = \"${local.name_prefix}-batch-job-role\"\n  assume_role_policy = data.aws_iam_policy_document.assume_ecs_tasks.json\n}\n\nresource \"aws_iam_role_policy\" \"batch_job\" {\n  name = \"${local.name_prefix}-batch-job-policy\"\n  role = aws_iam_role.batch_job.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"S3Artifacts\"\n        Effect = \"Allow\"\n        Action = [\n          \"s3:PutObject\",\n          \"s3:GetObject\",\n          \"s3:ListBucket\"\n        ]\n        Resource = [\n          aws_s3_bucket.artifacts.arn,\n          \"${aws_s3_bucket.artifacts.arn}/*\"\n        ]\n      },\n      {\n        Sid    = \"KMS\"\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Encrypt\",\n          \"kms:Decrypt\",\n          \"kms:GenerateDataKey\",\n          \"kms:DescribeKey\"\n        ]\n        Resource = aws_kms_key.main.arn\n      }\n    ]\n  })\n}\n\ndata \"aws_iam_policy_document\" \"assume_sfn\" {\n  statement {\n    effect = \"Allow\"\n    principals {\n      type        = \"Service\"\n      identifiers = [\"states.amazonaws.com\"]\n    }\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nresource \"aws_iam_role\" \"sfn\" {\n  name               = \"${local.name_prefix}-sfn-role\"\n  assume_role_policy = data.aws_iam_policy_document.assume_sfn.json\n}\n\nresource \"aws_iam_role_policy\" \"sfn\" {\n  name = \"${local.name_prefix}-sfn-policy\"\n  role = aws_iam_role.sfn.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"BatchSubmit\"\n        Effect = \"Allow\"\n        Action = [\n          \"batch:SubmitJob\",\n          \"batch:DescribeJobs\",\n          \"batch:TerminateJob\"\n        ]\n        Resource = \"*\"\n      },\n      {\n        Sid    = \"PassRoles\"\n        Effect = \"Allow\"\n        Action = [\"iam:PassRole\"]\n        Resource = [\n          aws_iam_role.batch_execution.arn,\n          aws_iam_role.batch_job.arn\n        ]\n      },\n      {\n        Sid    = \"Logs\"\n        Effect = \"Allow\"\n        Action = [\n          \"logs:CreateLogDelivery\",\n          \"logs:GetLogDelivery\",\n          \"logs:UpdateLogDelivery\",\n          \"logs:DeleteLogDelivery\",\n          \"logs:ListLogDeliveries\",\n          \"logs:PutResourcePolicy\",\n          \"logs:DescribeResourcePolicies\",\n          \"logs:DescribeLogGroups\"\n        ]\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n\ndata \"aws_iam_policy_document\" \"assume_events\" {\n  statement {\n    effect = \"Allow\"\n    principals {\n      type        = \"Service\"\n      identifiers = [\"events.amazonaws.com\"]\n    }\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nresource \"aws_iam_role\" \"eventbridge\" {\n  name               = \"${local.name_prefix}-events-role\"\n  assume_role_policy = data.aws_iam_policy_document.assume_events.json\n}\n\nresource \"aws_iam_role_policy\" \"eventbridge\" {\n  name = \"${local.name_prefix}-events-policy\"\n  role = aws_iam_role.eventbridge.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"StartExecution\"\n        Effect = \"Allow\"\n        Action = [\"states:StartExecution\"]\n        Resource = aws_sfn_state_machine.this.arn\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "codecommit_codebuild.tf",
      "content": "resource \"aws_codecommit_repository\" \"this\" {\n  repository_name = var.codecommit_repository_name\n  description     = \"${local.name_prefix} source repository\"\n}\n\nresource \"aws_cloudwatch_log_group\" \"codebuild\" {\n  name              = \"/aws/codebuild/${local.name_prefix}\"\n  retention_in_days = 30\n  kms_key_id        = aws_kms_key.main.arn\n}\n\nresource \"aws_security_group\" \"codebuild\" {\n  name        = \"${local.name_prefix}-codebuild-sg\"\n  description = \"Security group for CodeBuild in VPC\"\n  vpc_id      = aws_vpc.this.id\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-codebuild-sg\"\n  }\n}\n\nresource \"aws_codebuild_project\" \"docker_build\" {\n  name          = \"${local.name_prefix}-docker-build\"\n  description   = \"Build Docker image and push to ECR\"\n  service_role  = aws_iam_role.codebuild.arn\n  build_timeout = 60\n\n  artifacts {\n    type = \"NO_ARTIFACTS\"\n  }\n\n  environment {\n    compute_type                = \"BUILD_GENERAL1_MEDIUM\"\n    image                       = \"aws/codebuild/standard:7.0\"\n    type                        = \"LINUX_CONTAINER\"\n    privileged_mode             = true\n    image_pull_credentials_type = \"CODEBUILD\"\n\n    environment_variable {\n      name  = \"ECR_REPO_URI\"\n      value = aws_ecr_repository.toolchain.repository_url\n    }\n\n    environment_variable {\n      name  = \"AWS_REGION\"\n      value = var.aws_region\n    }\n  }\n\n  logs_config {\n    cloudwatch_logs {\n      group_name  = aws_cloudwatch_log_group.codebuild.name\n      stream_name = \"build\"\n    }\n  }\n\n  source {\n    type            = var.codebuild_source_type\n    location        = aws_codecommit_repository.this.clone_url_http\n    git_clone_depth = 1\n\n    buildspec = <<-YAML\n      version: 0.2\n      phases:\n        pre_build:\n          commands:\n            - echo Logging in to Amazon ECR...\n            - aws --version\n            - aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REPO_URI\n            - COMMIT_HASH=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7)\n            - IMAGE_TAG=$${COMMIT_HASH:-latest}\n        build:\n          commands:\n            - echo Build started on `date`\n            - echo Building the Docker image...\n            - docker build -t $ECR_REPO_URI:$IMAGE_TAG .\n        post_build:\n          commands:\n            - echo Build completed on `date`\n            - echo Pushing the Docker image...\n            - docker push $ECR_REPO_URI:$IMAGE_TAG\n            - echo Writing image detail...\n            - printf '{\"ImageURI\":\"%s\"}' $ECR_REPO_URI:$IMAGE_TAG > imageDetail.json\n      artifacts:\n        files:\n          - imageDetail.json\n    YAML\n  }\n\n  vpc_config {\n    vpc_id             = aws_vpc.this.id\n    subnets            = [for s in aws_subnet.private : s.id]\n    security_group_ids = [aws_security_group.codebuild.id]\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-docker-build\"\n  }\n}\n"
    },
    {
      "name": "batch.tf",
      "content": "resource \"aws_cloudwatch_log_group\" \"batch\" {\n  name              = \"/aws/batch/${local.name_prefix}\"\n  retention_in_days = 30\n  kms_key_id        = aws_kms_key.main.arn\n}\n\nresource \"aws_security_group\" \"batch\" {\n  name        = \"${local.name_prefix}-batch-sg\"\n  description = \"Security group for AWS Batch (Fargate)\"\n  vpc_id      = aws_vpc.this.id\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-batch-sg\"\n  }\n}\n\nresource \"aws_batch_compute_environment\" \"this\" {\n  compute_environment_name = \"${local.name_prefix}-ce\"\n  type                     = \"MANAGED\"\n\n  compute_resources {\n    type               = \"FARGATE\"\n    max_vcpus          = 16\n    subnets            = [for s in aws_subnet.private : s.id]\n    security_group_ids = [aws_security_group.batch.id]\n\n    # Fargate requires an execution role for pulling images/logging.\n    # In AWS Batch, this is set on the job definition; compute env doesn't take it.\n  }\n\n  service_role = aws_iam_role.batch_service.arn\n\n  depends_on = [aws_iam_role_policy_attachment.batch_service]\n}\n\ndata \"aws_iam_policy_document\" \"assume_batch\" {\n  statement {\n    effect = \"Allow\"\n    principals {\n      type        = \"Service\"\n      identifiers = [\"batch.amazonaws.com\"]\n    }\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nresource \"aws_iam_role\" \"batch_service\" {\n  name               = \"${local.name_prefix}-batch-service-role\"\n  assume_role_policy = data.aws_iam_policy_document.assume_batch.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"batch_service\" {\n  role       = aws_iam_role.batch_service.name\n  policy_arn = \"arn:${data.aws_partition.current.partition}:iam::aws:policy/service-role/AWSBatchServiceRole\"\n}\n\nresource \"aws_batch_job_queue\" \"this\" {\n  name     = \"${local.name_prefix}-queue\"\n  state    = \"ENABLED\"\n  priority = 1\n\n  compute_environment_order {\n    order               = 1\n    compute_environment = aws_batch_compute_environment.this.arn\n  }\n}\n\nresource \"aws_batch_job_definition\" \"this\" {\n  name = \"${local.name_prefix}-job\"\n  type = \"container\"\n\n  platform_capabilities = [\"FARGATE\"]\n\n  container_properties = jsonencode({\n    image = \"${aws_ecr_repository.toolchain.repository_url}:latest\"\n\n    command = length(var.batch_command) > 0 ? var.batch_command : null\n\n    executionRoleArn = aws_iam_role.batch_execution.arn\n    jobRoleArn       = aws_iam_role.batch_job.arn\n\n    resourceRequirements = [\n      { type = \"VCPU\", value = tostring(var.batch_vcpu) },\n      { type = \"MEMORY\", value = tostring(var.batch_memory) }\n    ]\n\n    environment = [\n      { name = \"ARTIFACT_BUCKET\", value = aws_s3_bucket.artifacts.bucket },\n      { name = \"AWS_REGION\", value = var.aws_region }\n    ]\n\n    logConfiguration = {\n      logDriver = \"awslogs\"\n      options = {\n        awslogs-group         = aws_cloudwatch_log_group.batch.name\n        awslogs-region        = var.aws_region\n        awslogs-stream-prefix = \"job\"\n      }\n    }\n\n    networkConfiguration = {\n      assignPublicIp = \"DISABLED\"\n    }\n  })\n\n  retry_strategy {\n    attempts = 1\n  }\n\n  timeout {\n    attempt_duration_seconds = 3600\n  }\n}\n"
    },
    {
      "name": "stepfunctions_eventbridge_sns.tf",
      "content": "resource \"aws_sns_topic\" \"notifications\" {\n  name              = \"${local.name_prefix}-notifications\"\n  kms_master_key_id = aws_kms_key.main.arn\n}\n\nresource \"aws_sns_topic_subscription\" \"email\" {\n  count     = var.notification_email == null ? 0 : 1\n  topic_arn = aws_sns_topic.notifications.arn\n  protocol  = \"email\"\n  endpoint  = var.notification_email\n}\n\nresource \"aws_sfn_state_machine\" \"this\" {\n  name     = \"${local.name_prefix}-state-machine\"\n  role_arn = aws_iam_role.sfn.arn\n\n  definition = jsonencode({\n    Comment = \"Submit AWS Batch job for ${local.name_prefix}\"\n    StartAt = \"SubmitBatchJob\"\n    States = {\n      SubmitBatchJob = {\n        Type     = \"Task\"\n        Resource = \"arn:${data.aws_partition.current.partition}:states:::batch:submitJob.sync\"\n        Parameters = {\n          JobName       = \"${local.name_prefix}-run\"\n          JobQueue      = aws_batch_job_queue.this.arn\n          JobDefinition = aws_batch_job_definition.this.arn\n        }\n        Next = \"NotifySuccess\"\n        Catch = [\n          {\n            ErrorEquals = [\"States.ALL\"]\n            Next        = \"NotifyFailure\"\n          }\n        ]\n      }\n      NotifySuccess = {\n        Type     = \"Task\"\n        Resource = \"arn:${data.aws_partition.current.partition}:states:::sns:publish\"\n        Parameters = {\n          TopicArn = aws_sns_topic.notifications.arn\n          Message  = \"${local.name_prefix} Batch job succeeded.\"\n          Subject  = \"${local.name_prefix}: SUCCESS\"\n        }\n        End = true\n      }\n      NotifyFailure = {\n        Type     = \"Task\"\n        Resource = \"arn:${data.aws_partition.current.partition}:states:::sns:publish\"\n        Parameters = {\n          TopicArn = aws_sns_topic.notifications.arn\n          Message  = \"${local.name_prefix} Batch job failed.\"\n          Subject  = \"${local.name_prefix}: FAILURE\"\n        }\n        End = true\n      }\n    }\n  })\n}\n\nresource \"aws_cloudwatch_event_rule\" \"schedule\" {\n  name                = \"${local.name_prefix}-schedule\"\n  description         = \"Schedule to trigger ${local.name_prefix} state machine\"\n  schedule_expression = var.schedule_expression\n}\n\nresource \"aws_cloudwatch_event_target\" \"sfn\" {\n  rule      = aws_cloudwatch_event_rule.schedule.name\n  target_id = \"sfn\"\n  arn       = aws_sfn_state_machine.this.arn\n  role_arn  = aws_iam_role.eventbridge.arn\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"codecommit_clone_url_http\" {\n  description = \"HTTP clone URL for the CodeCommit repository.\"\n  value       = aws_codecommit_repository.this.clone_url_http\n}\n\noutput \"ecr_repository_url\" {\n  description = \"ECR repository URL to push images to.\"\n  value       = aws_ecr_repository.toolchain.repository_url\n}\n\noutput \"artifact_bucket_name\" {\n  description = \"S3 bucket for job artifacts.\"\n  value       = aws_s3_bucket.artifacts.bucket\n}\n\noutput \"batch_job_queue_arn\" {\n  value = aws_batch_job_queue.this.arn\n}\n\noutput \"batch_job_definition_arn\" {\n  value = aws_batch_job_definition.this.arn\n}\n\noutput \"state_machine_arn\" {\n  value = aws_sfn_state_machine.this.arn\n}\n\noutput \"sns_topic_arn\" {\n  value = aws_sns_topic.notifications.arn\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region   = \"us-east-1\"\nproject_name = \"rust-cobol-toolchain\"\nenvironment  = \"dev\"\n\n# Optional: set to receive email notifications (requires confirmation)\n# notification_email = \"you@example.com\"\n\n# Optional: override schedule\n# schedule_expression = \"cron(0 2 * * ? *)\" # daily at 02:00 UTC\n\n# Optional: override Batch command\n# batch_command = [\"/bin/bash\", \"-lc\", \"./scripts/bash/environment.sh && cargo run --release -- --help\"]\n"
    },
    {
      "name": "README.md",
      "content": "# Terraform: Rust + GnuCOBOL toolchain on AWS (CodeBuild + ECR + Batch + Step Functions)\n\nThis Terraform deploys a minimal, secure batch-oriented AWS architecture:\n- CodeCommit repo (optional source host)\n- CodeBuild project to build/push Docker image to ECR\n- ECR repository (KMS encrypted, scan on push)\n- S3 bucket for artifacts (KMS encrypted)\n- AWS Batch (Fargate) job queue/definition to run the container on-demand\n- Step Functions state machine to submit the Batch job and notify via SNS\n- EventBridge schedule to trigger the state machine\n- VPC with private subnets + VPC endpoints (S3, ECR, CloudWatch Logs) and optional NAT\n\n## Usage\n\n```bash\ncd ai_tf\nterraform init\nterraform validate\nterraform plan\n```\n\nAfter apply:\n1. Push your repo content into the created CodeCommit repository.\n2. Start a CodeBuild build to publish an image tag (the Batch job definition uses `:latest` by default; you can update it to a specific tag).\n3. EventBridge will trigger the Step Functions state machine on the configured schedule.\n\n## Notes\n- This is a baseline. You may want to add CodePipeline to trigger CodeBuild on commits.\n- If you disable NAT, ensure your build/runtime does not require internet access beyond the configured VPC endpoints.\n"
    }
  ]
}