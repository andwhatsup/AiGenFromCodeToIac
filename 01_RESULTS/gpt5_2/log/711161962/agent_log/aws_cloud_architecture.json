{
  "aws_architecture_description": "## Proposed high-level AWS architecture (S3 → SQS → Lambda)\n\n### 1) Ingestion (CSV landing)\n- **Amazon S3 bucket** is the system’s entry point. Producers upload CSV files (optionally restricted to a prefix like `incoming/` and suffix `.csv`).\n- **S3 Event Notifications** are configured on `ObjectCreated:*` (or narrower) to publish a notification to an **Amazon SQS Standard queue** (S3 does not support sending notifications directly to SQS FIFO). ([docs.aws.amazon.com](https://docs.aws.amazon.com/AmazonS3/latest/userguide/EventNotifications.html?utm_source=openai))\n\n### 2) Buffering / decoupling\n- **Amazon SQS Standard queue** buffers events from S3, decoupling upload spikes from processing capacity.\n- Add a **Dead-Letter Queue (DLQ)** and configure a redrive policy on the main queue to isolate poison messages and prevent infinite retries.\n\n### 3) Processing\n- **AWS Lambda (Go)** consumes the SQS messages via an **event source mapping**.\n- Because the codebase uses a custom runtime bootstrap (`bootstrap` inside `handler.zip`), deploy the function using the **`provided` runtime family** (prefer `provided.al2023` unless you have a reason to stay on AL2). ([docs.aws.amazon.com](https://docs.aws.amazon.com/lambda/latest/dg/golang-package.html?utm_source=openai))\n- Configure the event source mapping with:\n  - **BatchSize** appropriate to processing time and message volume (Standard queues can go up to 10,000). ([docs.aws.amazon.com](https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-configure.html?utm_source=openai))\n  - Optional **MaximumBatchingWindowInSeconds** (required if BatchSize > 10). ([docs.aws.amazon.com](https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-configure.html?utm_source=openai))\n  - **Partial batch response** (`ReportBatchItemFailures`) if you want to fail only specific records in a batch (recommended for resilience with mixed-good/mixed-bad batches). ([docs.aws.amazon.com](https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-parameters.html?utm_source=openai))\n- The Lambda function can optionally read the referenced CSV object from S3 (least-privilege `s3:GetObject` on the bucket/prefix).\n\n### 4) Security / IAM\n- **S3 → SQS permission**: attach an SQS queue policy allowing the S3 bucket (and only that bucket) to `sqs:SendMessage` to the queue. AWS requires explicitly granting S3 permission to publish to SQS. ([docs.aws.amazon.com](https://docs.aws.amazon.com/AmazonS3/latest/userguide/notification-how-to-event-types-and-destinations.html?utm_source=openai))\n- **Lambda execution role**:\n  - CloudWatch Logs permissions\n  - `sqs:ReceiveMessage`, `sqs:DeleteMessage`, `sqs:GetQueueAttributes` on the main queue\n  - Optional `s3:GetObject` (and `s3:ListBucket` if needed) scoped to the bucket/prefix\n  - Optional KMS permissions if you enable SSE-KMS\n\n### 5) Observability & operations\n- **CloudWatch Logs** for Lambda logs.\n- **CloudWatch metrics/alarms** for:\n  - SQS `ApproximateNumberOfMessagesVisible` (backlog)\n  - DLQ depth\n  - Lambda `Errors`, `Throttles`, `Duration`\n- **AWS X-Ray** (optional) for tracing if you later add downstream calls.\n\n### 6) Networking (keep it lean)\n- This workload can run **without a VPC** (simplest, lowest cost) because it only uses AWS public endpoints (S3/SQS). Only place Lambda in a VPC if you must reach private resources.\n\n---\n\n## Deployment strategy (practical)\n- Package and deploy `handler.zip` (containing `bootstrap`) to Lambda.\n- Use IaC (CloudFormation/SAM/Terraform/CDK) to create the bucket, queues, policies, and event source mapping.\n- Use environment variables for bucket name, prefix, and any parsing configuration.\n",
  "aws_resources": [
    "Amazon S3 Bucket (CSV uploads)",
    "S3 Bucket Notification Configuration (ObjectCreated events → SQS)",
    "S3 Public Access Block (bucket-level)",
    "S3 Bucket Policy (optional; enforce TLS, restrict principals)",
    "Amazon SQS Standard Queue (main ingestion queue)",
    "Amazon SQS Dead-Letter Queue (DLQ)",
    "SQS Redrive Policy (main queue → DLQ)",
    "SQS Queue Policy (allow S3 bucket to sqs:SendMessage with source-arn condition)",
    "AWS Lambda Function (Go custom runtime, runtime: provided.al2023, zip artifact handler.zip with bootstrap)",
    "Lambda Event Source Mapping (SQS → Lambda; BatchSize/BatchingWindow/ReportBatchItemFailures as needed)",
    "IAM Role for Lambda execution",
    "IAM Policy attachments for Lambda role (CloudWatch Logs + SQS consume + optional S3 read)",
    "CloudWatch Log Group for Lambda (with retention policy)",
    "CloudWatch Alarms (SQS backlog, DLQ depth, Lambda errors/throttles)",
    "AWS KMS Key (optional; if using SSE-KMS for S3 and/or SQS)",
    "AWS KMS Key Alias (optional)",
    "AWS X-Ray configuration (optional)"
  ]
}