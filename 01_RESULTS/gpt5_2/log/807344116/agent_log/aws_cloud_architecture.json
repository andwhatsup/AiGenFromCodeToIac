{
  "aws_architecture_description": "## Proposed high-level AWS architecture (EKS Pod Identity + STS AssumeRole)\n\n### 1) Container build & delivery\n- **Source + CI/CD**: GitHub Actions builds the multi-stage container image (Rust `epicac` binary + Python runtime) and pushes it to **Amazon ECR**.\n- **Image security**: Enable ECR image scanning and enforce immutable tags (or a tag strategy like `sha-<gitsha>`). Optionally sign images (AWS Signer / cosign) and enforce signature verification via admission controls.\n\n### 2) Runtime: Amazon EKS\n- **EKS cluster in a dedicated VPC** spanning at least 2 AZs.\n- **Worker nodes**: Use **EKS Managed Node Groups** (or Fargate if you want to avoid nodes; this workload is a single Pod/Job-style utility and can fit either model). Keep nodes in **private subnets**.\n- **Namespace + ServiceAccount**: Deploy the Kubernetes `Namespace`, `ServiceAccount`, and `Pod` (or preferably a `Deployment`/`Job` depending on how it’s used) from your manifests.\n- **EKS Pod Identity**: Associate the Kubernetes ServiceAccount with an **IAM role** via **EKS Pod Identity**. At runtime, the Pod receives the projected identity token and the AWS SDK environment variables (as your code expects).\n\n### 3) Identity & access: STS role chaining\n- **Pod IAM role (source role)**: The Pod Identity role is granted permission to call **STS:AssumeRole** into one or more **target roles** (including cross-account roles).\n- **Target roles (destination roles)**: In each target account, create an IAM role that trusts the source role and grants the minimum required permissions (e.g., S3 read/list).\n- **Credential flow**:\n  1. Pod starts with Pod Identity credentials.\n  2. Rust `epicac` uses those credentials to call **AWS STS AssumeRole** (and optionally role chaining).\n  3. Python `boto3` uses `credential_process` to invoke `epicac` and receives temporary credentials.\n  4. Python calls AWS APIs (example: **S3 ListBuckets**) using the temporary credentials.\n\n### 4) Networking\n- **Private cluster posture**: Run nodes and Pods in private subnets; allow outbound access via **NAT Gateway**.\n- **VPC endpoints (recommended)**: Add **Interface/Gateway VPC Endpoints** so Pods can reach AWS APIs privately and reduce NAT dependency/cost:\n  - STS (Interface endpoint)\n  - ECR (api + dkr interface endpoints)\n  - S3 (Gateway endpoint)\n  - CloudWatch Logs (Interface endpoint) if you ship logs\n- **Security groups + NACLs**: Restrict egress to required destinations; restrict node-to-node and control-plane access per EKS best practices.\n\n### 5) Observability & operations\n- **Logging**: Send container logs to **CloudWatch Logs** (via Fluent Bit / CloudWatch agent add-on). \n- **Metrics**: Use **Container Insights** (CloudWatch) or Prometheus/Grafana if you already have it.\n- **Audit**: Enable **CloudTrail** for STS and IAM events; optionally centralize to a security account.\n\n### 6) Secrets/config\n- Prefer **IRSA/POD Identity** over static credentials (already the design).\n- If you need non-secret config, use Kubernetes ConfigMaps.\n- If you need secrets (not shown in your repo), use **AWS Secrets Manager** (or SSM Parameter Store) and grant access via the Pod Identity role.\n\n---\n\n## Notes on “lean” deployment choices\n- If this is a short-lived utility, consider running it as a **Kubernetes Job** rather than a long-running Pod.\n- If you want to avoid managing nodes, consider **EKS on Fargate** (ensure your image size/startup time is acceptable and you don’t need privileged features).\n",
  "aws_resources": [
    "Amazon VPC",
    "VPC subnets (private subnets across 2+ AZs, optional public subnets for NAT)",
    "Internet Gateway (if using public subnets)",
    "NAT Gateway(s) + Elastic IP(s) (if private subnets need outbound internet)",
    "Route tables (public/private)",
    "Security Groups (EKS control plane to nodes, node group, and any endpoint SGs)",
    "Network ACLs (optional, if you enforce subnet-level controls)",
    "Amazon EKS Cluster",
    "EKS Managed Node Group(s) (or EKS Fargate Profile as an alternative)",
    "EKS Add-ons (recommended): VPC CNI, CoreDNS, kube-proxy (and Pod Identity agent if required by your chosen setup)",
    "Kubernetes Namespace (manifest-managed)",
    "Kubernetes ServiceAccount (manifest-managed, used with EKS Pod Identity)",
    "EKS Pod Identity Association (ServiceAccount ↔ IAM Role mapping)",
    "Amazon ECR Repository",
    "ECR lifecycle policy (image retention)",
    "ECR image scanning configuration (basic/enhanced)",
    "IAM Role for EKS node group (if using nodes) + instance profile",
    "IAM Role for EKS Pod Identity (source role used by the Pod)",
    "IAM policy attached to Pod Identity role (minimum: sts:AssumeRole to specific target roles; plus any direct AWS API permissions if needed)",
    "IAM Role(s) in target account(s) for AssumeRole (destination roles)",
    "IAM policies for target role(s) (e.g., S3 permissions)",
    "AWS STS (service dependency; no resource to create, but permissions/policies required)",
    "Amazon S3 bucket(s) (only if this system owns/creates buckets; otherwise it consumes existing buckets)",
    "VPC Gateway Endpoint for Amazon S3 (recommended)",
    "VPC Interface Endpoint for AWS STS (recommended)",
    "VPC Interface Endpoints for Amazon ECR (api and dkr) (recommended)",
    "VPC Interface Endpoint for CloudWatch Logs (recommended if shipping logs privately)",
    "Amazon CloudWatch Log Group(s) (for EKS workload logs)",
    "CloudWatch alarms (basic: node group health, pod crashlooping via metrics, NAT GW errors if used)",
    "AWS CloudTrail trail (account-level; recommended for auditing STS/IAM activity)"
  ]
}