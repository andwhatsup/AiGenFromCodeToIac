{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~> 2.25\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~> 2.12\"\n    }\n    tls = {\n      source  = \"hashicorp/tls\"\n      version = \"~> 4.0\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = merge(\n      {\n        Project     = var.project_name\n        Environment = var.environment\n        ManagedBy   = \"terraform\"\n      },\n      var.tags\n    )\n  }\n}\n\n# EKS auth for Kubernetes/Helm providers\ndata \"aws_eks_cluster\" \"this\" {\n  name = module.eks.cluster_name\n}\n\ndata \"aws_eks_cluster_auth\" \"this\" {\n  name = module.eks.cluster_name\n}\n\nprovider \"kubernetes\" {\n  host                   = data.aws_eks_cluster.this.endpoint\n  cluster_ca_certificate = base64decode(data.aws_eks_cluster.this.certificate_authority[0].data)\n  token                  = data.aws_eks_cluster_auth.this.token\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = data.aws_eks_cluster.this.endpoint\n    cluster_ca_certificate = base64decode(data.aws_eks_cluster.this.certificate_authority[0].data)\n    token                  = data.aws_eks_cluster_auth.this.token\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"project_name\" {\n  description = \"Project/name prefix used for resources.\"\n  type        = string\n  default     = \"magic-color\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod).\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"aws_region\" {\n  description = \"AWS region.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"VPC CIDR.\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use (2 or 3).\"\n  type        = number\n  default     = 2\n  validation {\n    condition     = var.az_count >= 2 && var.az_count <= 3\n    error_message = \"az_count must be 2 or 3.\"\n  }\n}\n\nvariable \"cluster_version\" {\n  description = \"EKS Kubernetes version.\"\n  type        = string\n  default     = \"1.29\"\n}\n\nvariable \"node_instance_types\" {\n  description = \"Instance types for the managed node group.\"\n  type        = list(string)\n  default     = [\"t3.medium\"]\n}\n\nvariable \"node_desired_size\" {\n  description = \"Desired node count.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_min_size\" {\n  description = \"Minimum node count.\"\n  type        = number\n  default     = 1\n}\n\nvariable \"node_max_size\" {\n  description = \"Maximum node count.\"\n  type        = number\n  default     = 4\n}\n\nvariable \"app_namespace\" {\n  description = \"Kubernetes namespace for the app.\"\n  type        = string\n  default     = \"magic-color\"\n}\n\nvariable \"app_image\" {\n  description = \"Container image for the app (e.g., ECR/GHCR/DockerHub).\"\n  type        = string\n  default     = \"yash5090/magic-color:latest\"\n}\n\nvariable \"app_replicas\" {\n  description = \"Number of replicas for the app deployment.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"app_container_port\" {\n  description = \"Container port exposed by nginx.\"\n  type        = number\n  default     = 80\n}\n\nvariable \"enable_aws_load_balancer_controller\" {\n  description = \"Install AWS Load Balancer Controller via Helm.\"\n  type        = bool\n  default     = true\n}\n\nvariable \"tags\" {\n  description = \"Additional tags to apply to AWS resources.\"\n  type        = map(string)\n  default     = {}\n}\n"
    },
    {
      "name": "main.tf",
      "content": "locals {\n  name = \"${var.project_name}-${var.environment}\"\n}\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n}\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = var.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 4, i)]\n  public_subnets  = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 4, i + 8)]\n\n  enable_nat_gateway     = true\n  single_nat_gateway     = true\n  one_nat_gateway_per_az = false\n\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = \"1\"\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = \"1\"\n  }\n}\n\nmodule \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 20.0\"\n\n  cluster_name    = local.name\n  cluster_version = var.cluster_version\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  cluster_endpoint_public_access  = true\n  cluster_endpoint_private_access = true\n\n  enable_cluster_creator_admin_permissions = true\n\n  cluster_enabled_log_types = [\n    \"api\",\n    \"audit\",\n    \"authenticator\",\n    \"controllerManager\",\n    \"scheduler\",\n  ]\n\n  cluster_addons = {\n    coredns = {}\n    kube-proxy = {}\n    vpc-cni = {\n      most_recent = true\n    }\n  }\n\n  eks_managed_node_groups = {\n    default = {\n      name            = \"default\"\n      instance_types  = var.node_instance_types\n      min_size        = var.node_min_size\n      max_size        = var.node_max_size\n      desired_size    = var.node_desired_size\n      subnet_ids      = module.vpc.private_subnets\n      capacity_type   = \"ON_DEMAND\"\n\n      iam_role_additional_policies = {\n        AmazonSSMManagedInstanceCore = \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n      }\n    }\n  }\n}\n\n# IAM role for AWS Load Balancer Controller (IRSA)\nmodule \"lb_controller_irsa\" {\n  source  = \"terraform-aws-modules/iam/aws//modules/iam-role-for-service-accounts-eks\"\n  version = \"~> 5.0\"\n\n  create_role = var.enable_aws_load_balancer_controller\n\n  role_name                              = \"${local.name}-aws-load-balancer-controller\"\n  attach_load_balancer_controller_policy = true\n\n  oidc_providers = {\n    main = {\n      provider_arn               = module.eks.oidc_provider_arn\n      namespace_service_accounts = [\"kube-system:aws-load-balancer-controller\"]\n    }\n  }\n}\n\nresource \"helm_release\" \"aws_load_balancer_controller\" {\n  count = var.enable_aws_load_balancer_controller ? 1 : 0\n\n  name       = \"aws-load-balancer-controller\"\n  repository = \"https://aws.github.io/eks-charts\"\n  chart      = \"aws-load-balancer-controller\"\n  namespace  = \"kube-system\"\n\n  set {\n    name  = \"clusterName\"\n    value = module.eks.cluster_name\n  }\n\n  set {\n    name  = \"serviceAccount.create\"\n    value = \"true\"\n  }\n\n  set {\n    name  = \"serviceAccount.name\"\n    value = \"aws-load-balancer-controller\"\n  }\n\n  set {\n    name  = \"serviceAccount.annotations.eks\\\\.amazonaws\\\\.com/role-arn\"\n    value = module.lb_controller_irsa.iam_role_arn\n  }\n\n  set {\n    name  = \"region\"\n    value = var.aws_region\n  }\n\n  set {\n    name  = \"vpcId\"\n    value = module.vpc.vpc_id\n  }\n\n  depends_on = [module.eks]\n}\n"
    },
    {
      "name": "kubernetes_app.tf",
      "content": "resource \"kubernetes_namespace\" \"app\" {\n  metadata {\n    name = var.app_namespace\n    labels = {\n      app = var.project_name\n    }\n  }\n}\n\nresource \"kubernetes_deployment\" \"app\" {\n  metadata {\n    name      = \"magic-color-deployment\"\n    namespace = kubernetes_namespace.app.metadata[0].name\n    labels = {\n      app = \"magic-color\"\n    }\n  }\n\n  spec {\n    replicas = var.app_replicas\n\n    selector {\n      match_labels = {\n        app = \"magic-color\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"magic-color\"\n        }\n      }\n\n      spec {\n        container {\n          name  = \"magic-color\"\n          image = var.app_image\n\n          port {\n            container_port = var.app_container_port\n          }\n\n          resources {\n            requests = {\n              cpu    = \"50m\"\n              memory = \"64Mi\"\n            }\n            limits = {\n              cpu    = \"250m\"\n              memory = \"256Mi\"\n            }\n          }\n\n          liveness_probe {\n            http_get {\n              path = \"/\"\n              port = var.app_container_port\n            }\n            initial_delay_seconds = 10\n            period_seconds        = 10\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/\"\n              port = var.app_container_port\n            }\n            initial_delay_seconds = 5\n            period_seconds        = 5\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [module.eks]\n}\n\n# Service type LoadBalancer. With AWS Load Balancer Controller installed, annotations can\n# influence ALB/NLB behavior. This keeps it minimal and compatible.\nresource \"kubernetes_service\" \"app\" {\n  metadata {\n    name      = \"magic-color-service\"\n    namespace = kubernetes_namespace.app.metadata[0].name\n\n    labels = {\n      app = \"magic-color\"\n    }\n\n    annotations = {\n      # Use AWS Load Balancer Controller (if installed) and create an internet-facing LB.\n      \"service.beta.kubernetes.io/aws-load-balancer-scheme\" = \"internet-facing\"\n\n      # If you want NLB instead of classic, uncomment:\n      # \"service.beta.kubernetes.io/aws-load-balancer-type\" = \"nlb\"\n    }\n  }\n\n  spec {\n    selector = {\n      app = kubernetes_deployment.app.metadata[0].labels.app\n    }\n\n    port {\n      name        = \"http\"\n      port        = 80\n      target_port = var.app_container_port\n      protocol    = \"TCP\"\n    }\n\n    type = \"LoadBalancer\"\n  }\n\n  depends_on = [kubernetes_deployment.app]\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  value       = module.vpc.vpc_id\n  description = \"VPC ID.\"\n}\n\noutput \"eks_cluster_name\" {\n  value       = module.eks.cluster_name\n  description = \"EKS cluster name.\"\n}\n\noutput \"eks_cluster_endpoint\" {\n  value       = module.eks.cluster_endpoint\n  description = \"EKS cluster API endpoint.\"\n}\n\noutput \"app_service_hostname\" {\n  description = \"External hostname for the Kubernetes Service (once provisioned).\"\n  value       = try(kubernetes_service.app.status[0].load_balancer[0].ingress[0].hostname, null)\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region   = \"us-east-1\"\nproject_name = \"magic-color\"\nenvironment  = \"dev\"\n\n# Image can be DockerHub/GHCR/ECR\napp_image = \"yash5090/magic-color:latest\"\n"
    },
    {
      "name": "README.md",
      "content": "# Magic Color - Terraform (EKS + LoadBalancer Service)\n\nThis Terraform provisions:\n- VPC (public/private subnets + NAT)\n- EKS cluster + managed node group\n- (Optional) AWS Load Balancer Controller via Helm\n- Kubernetes namespace, deployment, and a Service type `LoadBalancer`\n\n## Usage\n\n```bash\ncd ai_tf\nterraform init\nterraform validate\nterraform plan\n```\n\nAfter apply, the service hostname is available as output `app_service_hostname`.\n\n> Note: For production, prefer an Ingress + ACM + Route53. This repo keeps it minimal and matches the existing Service type LoadBalancer pattern.\n"
    }
  ]
}