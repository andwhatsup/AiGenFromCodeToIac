{
  "files": [
    {
      "name": "provider.tf",
      "content": "terraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 6.27\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Project     = var.project_name\n      Environment = var.environment\n      ManagedBy   = \"terraform\"\n    }\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"project_name\" {\n  description = \"Project/name prefix used for tagging and resource names.\"\n  type        = string\n  default     = \"portfolio\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod).\"\n  type        = string\n  default     = \"prod\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for the VPC.\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"Public subnet CIDRs (2 AZs recommended).\"\n  type        = list(string)\n  default     = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type for the Docker host.\"\n  type        = string\n  default     = \"t3.micro\"\n}\n\nvariable \"ssh_public_key\" {\n  description = \"Public key material to create an EC2 key pair (optional). If empty, no key pair is created and SSH access is disabled unless you attach a key manually.\"\n  type        = string\n  default     = \"\"\n  sensitive   = true\n}\n\nvariable \"ssh_allowed_cidrs\" {\n  description = \"CIDR allowlist for inbound SSH (22). Keep this tight (e.g., your office/VPN or GitLab runner egress IPs).\"\n  type        = list(string)\n  default     = []\n}\n\nvariable \"enable_https\" {\n  description = \"If true, create an ACM certificate and HTTPS listener on the ALB. Requires a public Route53 hosted zone and a domain name.\"\n  type        = bool\n  default     = false\n}\n\nvariable \"domain_name\" {\n  description = \"Fully qualified domain name to serve (e.g., projects.example.com). Required if enable_https=true or if you want Route53 record.\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"hosted_zone_id\" {\n  description = \"Route53 hosted zone ID for domain_name. Required if enable_https=true or if you want Route53 record.\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"container_image\" {\n  description = \"Container image to run on the EC2 host (e.g., registry.gitlab.com/<group>/<project>/<image>:tag).\"\n  type        = string\n  default     = \"registry.gitlab.com/dmitry1094608/dmitryportfolio/portfolioimage:main\"\n}\n\nvariable \"container_name\" {\n  description = \"Docker container name.\"\n  type        = string\n  default     = \"portfolio-nginx\"\n}\n\nvariable \"container_port_http\" {\n  description = \"Container port for HTTP.\"\n  type        = number\n  default     = 80\n}\n\nvariable \"container_port_https\" {\n  description = \"Container port for HTTPS.\"\n  type        = number\n  default     = 443\n}\n\nvariable \"enable_cloudwatch_logs\" {\n  description = \"If true, install and configure the CloudWatch Agent to ship /var/log/messages and docker logs (basic).\"\n  type        = bool\n  default     = false\n}\n"
    },
    {
      "name": "main.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  name_prefix = \"${var.project_name}-${var.environment}\"\n  azs         = slice(data.aws_availability_zones.available.names, 0, length(var.public_subnet_cidrs))\n\n  create_key_pair = length(trimspace(var.ssh_public_key)) > 0\n  create_r53      = length(trimspace(var.domain_name)) > 0 && length(trimspace(var.hosted_zone_id)) > 0\n}\n\n# -----------------------------\n# Networking (VPC + public subnets)\n# -----------------------------\nresource \"aws_vpc\" \"this\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"${local.name_prefix}-vpc\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"this\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name_prefix}-igw\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  for_each = { for idx, cidr in var.public_subnet_cidrs : idx => cidr }\n\n  vpc_id                  = aws_vpc.this.id\n  cidr_block              = each.value\n  availability_zone       = local.azs[tonumber(each.key)]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"${local.name_prefix}-public-${each.key}\"\n    Tier = \"public\"\n  }\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.this.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.this.id\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-public-rt\"\n  }\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  for_each = aws_subnet.public\n\n  subnet_id      = each.value.id\n  route_table_id = aws_route_table.public.id\n}\n\n# -----------------------------\n# Security Groups\n# -----------------------------\nresource \"aws_security_group\" \"alb\" {\n  name        = \"${local.name_prefix}-alb-sg\"\n  description = \"ALB ingress\"\n  vpc_id      = aws_vpc.this.id\n\n  ingress {\n    description = \"HTTP\"\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  dynamic \"ingress\" {\n    for_each = var.enable_https ? [1] : []\n    content {\n      description = \"HTTPS\"\n      from_port   = 443\n      to_port     = 443\n      protocol    = \"tcp\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n    }\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-alb-sg\"\n  }\n}\n\nresource \"aws_security_group\" \"ec2\" {\n  name        = \"${local.name_prefix}-ec2-sg\"\n  description = \"EC2 Docker host\"\n  vpc_id      = aws_vpc.this.id\n\n  # Only allow web traffic from the ALB\n  ingress {\n    description     = \"HTTP from ALB\"\n    from_port       = 80\n    to_port         = 80\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.alb.id]\n  }\n\n  # Optional: allow SSH from allowlisted CIDRs\n  dynamic \"ingress\" {\n    for_each = length(var.ssh_allowed_cidrs) > 0 ? [1] : []\n    content {\n      description = \"SSH\"\n      from_port   = 22\n      to_port     = 22\n      protocol    = \"tcp\"\n      cidr_blocks = var.ssh_allowed_cidrs\n    }\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-ec2-sg\"\n  }\n}\n\n# -----------------------------\n# IAM for EC2 (SSM + optional CloudWatch)\n# -----------------------------\ndata \"aws_iam_policy_document\" \"ec2_assume\" {\n  statement {\n    effect = \"Allow\"\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ec2.amazonaws.com\"]\n    }\n\n    actions = [\"sts:AssumeRole\"]\n  }\n}\n\nresource \"aws_iam_role\" \"ec2\" {\n  name               = \"${local.name_prefix}-ec2-role\"\n  assume_role_policy = data.aws_iam_policy_document.ec2_assume.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ssm\" {\n  role       = aws_iam_role.ec2.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"cw_agent\" {\n  count      = var.enable_cloudwatch_logs ? 1 : 0\n  role       = aws_iam_role.ec2.name\n  policy_arn = \"arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy\"\n}\n\nresource \"aws_iam_instance_profile\" \"ec2\" {\n  name = \"${local.name_prefix}-ec2-profile\"\n  role = aws_iam_role.ec2.name\n}\n\n# -----------------------------\n# Optional EC2 key pair\n# -----------------------------\nresource \"aws_key_pair\" \"this\" {\n  count      = local.create_key_pair ? 1 : 0\n  key_name   = \"${local.name_prefix}-key\"\n  public_key = var.ssh_public_key\n}\n\n# -----------------------------\n# EC2 instance (Docker host)\n# -----------------------------\ndata \"aws_ami\" \"al2023\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"al2023-ami-*-x86_64\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\nresource \"aws_instance\" \"docker_host\" {\n  ami                         = data.aws_ami.al2023.id\n  instance_type               = var.instance_type\n  subnet_id                   = values(aws_subnet.public)[0].id\n  vpc_security_group_ids      = [aws_security_group.ec2.id]\n  associate_public_ip_address = true\n  iam_instance_profile        = aws_iam_instance_profile.ec2.name\n\n  key_name = local.create_key_pair ? aws_key_pair.this[0].key_name : null\n\n  user_data = templatefile(\"${path.module}/user_data.sh.tftpl\", {\n    container_image      = var.container_image\n    container_name       = var.container_name\n    container_port_http  = var.container_port_http\n    container_port_https = var.container_port_https\n    enable_cw_logs       = var.enable_cloudwatch_logs\n    region               = var.aws_region\n    log_group_name       = \"/${var.project_name}/${var.environment}/ec2\"\n  })\n\n  metadata_options {\n    http_endpoint = \"enabled\"\n    http_tokens   = \"required\"\n  }\n\n  root_block_device {\n    encrypted   = true\n    volume_type = \"gp3\"\n    volume_size = 10\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-docker-host\"\n  }\n}\n\n# -----------------------------\n# ALB + Target Group + Listeners\n# -----------------------------\nresource \"aws_lb\" \"this\" {\n  name               = substr(replace(\"${local.name_prefix}-alb\", \"_\", \"-\"), 0, 32)\n  load_balancer_type = \"application\"\n  internal           = false\n  security_groups    = [aws_security_group.alb.id]\n  subnets            = [for s in aws_subnet.public : s.id]\n\n  drop_invalid_header_fields = true\n\n  tags = {\n    Name = \"${local.name_prefix}-alb\"\n  }\n}\n\nresource \"aws_lb_target_group\" \"http\" {\n  name        = substr(replace(\"${local.name_prefix}-tg\", \"_\", \"-\"), 0, 32)\n  port        = 80\n  protocol    = \"HTTP\"\n  vpc_id      = aws_vpc.this.id\n  target_type = \"instance\"\n\n  health_check {\n    enabled             = true\n    path                = \"/\"\n    matcher             = \"200-399\"\n    interval            = 30\n    timeout             = 5\n    healthy_threshold   = 2\n    unhealthy_threshold = 2\n  }\n\n  tags = {\n    Name = \"${local.name_prefix}-tg\"\n  }\n}\n\nresource \"aws_lb_target_group_attachment\" \"ec2\" {\n  target_group_arn = aws_lb_target_group.http.arn\n  target_id        = aws_instance.docker_host.id\n  port             = 80\n}\n\nresource \"aws_lb_listener\" \"http\" {\n  load_balancer_arn = aws_lb.this.arn\n  port              = 80\n  protocol          = \"HTTP\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.http.arn\n  }\n}\n\n# Optional HTTPS (ACM + listener)\nresource \"aws_acm_certificate\" \"this\" {\n  count             = var.enable_https ? 1 : 0\n  domain_name       = var.domain_name\n  validation_method = \"DNS\"\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_route53_record\" \"acm_validation\" {\n  for_each = var.enable_https ? {\n    for dvo in aws_acm_certificate.this[0].domain_validation_options : dvo.domain_name => {\n      name   = dvo.resource_record_name\n      record = dvo.resource_record_value\n      type   = dvo.resource_record_type\n    }\n  } : {}\n\n  zone_id = var.hosted_zone_id\n  name    = each.value.name\n  type    = each.value.type\n  ttl     = 60\n  records = [each.value.record]\n}\n\nresource \"aws_acm_certificate_validation\" \"this\" {\n  count                   = var.enable_https ? 1 : 0\n  certificate_arn         = aws_acm_certificate.this[0].arn\n  validation_record_fqdns = [for r in aws_route53_record.acm_validation : r.fqdn]\n}\n\nresource \"aws_lb_listener\" \"https\" {\n  count             = var.enable_https ? 1 : 0\n  load_balancer_arn = aws_lb.this.arn\n  port              = 443\n  protocol          = \"HTTPS\"\n  ssl_policy        = \"ELBSecurityPolicy-TLS13-1-2-2021-06\"\n  certificate_arn   = aws_acm_certificate_validation.this[0].certificate_arn\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.http.arn\n  }\n}\n\n# Optional Route53 record to ALB\nresource \"aws_route53_record\" \"app\" {\n  count   = local.create_r53 ? 1 : 0\n  zone_id = var.hosted_zone_id\n  name    = var.domain_name\n  type    = \"A\"\n\n  alias {\n    name                   = aws_lb.this.dns_name\n    zone_id                = aws_lb.this.zone_id\n    evaluate_target_health = true\n  }\n}\n"
    },
    {
      "name": "user_data.sh.tftpl",
      "content": "#!/bin/bash\nset -euo pipefail\n\n# Basic hardening\ndnf -y update\n\n# Install Docker\ndnf -y install docker\nsystemctl enable docker\nsystemctl start docker\n\n# Allow ec2-user to run docker without sudo (optional)\nusermod -aG docker ec2-user || true\n\n# Install SSM agent (AL2023 usually has it, but ensure)\ndnf -y install amazon-ssm-agent || true\nsystemctl enable amazon-ssm-agent\nsystemctl restart amazon-ssm-agent || true\n\n%{ if enable_cw_logs }\n# Optional: CloudWatch Agent (basic)\ndnf -y install amazon-cloudwatch-agent || true\ncat >/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json <<'CWCFG'\n{\n  \"agent\": {\"metrics_collection_interval\": 60, \"run_as_user\": \"root\"},\n  \"logs\": {\n    \"logs_collected\": {\n      \"files\": {\n        \"collect_list\": [\n          {\"file_path\": \"/var/log/messages\", \"log_group_name\": \"${log_group_name}\", \"log_stream_name\": \"{instance_id}/messages\"}\n        ]\n      }\n    }\n  }\n}\nCWCFG\n/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json -s\n%{ endif }\n\n# Run container (GitLab CI can still redeploy by pulling a new tag and restarting)\n# Stop/remove existing container if present\nif docker ps -a --format '{{.Names}}' | grep -q '^${container_name}$'; then\n  docker rm -f ${container_name} || true\nfi\n\n# Pull and run\n# NOTE: If your registry requires auth, GitLab CI deploy step should run `docker login` first.\ndocker pull ${container_image} || true\n\ndocker run -d \\\n  --name ${container_name} \\\n  --restart unless-stopped \\\n  -p 80:${container_port_http} \\\n  -p 443:${container_port_https} \\\n  ${container_image}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  value       = aws_vpc.this.id\n  description = \"VPC ID.\"\n}\n\noutput \"public_subnet_ids\" {\n  value       = [for s in aws_subnet.public : s.id]\n  description = \"Public subnet IDs.\"\n}\n\noutput \"ec2_instance_id\" {\n  value       = aws_instance.docker_host.id\n  description = \"EC2 instance ID for the Docker host.\"\n}\n\noutput \"ec2_public_ip\" {\n  value       = aws_instance.docker_host.public_ip\n  description = \"EC2 public IP (useful for SSH if enabled).\"\n}\n\noutput \"alb_dns_name\" {\n  value       = aws_lb.this.dns_name\n  description = \"ALB DNS name.\"\n}\n\noutput \"site_url\" {\n  value = var.enable_https && length(trimspace(var.domain_name)) > 0 ? \"https://${var.domain_name}\" : \"http://${aws_lb.this.dns_name}\"\n}\n"
    },
    {
      "name": "terraform.tfvars.example",
      "content": "aws_region    = \"us-east-1\"\nproject_name  = \"portfolio\"\nenvironment   = \"prod\"\n\n# Tighten this to your IP(s) or GitLab runner egress IP(s)\nssh_allowed_cidrs = [\"203.0.113.10/32\"]\n\n# Optional: provide a public key to create a key pair\n# ssh_public_key = \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAI... you@example\"\n\n# Image built by GitLab CI\ncontainer_image = \"registry.gitlab.com/dmitry1094608/dmitryportfolio/portfolioimage:main\"\n\n# Optional HTTPS + DNS\n# enable_https  = true\n# domain_name   = \"projects.example.com\"\n# hosted_zone_id = \"Z1234567890ABCDEFG\"\n"
    },
    {
      "name": "README_TERRAFORM.md",
      "content": "## Terraform (AWS) - Nginx static site on Docker/EC2 behind an ALB\n\n### What this provisions\n- VPC with 2 public subnets\n- Internet Gateway + public route table\n- Security groups:\n  - ALB: 80 (and 443 if enabled)\n  - EC2: 80 from ALB; optional 22 from allowlisted CIDRs\n- EC2 instance (Amazon Linux 2023) with Docker installed via user-data\n- Application Load Balancer forwarding to the EC2 instance\n- Optional: ACM + Route53 record for HTTPS\n- EC2 IAM role with SSM enabled (Session Manager)\n\n### How GitLab CI deploy fits\nYour `.gitlab-ci.yml` deploy job SSHes to the instance and runs `docker login`, `docker pull`, and `docker run`.\nThis Terraform keeps that model, but also runs the container once at boot (user-data) so the instance is functional immediately.\n\n### Usage\n1) Copy tfvars example:\n```bash\ncp terraform.tfvars.example terraform.tfvars\n```\n2) Edit `terraform.tfvars` (especially `ssh_allowed_cidrs` and `container_image`).\n\n3) Run:\n```bash\nterraform init\nterraform validate\nterraform plan\n```\n\n### Notes\n- If you enable HTTPS, you must set `domain_name` and `hosted_zone_id` for DNS validation.\n- For better security, consider removing SSH entirely and switching GitLab deploy to AWS SSM (Session Manager) or a runner inside your VPC.\n"
    }
  ]
}