{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.5.7\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \">= 6.28.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \">= 3.0.1\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \">= 3.1.1\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = var.tags\n  }\n}\n\n# These providers are configured after the EKS cluster is created.\nprovider \"kubernetes\" {\n  host                   = module.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n  token                  = data.aws_eks_cluster_auth.this.token\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n    token                  = data.aws_eks_cluster_auth.this.token\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into\"\n  type        = string\n  default     = \"us-west-1\"\n}\n\nvariable \"name\" {\n  description = \"Base name/prefix for resources\"\n  type        = string\n  default     = \"react-eks\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR for the VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use\"\n  type        = number\n  default     = 2\n}\n\nvariable \"single_nat_gateway\" {\n  description = \"Use a single NAT gateway (cheaper) instead of one per AZ\"\n  type        = bool\n  default     = true\n}\n\nvariable \"cluster_version\" {\n  description = \"EKS Kubernetes version (major.minor)\"\n  type        = string\n  default     = \"1.31\"\n}\n\nvariable \"cluster_endpoint_public_access\" {\n  description = \"Whether the EKS API endpoint is publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"cluster_endpoint_public_access_cidrs\" {\n  description = \"Allowed CIDRs for public EKS API endpoint (only used if public access enabled)\"\n  type        = list(string)\n  default     = [\"0.0.0.0/0\"]\n}\n\nvariable \"node_instance_types\" {\n  description = \"Instance types for EKS managed node group\"\n  type        = list(string)\n  default     = [\"t3.medium\"]\n}\n\nvariable \"node_min_size\" {\n  type    = number\n  default = 1\n}\n\nvariable \"node_max_size\" {\n  type    = number\n  default = 3\n}\n\nvariable \"node_desired_size\" {\n  type    = number\n  default = 1\n}\n\nvariable \"app_namespace\" {\n  description = \"Kubernetes namespace for the React app\"\n  type        = string\n  default     = \"react-app\"\n}\n\nvariable \"app_name\" {\n  description = \"Kubernetes app name\"\n  type        = string\n  default     = \"react-aws-eks-github-actions\"\n}\n\nvariable \"app_image\" {\n  description = \"Container image for the React app\"\n  type        = string\n  default     = \"codewithmuh/react-aws-eks-github-actions:latest\"\n}\n\nvariable \"app_replicas\" {\n  description = \"Number of replicas for the React app\"\n  type        = number\n  default     = 1\n}\n\nvariable \"tags\" {\n  description = \"Tags applied to all AWS resources\"\n  type        = map(string)\n  default = {\n    Project = \"react-aws-eks-github-actions\"\n    Managed = \"terraform\"\n  }\n}\n\n# Optional: create a self-hosted GitHub Actions runner EC2 instance.\nvariable \"create_runner\" {\n  description = \"Whether to create an EC2 instance intended to host a self-hosted GitHub Actions runner\"\n  type        = bool\n  default     = false\n}\n\nvariable \"runner_instance_type\" {\n  description = \"EC2 instance type for the runner\"\n  type        = string\n  default     = \"t3.medium\"\n}\n\nvariable \"runner_key_name\" {\n  description = \"Optional EC2 key pair name (leave null to use SSM only)\"\n  type        = string\n  default     = null\n}\n\nvariable \"runner_allowed_ssh_cidrs\" {\n  description = \"If runner_key_name is set, allow SSH from these CIDRs\"\n  type        = list(string)\n  default     = []\n}\n\nvariable \"github_repo_url\" {\n  description = \"GitHub repository URL for the runner registration (used in user_data)\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"github_runner_token\" {\n  description = \"GitHub runner registration token (sensitive). Prefer SSM/Secrets Manager in real deployments.\"\n  type        = string\n  sensitive   = true\n  default     = \"\"\n}\n\nvariable \"sonarqube_host_url\" {\n  description = \"Optional SonarQube URL (used by runner tooling; not provisioned here)\"\n  type        = string\n  default     = \"\"\n}\n"
    },
    {
      "name": "data.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_partition\" \"current\" {}\n\n# Used by kubernetes/helm providers\ndata \"aws_eks_cluster_auth\" \"this\" {\n  name = module.eks.cluster_name\n}\n\n# Ubuntu 22.04 AMI for runner\ndata \"aws_ami\" \"ubuntu_2204\" {\n  most_recent = true\n  owners      = [\"099720109477\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n"
    },
    {
      "name": "network.tf",
      "content": "locals {\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n\n  # /16 -> create /24s\n  public_subnets  = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 8, i)]\n  private_subnets = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 8, i + 10)]\n}\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"6.6.0\"\n\n  name = var.name\n  cidr = var.vpc_cidr\n\n  azs             = local.azs\n  public_subnets  = local.public_subnets\n  private_subnets = local.private_subnets\n\n  enable_nat_gateway = true\n  single_nat_gateway = var.single_nat_gateway\n\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  # Required tags for EKS\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\"            = \"1\"\n    \"kubernetes.io/cluster/${var.name}\" = \"shared\"\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\"   = \"1\"\n    \"kubernetes.io/cluster/${var.name}\" = \"shared\"\n  }\n}\n"
    },
    {
      "name": "eks.tf",
      "content": "module \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"21.15.1\"\n\n  name               = var.name\n  kubernetes_version = var.cluster_version\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  endpoint_private_access = true\n  endpoint_public_access  = var.cluster_endpoint_public_access\n  endpoint_public_access_cidrs = var.cluster_endpoint_public_access ? var.cluster_endpoint_public_access_cidrs : null\n\n  enable_irsa = true\n\n  # Keep logs lean but useful\n  enabled_log_types = [\"api\", \"audit\", \"authenticator\"]\n\n  eks_managed_node_groups = {\n    default = {\n      name           = \"default\"\n      instance_types = var.node_instance_types\n\n      min_size     = var.node_min_size\n      max_size     = var.node_max_size\n      desired_size = var.node_desired_size\n\n      subnet_ids = module.vpc.private_subnets\n\n      # Security hardening\n      metadata_options = {\n        http_endpoint               = \"enabled\"\n        http_tokens                 = \"required\"\n        http_put_response_hop_limit = 2\n      }\n\n      block_device_mappings = {\n        root = {\n          device_name = \"/dev/xvda\"\n          ebs = {\n            volume_size = 30\n            volume_type = \"gp3\"\n            encrypted   = true\n          }\n        }\n      }\n    }\n  }\n\n  tags = var.tags\n}\n"
    },
    {
      "name": "ecr.tf",
      "content": "resource \"aws_ecr_repository\" \"app\" {\n  name                 = var.app_name\n  image_tag_mutability = \"MUTABLE\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n\n  encryption_configuration {\n    encryption_type = \"AES256\"\n  }\n\n  tags = var.tags\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"app\" {\n  repository = aws_ecr_repository.app.name\n\n  policy = jsonencode({\n    rules = [\n      {\n        rulePriority = 1\n        description  = \"Expire untagged images older than 14 days\"\n        selection = {\n          tagStatus   = \"untagged\"\n          countType   = \"sinceImagePushed\"\n          countUnit   = \"days\"\n          countNumber = 14\n        }\n        action = {\n          type = \"expire\"\n        }\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "k8s_app.tf",
      "content": "resource \"kubernetes_namespace_v1\" \"app\" {\n  metadata {\n    name = var.app_namespace\n  }\n}\n\nresource \"kubernetes_deployment_v1\" \"app\" {\n  metadata {\n    name      = var.app_name\n    namespace = kubernetes_namespace_v1.app.metadata[0].name\n    labels = {\n      app = var.app_name\n    }\n  }\n\n  spec {\n    replicas = var.app_replicas\n\n    selector {\n      match_labels = {\n        app = var.app_name\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = var.app_name\n        }\n      }\n\n      spec {\n        container {\n          name  = var.app_name\n          image = var.app_image\n\n          port {\n            container_port = 3000\n          }\n\n          resources {\n            requests = {\n              cpu    = \"100m\"\n              memory = \"128Mi\"\n            }\n            limits = {\n              cpu    = \"500m\"\n              memory = \"512Mi\"\n            }\n          }\n\n          liveness_probe {\n            http_get {\n              path = \"/\"\n              port = 3000\n            }\n            initial_delay_seconds = 30\n            period_seconds        = 10\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/\"\n              port = 3000\n            }\n            initial_delay_seconds = 10\n            period_seconds        = 5\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [module.eks]\n}\n\nresource \"kubernetes_service_v1\" \"app\" {\n  metadata {\n    name      = \"${var.app_name}-service\"\n    namespace = kubernetes_namespace_v1.app.metadata[0].name\n    labels = {\n      app = var.app_name\n    }\n  }\n\n  spec {\n    selector = {\n      app = var.app_name\n    }\n\n    port {\n      port        = 80\n      target_port = 3000\n      protocol    = \"TCP\"\n    }\n\n    type = \"LoadBalancer\"\n  }\n\n  depends_on = [kubernetes_deployment_v1.app]\n}\n"
    },
    {
      "name": "runner.tf",
      "content": "# Optional self-hosted GitHub Actions runner instance.\n# This is intentionally minimal and uses SSM (no inbound SSH required).\n\nresource \"aws_security_group\" \"runner\" {\n  count = var.create_runner ? 1 : 0\n\n  name        = \"${var.name}-runner\"\n  description = \"Security group for GitHub Actions runner\"\n  vpc_id      = module.vpc.vpc_id\n\n  # No inbound by default\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = var.tags\n}\n\nresource \"aws_security_group_rule\" \"runner_ssh\" {\n  count = var.create_runner && var.runner_key_name != null && length(var.runner_allowed_ssh_cidrs) > 0 ? 1 : 0\n\n  type              = \"ingress\"\n  from_port         = 22\n  to_port           = 22\n  protocol          = \"tcp\"\n  cidr_blocks       = var.runner_allowed_ssh_cidrs\n  security_group_id = aws_security_group.runner[0].id\n  description       = \"Optional SSH access\"\n}\n\ndata \"aws_iam_policy_document\" \"runner_assume\" {\n  statement {\n    effect = \"Allow\"\n    actions = [\n      \"sts:AssumeRole\",\n    ]\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ec2.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"runner\" {\n  count              = var.create_runner ? 1 : 0\n  name_prefix        = \"${var.name}-runner-\"\n  assume_role_policy = data.aws_iam_policy_document.runner_assume.json\n  tags               = var.tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"runner_ssm\" {\n  count      = var.create_runner ? 1 : 0\n  role       = aws_iam_role.runner[0].name\n  policy_arn = \"arn:${data.aws_partition.current.partition}:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"runner_ecr_power\" {\n  count      = var.create_runner ? 1 : 0\n  role       = aws_iam_role.runner[0].name\n  policy_arn = \"arn:${data.aws_partition.current.partition}:iam::aws:policy/AmazonEC2ContainerRegistryPowerUser\"\n}\n\nresource \"aws_iam_instance_profile\" \"runner\" {\n  count = var.create_runner ? 1 : 0\n  name_prefix = \"${var.name}-runner-\"\n  role        = aws_iam_role.runner[0].name\n}\n\nresource \"aws_instance\" \"runner\" {\n  count = var.create_runner ? 1 : 0\n\n  ami           = data.aws_ami.ubuntu_2204.id\n  instance_type = var.runner_instance_type\n\n  subnet_id              = module.vpc.private_subnets[0]\n  vpc_security_group_ids = [aws_security_group.runner[0].id]\n\n  iam_instance_profile = aws_iam_instance_profile.runner[0].name\n  key_name             = var.runner_key_name\n\n  metadata_options {\n    http_endpoint               = \"enabled\"\n    http_tokens                 = \"required\"\n    http_put_response_hop_limit = 2\n  }\n\n  root_block_device {\n    encrypted   = true\n    volume_type = \"gp3\"\n    volume_size = 50\n  }\n\n  user_data = <<-EOF\n    #!/bin/bash\n    set -euo pipefail\n\n    apt-get update -y\n    apt-get install -y ca-certificates curl unzip jq\n\n    # Install Docker\n    apt-get install -y docker.io\n    usermod -aG docker ubuntu || true\n\n    # Install AWS CLI v2\n    curl -sS \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n    unzip -q awscliv2.zip\n    ./aws/install\n\n    # Install kubectl\n    curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n    install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n    # Install Node.js 18 (for CRA tooling if needed)\n    curl -fsSL https://deb.nodesource.com/setup_18.x | bash -\n    apt-get install -y nodejs\n\n    # Install Java 17 (Sonar scanner may require)\n    apt-get install -y openjdk-17-jre-headless\n\n    # GitHub Actions runner install (requires repo URL + token)\n    if [ -n \"${var.github_repo_url}\" ] && [ -n \"${var.github_runner_token}\" ]; then\n      mkdir -p /opt/actions-runner\n      cd /opt/actions-runner\n\n      RUNNER_VERSION=\"2.311.0\"\n      curl -L -o actions-runner-linux-x64-$RUNNER_VERSION.tar.gz https://github.com/actions/runner/releases/download/v$RUNNER_VERSION/actions-runner-linux-x64-$RUNNER_VERSION.tar.gz\n      tar xzf actions-runner-linux-x64-$RUNNER_VERSION.tar.gz\n\n      ./config.sh --unattended --url \"${var.github_repo_url}\" --token \"${var.github_runner_token}\" --name \"${var.name}-runner\" --labels \"self-hosted,aws\" --work \"/opt/actions-runner/_work\"\n\n      ./svc.sh install\n      ./svc.sh start\n    fi\n  EOF\n\n  tags = merge(var.tags, { Name = \"${var.name}-runner\" })\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  value       = module.vpc.vpc_id\n  description = \"VPC ID\"\n}\n\noutput \"private_subnet_ids\" {\n  value       = module.vpc.private_subnets\n  description = \"Private subnet IDs\"\n}\n\noutput \"public_subnet_ids\" {\n  value       = module.vpc.public_subnets\n  description = \"Public subnet IDs\"\n}\n\noutput \"eks_cluster_name\" {\n  value       = module.eks.cluster_name\n  description = \"EKS cluster name\"\n}\n\noutput \"eks_cluster_endpoint\" {\n  value       = module.eks.cluster_endpoint\n  description = \"EKS cluster endpoint\"\n}\n\noutput \"ecr_repository_url\" {\n  value       = aws_ecr_repository.app.repository_url\n  description = \"ECR repository URL for the app\"\n}\n\noutput \"k8s_service_hostname\" {\n  description = \"External hostname of the Kubernetes LoadBalancer service (when provisioned)\"\n  value       = try(kubernetes_service_v1.app.status[0].load_balancer[0].ingress[0].hostname, null)\n}\n\noutput \"runner_instance_id\" {\n  description = \"Runner EC2 instance ID (if created)\"\n  value       = try(aws_instance.runner[0].id, null)\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region = \"us-west-1\"\nname       = \"react-aws-eks\"\n\n# App image currently points to Docker Hub (matches repo manifest).\n# Consider switching to the ECR repo output by this Terraform.\napp_image = \"codewithmuh/react-aws-eks-github-actions:latest\"\n\n# Optional: create a runner instance\ncreate_runner = false\n# github_repo_url     = \"https://github.com/<org>/<repo>\"\n# github_runner_token = \"<token>\"\n"
    },
    {
      "name": "README.md",
      "content": "# Terraform: React SPA on AWS EKS\n\nThis Terraform stack provisions:\n- VPC (2 AZs, public + private subnets, NAT)\n- EKS cluster + managed node group\n- ECR repository for the app image\n- Kubernetes namespace + Deployment + Service (type LoadBalancer)\n- Optional EC2 instance to host a self-hosted GitHub Actions runner (disabled by default)\n\n## Usage\n\n```bash\ncd ai_tf\nterraform init\nterraform validate\nterraform plan\nterraform apply\n```\n\nAfter apply, get the service hostname:\n\n```bash\nterraform output -raw k8s_service_hostname\n```\n\n## Notes\n\n- The Kubernetes Service is `type=LoadBalancer` to match `deployment-service.yml`. On AWS this will provision an ELB/NLB.\n- For production, prefer AWS Load Balancer Controller + Ingress + ACM + Route53.\n- The ECR repository is created, but the app deployment defaults to the Docker Hub image from the repo. Update `app_image` to the ECR URL once your CI pushes there.\n"
    }
  ]
}