{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~> 2.25\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~> 2.13\"\n    }\n    tls = {\n      source  = \"hashicorp/tls\"\n      version = \"~> 4.0\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Project     = var.project_name\n      Environment = var.environment\n      ManagedBy   = \"terraform\"\n    }\n  }\n}\n\ndata \"aws_caller_identity\" \"current\" {}\ndata \"aws_partition\" \"current\" {}\n\n# EKS auth token for Kubernetes/Helm providers\ndata \"aws_eks_cluster\" \"this\" {\n  name = module.eks.cluster_name\n}\n\ndata \"aws_eks_cluster_auth\" \"this\" {\n  name = module.eks.cluster_name\n}\n\nprovider \"kubernetes\" {\n  host                   = data.aws_eks_cluster.this.endpoint\n  cluster_ca_certificate = base64decode(data.aws_eks_cluster.this.certificate_authority[0].data)\n  token                  = data.aws_eks_cluster_auth.this.token\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = data.aws_eks_cluster.this.endpoint\n    cluster_ca_certificate = base64decode(data.aws_eks_cluster.this.certificate_authority[0].data)\n    token                  = data.aws_eks_cluster_auth.this.token\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"project_name\" {\n  description = \"Project name used for naming/tagging.\"\n  type        = string\n  default     = \"flask-activemq\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod).\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"aws_region\" {\n  description = \"AWS region.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"VPC CIDR.\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use (2 or 3).\"\n  type        = number\n  default     = 2\n  validation {\n    condition     = var.az_count >= 2 && var.az_count <= 3\n    error_message = \"az_count must be 2 or 3.\"\n  }\n}\n\nvariable \"cluster_version\" {\n  description = \"EKS Kubernetes version.\"\n  type        = string\n  default     = \"1.29\"\n}\n\nvariable \"node_instance_types\" {\n  description = \"EKS managed node group instance types.\"\n  type        = list(string)\n  default     = [\"t3.medium\"]\n}\n\nvariable \"node_desired_size\" {\n  description = \"Desired node count.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_min_size\" {\n  description = \"Minimum node count.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_max_size\" {\n  description = \"Maximum node count.\"\n  type        = number\n  default     = 4\n}\n\nvariable \"k8s_namespace\" {\n  description = \"Kubernetes namespace for the app.\"\n  type        = string\n  default     = \"helloworld\"\n}\n\nvariable \"app_image\" {\n  description = \"Flask app container image (ECR image URI + tag).\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"app_replicas\" {\n  description = \"Number of Flask app replicas.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"app_container_port\" {\n  description = \"Container port for Flask app. Dockerfile exposes 80.\"\n  type        = number\n  default     = 80\n}\n\nvariable \"app_service_port\" {\n  description = \"Kubernetes Service port for Flask app.\"\n  type        = number\n  default     = 80\n}\n\nvariable \"enable_public_ingress\" {\n  description = \"If true, create an internet-facing ALB Ingress for the Flask service.\"\n  type        = bool\n  default     = false\n}\n\nvariable \"acm_certificate_arn\" {\n  description = \"ACM certificate ARN for HTTPS on ALB (required if enable_public_ingress=true).\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"route53_zone_id\" {\n  description = \"Optional Route53 hosted zone id to create an alias record to the ALB.\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"route53_record_name\" {\n  description = \"Optional DNS record name (e.g., api.example.com). Requires route53_zone_id.\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"mq_deployment_mode\" {\n  description = \"Amazon MQ deployment mode. Use ACTIVE_STANDBY_MULTI_AZ for HA.\"\n  type        = string\n  default     = \"ACTIVE_STANDBY_MULTI_AZ\"\n  validation {\n    condition     = contains([\"SINGLE_INSTANCE\", \"ACTIVE_STANDBY_MULTI_AZ\"], var.mq_deployment_mode)\n    error_message = \"mq_deployment_mode must be SINGLE_INSTANCE or ACTIVE_STANDBY_MULTI_AZ.\"\n  }\n}\n\nvariable \"mq_instance_type\" {\n  description = \"Amazon MQ broker instance type.\"\n  type        = string\n  default     = \"mq.t3.micro\"\n}\n\nvariable \"mq_engine_version\" {\n  description = \"Amazon MQ ActiveMQ engine version.\"\n  type        = string\n  default     = \"5.18\"\n}\n\nvariable \"mq_username\" {\n  description = \"Amazon MQ username.\"\n  type        = string\n  default     = \"admin\"\n}\n\nvariable \"mq_password\" {\n  description = \"Amazon MQ password. If empty, a random password is generated.\"\n  type        = string\n  default     = \"\"\n  sensitive   = true\n}\n"
    },
    {
      "name": "main.tf",
      "content": "locals {\n  name = \"${var.project_name}-${var.environment}\"\n}\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n}\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = var.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 4, i)]\n  public_subnets  = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 4, i + 8)]\n\n  enable_nat_gateway     = true\n  single_nat_gateway     = var.az_count == 2 ? true : false\n  one_nat_gateway_per_az = var.az_count == 3 ? true : false\n\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = 1\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = 1\n  }\n}\n\nmodule \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 20.0\"\n\n  cluster_name    = local.name\n  cluster_version = var.cluster_version\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  cluster_endpoint_public_access  = true\n  cluster_endpoint_private_access = true\n\n  enable_cluster_creator_admin_permissions = true\n\n  eks_managed_node_groups = {\n    default = {\n      name            = \"${local.name}-ng\"\n      instance_types  = var.node_instance_types\n      min_size        = var.node_min_size\n      max_size        = var.node_max_size\n      desired_size    = var.node_desired_size\n      subnet_ids      = module.vpc.private_subnets\n      capacity_type   = \"ON_DEMAND\"\n      ami_type        = \"AL2_x86_64\"\n    }\n  }\n\n  cluster_addons = {\n    coredns    = {}\n    kube-proxy = {}\n    vpc-cni    = {}\n  }\n}\n\n# ECR repository for the Flask app image\nresource \"aws_ecr_repository\" \"app\" {\n  name                 = local.name\n  image_tag_mutability = \"MUTABLE\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n\n  encryption_configuration {\n    encryption_type = \"AES256\"\n  }\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"app\" {\n  repository = aws_ecr_repository.app.name\n\n  policy = jsonencode({\n    rules = [\n      {\n        rulePriority = 1\n        description  = \"Keep last 20 images\"\n        selection = {\n          tagStatus   = \"any\"\n          countType   = \"imageCountMoreThan\"\n          countNumber = 20\n        }\n        action = {\n          type = \"expire\"\n        }\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "mq.tf",
      "content": "resource \"aws_security_group\" \"mq\" {\n  name        = \"${local.name}-mq\"\n  description = \"Amazon MQ broker security group\"\n  vpc_id      = module.vpc.vpc_id\n\n  # Egress anywhere\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name}-mq\"\n  }\n}\n\n# Allow STOMP (61613) and OpenWire (61616) from EKS node security group.\n# Note: the app currently uses stomp.Connection() defaults; you should configure it to use TLS/61614 in production.\nresource \"aws_security_group_rule\" \"mq_from_nodes_stomp\" {\n  type                     = \"ingress\"\n  security_group_id        = aws_security_group.mq.id\n  from_port                = 61613\n  to_port                  = 61613\n  protocol                 = \"tcp\"\n  source_security_group_id = module.eks.node_security_group_id\n  description              = \"Allow STOMP from EKS nodes\"\n}\n\nresource \"aws_security_group_rule\" \"mq_from_nodes_openwire\" {\n  type                     = \"ingress\"\n  security_group_id        = aws_security_group.mq.id\n  from_port                = 61616\n  to_port                  = 61616\n  protocol                 = \"tcp\"\n  source_security_group_id = module.eks.node_security_group_id\n  description              = \"Allow OpenWire from EKS nodes\"\n}\n\nresource \"random_password\" \"mq\" {\n  length  = 24\n  special = true\n}\n\nlocals {\n  mq_password_effective = var.mq_password != \"\" ? var.mq_password : random_password.mq.result\n}\n\nresource \"aws_secretsmanager_secret\" \"mq_credentials\" {\n  name                    = \"${local.name}/mq/credentials\"\n  recovery_window_in_days = 0\n}\n\nresource \"aws_secretsmanager_secret_version\" \"mq_credentials\" {\n  secret_id = aws_secretsmanager_secret.mq_credentials.id\n  secret_string = jsonencode({\n    username = var.mq_username\n    password = local.mq_password_effective\n  })\n}\n\nresource \"aws_mq_broker\" \"this\" {\n  broker_name         = \"${local.name}-broker\"\n  engine_type         = \"ActiveMQ\"\n  engine_version      = var.mq_engine_version\n  host_instance_type  = var.mq_instance_type\n  deployment_mode     = var.mq_deployment_mode\n  publicly_accessible = false\n\n  subnet_ids      = module.vpc.private_subnets\n  security_groups = [aws_security_group.mq.id]\n\n  user {\n    username = var.mq_username\n    password = local.mq_password_effective\n  }\n\n  logs {\n    general = true\n  }\n\n  auto_minor_version_upgrade = true\n\n  maintenance_window_start_time {\n    day_of_week = \"SUNDAY\"\n    time_of_day = \"03:00\"\n    time_zone   = \"UTC\"\n  }\n}\n"
    },
    {
      "name": "k8s.tf",
      "content": "resource \"kubernetes_namespace\" \"app\" {\n  metadata {\n    name = var.k8s_namespace\n    labels = {\n      \"app.kubernetes.io/name\" = var.project_name\n    }\n  }\n}\n\n# ServiceAccount for the Flask app (IRSA can be added later if the app needs AWS API access)\nresource \"kubernetes_service_account\" \"app\" {\n  metadata {\n    name      = \"flask-app\"\n    namespace = kubernetes_namespace.app.metadata[0].name\n  }\n}\n\nresource \"kubernetes_deployment\" \"app\" {\n  metadata {\n    name      = \"flask-app\"\n    namespace = kubernetes_namespace.app.metadata[0].name\n    labels = {\n      app = \"flask-app\"\n    }\n  }\n\n  spec {\n    replicas = var.app_replicas\n\n    selector {\n      match_labels = {\n        app = \"flask-app\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"flask-app\"\n        }\n      }\n\n      spec {\n        service_account_name = kubernetes_service_account.app.metadata[0].name\n\n        container {\n          name  = \"flask-app\"\n          image = var.app_image != \"\" ? var.app_image : \"public.ecr.aws/docker/library/python:3.9\"\n\n          port {\n            container_port = var.app_container_port\n          }\n\n          env {\n            name  = \"ACTIVEMQ_HOST\"\n            value = aws_mq_broker.this.instances[0].endpoints[0]\n          }\n\n          env {\n            name  = \"ACTIVEMQ_USERNAME\"\n            value = var.mq_username\n          }\n\n          env {\n            name  = \"ACTIVEMQ_PASSWORD\"\n            value = local.mq_password_effective\n          }\n\n          resources {\n            limits = {\n              cpu    = \"500m\"\n              memory = \"512Mi\"\n            }\n            requests = {\n              cpu    = \"100m\"\n              memory = \"128Mi\"\n            }\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [aws_mq_broker.this]\n}\n\nresource \"kubernetes_service\" \"app\" {\n  metadata {\n    name      = \"flask-app\"\n    namespace = kubernetes_namespace.app.metadata[0].name\n    labels = {\n      app = \"flask-app\"\n    }\n  }\n\n  spec {\n    selector = {\n      app = \"flask-app\"\n    }\n\n    port {\n      port        = var.app_service_port\n      target_port = var.app_container_port\n      protocol    = \"TCP\"\n    }\n\n    type = \"ClusterIP\"\n  }\n}\n"
    },
    {
      "name": "alb_controller.tf",
      "content": "data \"aws_iam_policy_document\" \"lbc_assume\" {\n  statement {\n    actions = [\"sts:AssumeRoleWithWebIdentity\"]\n\n    principals {\n      type        = \"Federated\"\n      identifiers = [module.eks.oidc_provider_arn]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${replace(module.eks.oidc_provider, \"https://\", \"\")}:sub\"\n      values   = [\"system:serviceaccount:kube-system:aws-load-balancer-controller\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${replace(module.eks.oidc_provider, \"https://\", \"\")}:aud\"\n      values   = [\"sts.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"aws_load_balancer_controller\" {\n  name               = \"${local.name}-aws-lbc\"\n  assume_role_policy = data.aws_iam_policy_document.lbc_assume.json\n}\n\n# AWS managed policy for the controller\nresource \"aws_iam_role_policy_attachment\" \"lbc\" {\n  role       = aws_iam_role.aws_load_balancer_controller.name\n  policy_arn = \"arn:${data.aws_partition.current.partition}:iam::aws:policy/AWSLoadBalancerControllerIAMPolicy\"\n}\n\nresource \"helm_release\" \"aws_load_balancer_controller\" {\n  name       = \"aws-load-balancer-controller\"\n  repository = \"https://aws.github.io/eks-charts\"\n  chart      = \"aws-load-balancer-controller\"\n  namespace  = \"kube-system\"\n\n  set {\n    name  = \"clusterName\"\n    value = module.eks.cluster_name\n  }\n\n  set {\n    name  = \"serviceAccount.create\"\n    value = \"true\"\n  }\n\n  set {\n    name  = \"serviceAccount.name\"\n    value = \"aws-load-balancer-controller\"\n  }\n\n  set {\n    name  = \"serviceAccount.annotations.eks\\\\.amazonaws\\\\.com/role-arn\"\n    value = aws_iam_role.aws_load_balancer_controller.arn\n  }\n\n  set {\n    name  = \"region\"\n    value = var.aws_region\n  }\n\n  set {\n    name  = \"vpcId\"\n    value = module.vpc.vpc_id\n  }\n\n  depends_on = [module.eks]\n}\n"
    },
    {
      "name": "ingress.tf",
      "content": "resource \"kubernetes_ingress_v1\" \"app\" {\n  count = var.enable_public_ingress ? 1 : 0\n\n  metadata {\n    name      = \"flask-app\"\n    namespace = kubernetes_namespace.app.metadata[0].name\n\n    annotations = {\n      \"kubernetes.io/ingress.class\"              = \"alb\"\n      \"alb.ingress.kubernetes.io/scheme\"        = \"internet-facing\"\n      \"alb.ingress.kubernetes.io/target-type\"   = \"ip\"\n      \"alb.ingress.kubernetes.io/listen-ports\"  = \"[{\\\"HTTPS\\\":443}]\"\n      \"alb.ingress.kubernetes.io/certificate-arn\" = var.acm_certificate_arn\n      \"alb.ingress.kubernetes.io/healthcheck-path\" = \"/\"\n    }\n  }\n\n  spec {\n    rule {\n      http {\n        path {\n          path      = \"/\"\n          path_type = \"Prefix\"\n\n          backend {\n            service {\n              name = kubernetes_service.app.metadata[0].name\n              port {\n                number = var.app_service_port\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [helm_release.aws_load_balancer_controller]\n}\n\n# Optional Route53 alias record to the ALB created by the ingress.\n# Note: The ALB hostname is only available after the ingress is reconciled.\nresource \"aws_route53_record\" \"app\" {\n  count = var.enable_public_ingress && var.route53_zone_id != \"\" && var.route53_record_name != \"\" ? 1 : 0\n\n  zone_id = var.route53_zone_id\n  name    = var.route53_record_name\n  type    = \"A\"\n\n  alias {\n    name                   = kubernetes_ingress_v1.app[0].status[0].load_balancer[0].ingress[0].hostname\n    zone_id                = \"Z35SXDOTRQ7X7K\" # ALB hosted zone id varies by region; set explicitly if using Route53.\n    evaluate_target_health = true\n  }\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  value = module.vpc.vpc_id\n}\n\noutput \"eks_cluster_name\" {\n  value = module.eks.cluster_name\n}\n\noutput \"ecr_repository_url\" {\n  value = aws_ecr_repository.app.repository_url\n}\n\noutput \"amazon_mq_broker_id\" {\n  value = aws_mq_broker.this.id\n}\n\noutput \"amazon_mq_endpoints\" {\n  value = aws_mq_broker.this.instances[*].endpoints\n}\n\noutput \"mq_credentials_secret_arn\" {\n  value     = aws_secretsmanager_secret.mq_credentials.arn\n  sensitive = true\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region   = \"us-east-1\"\nenvironment  = \"dev\"\nproject_name = \"flask-activemq\"\n\n# Provide your built image (recommended). Example:\n# app_image = \"123456789012.dkr.ecr.us-east-1.amazonaws.com/flask-activemq-dev:1.0.0\"\napp_image = \"\"\n\n# For a public HTTPS endpoint, set these and enable_public_ingress=true\nenable_public_ingress = false\nacm_certificate_arn   = \"\"\n\n# Optional DNS\nroute53_zone_id      = \"\"\nroute53_record_name  = \"\"\n"
    }
  ]
}