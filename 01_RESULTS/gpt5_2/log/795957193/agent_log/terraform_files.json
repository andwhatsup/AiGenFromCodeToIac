{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 6.28\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Project     = var.project_name\n      Environment = var.environment\n      ManagedBy   = \"terraform\"\n    }\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"project_name\" {\n  description = \"Project/name prefix used for tagging and resource names.\"\n  type        = string\n  default     = \"express-ec2\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod).\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"aws_region\" {\n  description = \"AWS region to deploy into.\"\n  type        = string\n  default     = \"us-west-2\"\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type for the Node.js host.\"\n  type        = string\n  default     = \"t3.micro\"\n}\n\nvariable \"key_name\" {\n  description = \"Existing EC2 Key Pair name to enable SSH access. (Per README.md you will be prompted for this.)\"\n  type        = string\n}\n\nvariable \"ssh_ingress_cidr\" {\n  description = \"CIDR allowed to SSH to the instance. Use your public IP/32.\"\n  type        = string\n  default     = \"0.0.0.0/0\"\n}\n\nvariable \"app_port\" {\n  description = \"Port the Express app listens on.\"\n  type        = number\n  default     = 3000\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for the VPC.\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"public_subnet_cidr\" {\n  description = \"CIDR block for the public subnet.\"\n  type        = string\n  default     = \"10.0.1.0/24\"\n}\n\nvariable \"enable_cloudwatch_logs\" {\n  description = \"If true, install and configure CloudWatch Agent to ship logs.\"\n  type        = bool\n  default     = false\n}\n"
    },
    {
      "name": "main.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  name = \"${var.project_name}-${var.environment}\"\n  az   = data.aws_availability_zones.available.names[0]\n}\n\nresource \"aws_vpc\" \"this\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"${local.name}-vpc\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"this\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name}-igw\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  vpc_id                  = aws_vpc.this.id\n  cidr_block              = var.public_subnet_cidr\n  availability_zone       = local.az\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"${local.name}-public-${local.az}\"\n  }\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.this.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.this.id\n  }\n\n  tags = {\n    Name = \"${local.name}-public-rt\"\n  }\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  subnet_id      = aws_subnet.public.id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_security_group\" \"instance\" {\n  name        = \"${local.name}-sg\"\n  description = \"Security group for Express EC2 instance\"\n  vpc_id      = aws_vpc.this.id\n\n  ingress {\n    description = \"HTTP to Express app\"\n    from_port   = var.app_port\n    to_port     = var.app_port\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    description = \"SSH\"\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [var.ssh_ingress_cidr]\n  }\n\n  egress {\n    description = \"All outbound\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name}-sg\"\n  }\n}\n\ndata \"aws_ami\" \"al2023\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"al2023-ami-*-x86_64\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\nresource \"aws_iam_role\" \"ec2\" {\n  name = \"${local.name}-ec2-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"ec2.amazonaws.com\"\n        }\n        Action = \"sts:AssumeRole\"\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ssm\" {\n  role       = aws_iam_role.ec2.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n}\n\nresource \"aws_iam_instance_profile\" \"ec2\" {\n  name = \"${local.name}-ec2-profile\"\n  role = aws_iam_role.ec2.name\n}\n\nresource \"aws_cloudwatch_log_group\" \"app\" {\n  count             = var.enable_cloudwatch_logs ? 1 : 0\n  name              = \"/${local.name}/app\"\n  retention_in_days = 14\n}\n\nresource \"aws_instance\" \"app\" {\n  ami                         = data.aws_ami.al2023.id\n  instance_type               = var.instance_type\n  subnet_id                   = aws_subnet.public.id\n  vpc_security_group_ids      = [aws_security_group.instance.id]\n  key_name                    = var.key_name\n  associate_public_ip_address = true\n  iam_instance_profile        = aws_iam_instance_profile.ec2.name\n\n  user_data = templatefile(\"${path.module}/user_data.sh.tftpl\", {\n    app_port             = var.app_port\n    enable_cloudwatch    = var.enable_cloudwatch_logs\n    cloudwatch_log_group = var.enable_cloudwatch_logs ? aws_cloudwatch_log_group.app[0].name : \"\"\n    project_name         = var.project_name\n    environment          = var.environment\n  })\n\n  metadata_options {\n    http_endpoint = \"enabled\"\n    http_tokens   = \"required\"\n  }\n\n  root_block_device {\n    volume_type = \"gp3\"\n    volume_size = 16\n    encrypted   = true\n  }\n\n  tags = {\n    Name = \"${local.name}-ec2\"\n  }\n}\n"
    },
    {
      "name": "user_data.sh.tftpl",
      "content": "#!/bin/bash\nset -euo pipefail\n\n# Basic OS setup\ndnf update -y\n\n# Install Node.js (Amazon Linux 2023)\ndnf install -y nodejs npm git\n\n# Create app user\nid -u nodeapp &>/dev/null || useradd -m -s /bin/bash nodeapp\n\nAPP_DIR=/opt/app\nmkdir -p $APP_DIR\nchown -R nodeapp:nodeapp $APP_DIR\n\n# NOTE: This is a minimal bootstrap. It does not pull your repo automatically.\n# You can SSH/SSM in and deploy your code, or extend this script to fetch from Git.\n\ncat >/etc/systemd/system/express-app.service <<'UNIT'\n[Unit]\nDescription=Express App\nAfter=network.target\n\n[Service]\nType=simple\nUser=nodeapp\nWorkingDirectory=/opt/app\nEnvironment=PORT=${app_port}\nExecStart=/usr/bin/node /opt/app/server.js\nRestart=always\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\nUNIT\n\nsystemctl daemon-reload\nsystemctl enable express-app.service\n\n# If you later copy server.js into /opt/app, you can start the service:\n# systemctl start express-app.service\n\n%{ if enable_cloudwatch }\n# Optional: CloudWatch Agent (logs)\ndnf install -y amazon-cloudwatch-agent\n\ncat >/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json <<CW\n{\n  \"logs\": {\n    \"logs_collected\": {\n      \"files\": {\n        \"collect_list\": [\n          {\n            \"file_path\": \"/var/log/messages\",\n            \"log_group_name\": \"${cloudwatch_log_group}\",\n            \"log_stream_name\": \"{instance_id}/messages\"\n          }\n        ]\n      }\n    }\n  }\n}\nCW\n\n/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json -s\n%{ endif }\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"instance_public_ip\" {\n  description = \"Public IP of the EC2 instance. Visit http://<ip>:3000\"\n  value       = aws_instance.app.public_ip\n}\n\noutput \"instance_public_dns\" {\n  description = \"Public DNS of the EC2 instance.\"\n  value       = aws_instance.app.public_dns\n}\n\noutput \"ssh_command\" {\n  description = \"Convenience SSH command (adjust user if you use a different AMI).\"\n  value       = \"ssh -i <path-to-your-key.pem> ec2-user@${aws_instance.app.public_dns}\"\n}\n"
    },
    {
      "name": "terraform.tfvars.example",
      "content": "aws_region = \"us-west-2\"\n\n# REQUIRED: existing EC2 key pair name in this region\nkey_name = \"your-keypair-name\"\n\n# Strongly recommended: restrict SSH to your IP\nssh_ingress_cidr = \"203.0.113.10/32\"\n\nproject_name = \"express-ec2\"\nenvironment  = \"dev\"\n\ninstance_type = \"t3.micro\"\n\n# Optional\nenable_cloudwatch_logs = false\n"
    },
    {
      "name": "README_DEPLOY.md",
      "content": "# Terraform (AI-generated) - Express on EC2\n\nThis Terraform deploys a minimal AWS setup matching the repository README expectation: an EC2 instance with a public IP and inbound access to port 3000.\n\n## Deploy\n\n```bash\ncd ai_tf\nterraform init\nterraform apply -var=\"key_name=<your-ec2-keypair-name>\" -var=\"ssh_ingress_cidr=<your-ip>/32\"\n```\n\nAfter apply, open:\n\n- `http://<instance_public_ip>:3000`\n\n## App deployment onto the instance\n\nThis Terraform does **not** automatically copy your Node.js code to the instance.\n\nOptions:\n- SSH to the instance and copy files to `/opt/app` (owned by `nodeapp`), then:\n  - `sudo systemctl start express-app.service`\n- Or extend `user_data.sh.tftpl` to `git clone` your repo.\n\n## Notes\n- IMDSv2 is enforced.\n- Root EBS volume is encrypted.\n- SSM is enabled via IAM role (you can use Session Manager if the instance has outbound internet).\n"
    }
  ]
}