{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 6.31\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~> 3.0\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~> 3.1\"\n    }\n    tls = {\n      source  = \"hashicorp/tls\"\n      version = \"~> 4.0\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = var.tags\n  }\n}\n\n# These providers are configured *after* the EKS cluster exists.\n# They use the AWS CLI exec plugin to obtain a token.\nprovider \"kubernetes\" {\n  host                   = module.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--region\", var.aws_region, \"--cluster-name\", module.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--region\", var.aws_region, \"--cluster-name\", module.eks.cluster_name]\n    }\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"name\" {\n  description = \"Name prefix used for resources\"\n  type        = string\n  default     = \"flask-calc\"\n}\n\nvariable \"kubernetes_version\" {\n  description = \"EKS Kubernetes version (major.minor)\"\n  type        = string\n  default     = \"1.29\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"VPC CIDR\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"How many AZs to use\"\n  type        = number\n  default     = 2\n}\n\nvariable \"single_nat_gateway\" {\n  description = \"Use a single NAT gateway (cheaper) instead of one per AZ\"\n  type        = bool\n  default     = true\n}\n\nvariable \"node_instance_types\" {\n  description = \"EKS managed node group instance types\"\n  type        = list(string)\n  default     = [\"t3.medium\"]\n}\n\nvariable \"node_desired_size\" {\n  description = \"Desired number of worker nodes\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_min_size\" {\n  description = \"Minimum number of worker nodes\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_max_size\" {\n  description = \"Maximum number of worker nodes\"\n  type        = number\n  default     = 4\n}\n\nvariable \"app_namespace\" {\n  description = \"Kubernetes namespace for the application\"\n  type        = string\n  default     = \"calculator\"\n}\n\nvariable \"app_name\" {\n  description = \"Kubernetes app name\"\n  type        = string\n  default     = \"calculator\"\n}\n\nvariable \"app_image\" {\n  description = \"Container image to deploy (e.g., <account>.dkr.ecr.<region>.amazonaws.com/repo:tag or ghcr.io/org/repo:tag)\"\n  type        = string\n  default     = \"nginx:stable\" # placeholder; set to your built Flask image\n}\n\nvariable \"app_port\" {\n  description = \"Container port exposed by the Flask app\"\n  type        = number\n  default     = 5000\n}\n\nvariable \"replicas\" {\n  description = \"Number of pod replicas\"\n  type        = number\n  default     = 2\n}\n\nvariable \"service_type\" {\n  description = \"Kubernetes Service type. Use LoadBalancer to provision an AWS NLB via the EKS service controller.\"\n  type        = string\n  default     = \"LoadBalancer\"\n  validation {\n    condition     = contains([\"ClusterIP\", \"NodePort\", \"LoadBalancer\"], var.service_type)\n    error_message = \"service_type must be one of ClusterIP, NodePort, LoadBalancer\"\n  }\n}\n\nvariable \"service_annotations\" {\n  description = \"Annotations to apply to the Service (e.g., AWS load balancer annotations)\"\n  type        = map(string)\n  default = {\n    \"service.beta.kubernetes.io/aws-load-balancer-scheme\" = \"internet-facing\"\n    # If you want to force NLB:\n    # \"service.beta.kubernetes.io/aws-load-balancer-type\" = \"nlb\"\n  }\n}\n\nvariable \"tags\" {\n  description = \"Tags applied to all taggable AWS resources\"\n  type        = map(string)\n  default = {\n    Project = \"flask-calculator\"\n    Managed = \"terraform\"\n  }\n}\n"
    },
    {
      "name": "main.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n\n  # Simple deterministic subnetting: /16 -> /20s\n  public_subnets  = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 4, i)]\n  private_subnets = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 4, i + 10)]\n}\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"6.6.0\"\n\n  name = var.name\n  cidr = var.vpc_cidr\n\n  azs             = local.azs\n  public_subnets  = local.public_subnets\n  private_subnets = local.private_subnets\n\n  enable_nat_gateway = true\n  single_nat_gateway = var.single_nat_gateway\n\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  # Required for EKS + AWS Load Balancer Controller / in-tree LB provisioning\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = \"1\"\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = \"1\"\n  }\n\n  tags = var.tags\n}\n\nmodule \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"21.15.1\"\n\n  name               = var.name\n  kubernetes_version = var.kubernetes_version\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  endpoint_public_access  = true\n  endpoint_private_access = true\n\n  enable_irsa = true\n\n  enabled_log_types = [\"api\", \"audit\", \"authenticator\"]\n\n  eks_managed_node_groups = {\n    default = {\n      instance_types = var.node_instance_types\n\n      min_size     = var.node_min_size\n      max_size     = var.node_max_size\n      desired_size = var.node_desired_size\n\n      capacity_type = \"ON_DEMAND\"\n\n      # IMDSv2 required\n      metadata_options = {\n        http_endpoint = \"enabled\"\n        http_tokens   = \"required\"\n      }\n    }\n  }\n\n  tags = var.tags\n}\n\n# --- ECR (optional but recommended) ---\nresource \"aws_ecr_repository\" \"app\" {\n  name                 = var.name\n  image_tag_mutability = \"MUTABLE\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n\n  encryption_configuration {\n    encryption_type = \"AES256\"\n  }\n\n  tags = var.tags\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"app\" {\n  repository = aws_ecr_repository.app.name\n\n  policy = jsonencode({\n    rules = [\n      {\n        rulePriority = 1\n        description  = \"Expire untagged images older than 14 days\"\n        selection = {\n          tagStatus   = \"untagged\"\n          countType   = \"sinceImagePushed\"\n          countUnit   = \"days\"\n          countNumber = 14\n        }\n        action = {\n          type = \"expire\"\n        }\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "k8s_app.tf",
      "content": "resource \"kubernetes_namespace_v1\" \"app\" {\n  metadata {\n    name = var.app_namespace\n\n    labels = {\n      \"app.kubernetes.io/managed-by\" = \"terraform\"\n    }\n  }\n}\n\nresource \"kubernetes_deployment_v1\" \"app\" {\n  metadata {\n    name      = \"${var.app_name}-deployment\"\n    namespace = kubernetes_namespace_v1.app.metadata[0].name\n\n    labels = {\n      app = var.app_name\n    }\n  }\n\n  spec {\n    replicas = var.replicas\n\n    selector {\n      match_labels = {\n        app = var.app_name\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = var.app_name\n        }\n      }\n\n      spec {\n        container {\n          name  = var.app_name\n          image = var.app_image\n\n          port {\n            container_port = var.app_port\n          }\n\n          # Basic health checks; adjust paths if your Flask app differs\n          liveness_probe {\n            http_get {\n              path = \"/\"\n              port = var.app_port\n            }\n            initial_delay_seconds = 15\n            period_seconds        = 20\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/\"\n              port = var.app_port\n            }\n            initial_delay_seconds = 5\n            period_seconds        = 10\n          }\n\n          resources {\n            requests = {\n              cpu    = \"100m\"\n              memory = \"128Mi\"\n            }\n            limits = {\n              cpu    = \"500m\"\n              memory = \"512Mi\"\n            }\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [module.eks]\n}\n\nresource \"kubernetes_service_v1\" \"app\" {\n  metadata {\n    name      = \"${var.app_name}-service\"\n    namespace = kubernetes_namespace_v1.app.metadata[0].name\n\n    annotations = var.service_annotations\n\n    labels = {\n      app = var.app_name\n    }\n  }\n\n  spec {\n    selector = {\n      app = var.app_name\n    }\n\n    port {\n      name        = \"http\"\n      port        = 80\n      target_port = var.app_port\n      protocol    = \"TCP\"\n    }\n\n    type = var.service_type\n  }\n\n  depends_on = [kubernetes_deployment_v1.app]\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  value       = module.vpc.vpc_id\n  description = \"VPC ID\"\n}\n\noutput \"private_subnet_ids\" {\n  value       = module.vpc.private_subnets\n  description = \"Private subnet IDs\"\n}\n\noutput \"public_subnet_ids\" {\n  value       = module.vpc.public_subnets\n  description = \"Public subnet IDs\"\n}\n\noutput \"eks_cluster_name\" {\n  value       = module.eks.cluster_name\n  description = \"EKS cluster name\"\n}\n\noutput \"eks_cluster_endpoint\" {\n  value       = module.eks.cluster_endpoint\n  description = \"EKS cluster endpoint\"\n}\n\noutput \"ecr_repository_url\" {\n  value       = aws_ecr_repository.app.repository_url\n  description = \"ECR repository URL (push your app image here)\"\n}\n\noutput \"service_hostname\" {\n  description = \"External hostname of the Kubernetes Service (when type=LoadBalancer)\"\n  value       = try(kubernetes_service_v1.app.status[0].load_balancer[0].ingress[0].hostname, null)\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region = \"us-east-1\"\nname       = \"flask-calc\"\n\n# Set this to your built image (from GHCR/DockerHub/ECR)\n# app_image = \"<account>.dkr.ecr.us-east-1.amazonaws.com/flask-calc:latest\"\napp_image = \"ghcr.io/your-org/your-repo:latest\"\n\nreplicas = 2\n\n# Optional: add/override service annotations\nservice_annotations = {\n  \"service.beta.kubernetes.io/aws-load-balancer-scheme\" = \"internet-facing\"\n  # \"service.beta.kubernetes.io/aws-load-balancer-type\"   = \"nlb\"\n}\n"
    },
    {
      "name": "README.md",
      "content": "# Terraform: Flask calculator on EKS\n\nThis Terraform config provisions:\n- VPC (public + private subnets, NAT)\n- EKS cluster + managed node group\n- ECR repository (optional, recommended)\n- Kubernetes namespace + Deployment (2 replicas) + Service (type LoadBalancer)\n\n## Usage\n\n```bash\ncd ai_tf\nterraform init\nterraform validate\nterraform plan\nterraform apply\n```\n\nAfter apply, you can fetch the service hostname:\n\n```bash\nterraform output -raw service_hostname\n```\n\n## Notes\n- `kubernetes` and `helm` providers use `aws eks get-token` (AWS CLI must be installed).\n- `app_image` must be set to your built Flask image.\n- The Service is `LoadBalancer` which will provision an AWS NLB by default via the EKS service controller.\n  If you want an ALB, typically use an Ingress + AWS Load Balancer Controller.\n"
    }
  ]
}