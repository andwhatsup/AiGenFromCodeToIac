{
  "files": [
    {
      "name": "provider.tf",
      "content": "terraform {\n  required_version = \">= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region  = var.aws_region\n  profile = var.aws_profile\n\n  default_tags {\n    tags = var.tags\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"aws_profile\" {\n  description = \"AWS CLI profile name to use for credentials.\"\n  type        = string\n  default     = \"default\"\n}\n\nvariable \"name_prefix\" {\n  description = \"Prefix used for naming AWS resources.\"\n  type        = string\n  default     = \"devops\"\n}\n\nvariable \"tags\" {\n  description = \"Tags applied to all resources via provider default_tags.\"\n  type        = map(string)\n  default = {\n    Project = \"ontwikkelingsbedrywighede\"\n    Managed = \"terraform\"\n  }\n}\n\nvariable \"s3_bucket_name\" {\n  description = \"Optional explicit S3 bucket name. If null, a unique name will be generated.\"\n  type        = string\n  default     = null\n}\n\nvariable \"lambda_runtime\" {\n  description = \"Lambda runtime.\"\n  type        = string\n  default     = \"python3.12\"\n}\n\nvariable \"lambda_timeout_seconds\" {\n  description = \"Lambda timeout in seconds.\"\n  type        = number\n  default     = 30\n}\n\nvariable \"lambda_memory_mb\" {\n  description = \"Lambda memory size in MB.\"\n  type        = number\n  default     = 128\n}\n\nvariable \"lambda_log_retention_days\" {\n  description = \"CloudWatch log retention for Lambda log group.\"\n  type        = number\n  default     = 14\n}\n\nvariable \"source_prefix\" {\n  description = \"S3 prefix that triggers the Lambda.\"\n  type        = string\n  default     = \"source/\"\n}\n\nvariable \"destination_prefix\" {\n  description = \"S3 prefix where objects are copied to.\"\n  type        = string\n  default     = \"destination/\"\n}\n"
    },
    {
      "name": "main.tf",
      "content": "locals {\n  bucket_name = coalesce(var.s3_bucket_name, \"${var.name_prefix}-${data.aws_caller_identity.current.account_id}-${data.aws_region.current.name}-files\")\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_region\" \"current\" {}\n\n# --- S3 bucket ---\nresource \"aws_s3_bucket\" \"this\" {\n  bucket        = local.bucket_name\n  force_destroy = false\n}\n\nresource \"aws_s3_bucket_versioning\" \"this\" {\n  bucket = aws_s3_bucket.this.id\n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"this\" {\n  bucket                  = aws_s3_bucket.this.id\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"this\" {\n  bucket = aws_s3_bucket.this.id\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm = \"AES256\"\n    }\n  }\n}\n\n# --- Lambda packaging ---\n# Uses the prebuilt artifact in the repo.\n# If you change lambda_function.py, rebuild lambda.zip accordingly.\nresource \"aws_lambda_function\" \"mover\" {\n  function_name = \"${var.name_prefix}-s3-mover\"\n  role          = aws_iam_role.lambda_exec.arn\n\n  runtime = var.lambda_runtime\n  handler = \"lambda_function.lambda_handler\"\n\n  filename         = \"${path.module}/../lambda.zip\"\n  source_code_hash = filebase64sha256(\"${path.module}/../lambda.zip\")\n\n  timeout     = var.lambda_timeout_seconds\n  memory_size = var.lambda_memory_mb\n\n  environment {\n    variables = {\n      BUCKET = aws_s3_bucket.this.bucket\n    }\n  }\n\n  depends_on = [aws_cloudwatch_log_group.lambda]\n}\n\nresource \"aws_cloudwatch_log_group\" \"lambda\" {\n  name              = \"/aws/lambda/${var.name_prefix}-s3-mover\"\n  retention_in_days = var.lambda_log_retention_days\n}\n\n# Allow S3 to invoke the Lambda\nresource \"aws_lambda_permission\" \"allow_s3\" {\n  statement_id  = \"AllowExecutionFromS3\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.mover.function_name\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket.this.arn\n}\n\n# S3 notification: only trigger on source/ prefix to avoid recursion\nresource \"aws_s3_bucket_notification\" \"this\" {\n  bucket = aws_s3_bucket.this.id\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.mover.arn\n    events              = [\"s3:ObjectCreated:*\"]\n    filter_prefix       = var.source_prefix\n  }\n\n  depends_on = [aws_lambda_permission.allow_s3]\n}\n\n# --- IAM for Lambda ---\nresource \"aws_iam_role\" \"lambda_exec\" {\n  name = \"${var.name_prefix}-lambda-s3-mover\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"lambda.amazonaws.com\"\n        }\n        Action = \"sts:AssumeRole\"\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy\" \"lambda_inline\" {\n  name = \"${var.name_prefix}-lambda-s3-mover\"\n  role = aws_iam_role.lambda_exec.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"AllowCloudWatchLogs\"\n        Effect = \"Allow\"\n        Action = [\n          \"logs:CreateLogGroup\",\n          \"logs:CreateLogStream\",\n          \"logs:PutLogEvents\"\n        ]\n        Resource = \"arn:aws:logs:*:*:*\"\n      },\n      {\n        Sid    = \"AllowReadFromSourcePrefix\"\n        Effect = \"Allow\"\n        Action = [\n          \"s3:GetObject\"\n        ]\n        Resource = \"${aws_s3_bucket.this.arn}/${var.source_prefix}*\"\n      },\n      {\n        Sid    = \"AllowWriteToDestinationPrefix\"\n        Effect = \"Allow\"\n        Action = [\n          \"s3:PutObject\"\n        ]\n        Resource = \"${aws_s3_bucket.this.arn}/${var.destination_prefix}*\"\n      },\n      {\n        Sid    = \"AllowDeleteFromSourcePrefix\"\n        Effect = \"Allow\"\n        Action = [\n          \"s3:DeleteObject\"\n        ]\n        Resource = \"${aws_s3_bucket.this.arn}/${var.source_prefix}*\"\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"s3_bucket_name\" {\n  description = \"Name of the S3 bucket used for source/ and destination/ prefixes.\"\n  value       = aws_s3_bucket.this.bucket\n}\n\noutput \"lambda_function_name\" {\n  description = \"Name of the Lambda function that moves objects from source/ to destination/.\"\n  value       = aws_lambda_function.mover.function_name\n}\n\noutput \"lambda_role_arn\" {\n  description = \"IAM role ARN used by the Lambda function.\"\n  value       = aws_iam_role.lambda_exec.arn\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region  = \"us-east-1\"\naws_profile = \"default\"\n\n# Optionally set a globally-unique bucket name\n# s3_bucket_name = \"my-unique-bucket-name\"\n\nname_prefix = \"ontw\"\n\ntags = {\n  Project = \"ontwikkelingsbedrywighede\"\n  Env     = \"dev\"\n  Managed = \"terraform\"\n}\n"
    }
  ]
}