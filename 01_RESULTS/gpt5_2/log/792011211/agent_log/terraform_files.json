{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 6.28\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~> 3.0\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~> 3.1\"\n    }\n    tls = {\n      source  = \"hashicorp/tls\"\n      version = \"~> 4.1\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = var.tags\n  }\n}\n\n# These providers are configured after the EKS cluster is created.\n# They use the AWS CLI exec plugin to obtain an authentication token.\nprovider \"kubernetes\" {\n  host                   = module.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--region\", var.aws_region, \"--cluster-name\", module.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes = {\n    host                   = module.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n\n    exec = {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--region\", var.aws_region, \"--cluster-name\", module.eks.cluster_name]\n    }\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"aws_region\" {\n  description = \"AWS region to deploy into\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"name\" {\n  description = \"Base name/prefix for resources\"\n  type        = string\n  default     = \"python-weather\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, prod)\"\n  type        = string\n  default     = \"prod\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR for the VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use (2 recommended)\"\n  type        = number\n  default     = 2\n}\n\nvariable \"kubernetes_version\" {\n  description = \"EKS Kubernetes version\"\n  type        = string\n  default     = \"1.29\"\n}\n\nvariable \"cluster_endpoint_public_access\" {\n  description = \"Whether the EKS API endpoint is publicly accessible\"\n  type        = bool\n  default     = true\n}\n\nvariable \"cluster_endpoint_public_access_cidrs\" {\n  description = \"CIDRs allowed to access the public EKS API endpoint\"\n  type        = list(string)\n  default     = [\"0.0.0.0/0\"]\n}\n\nvariable \"node_instance_types\" {\n  description = \"Instance types for the EKS managed node group\"\n  type        = list(string)\n  default     = [\"t3.medium\"]\n}\n\nvariable \"node_desired_size\" {\n  description = \"Desired number of worker nodes\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_min_size\" {\n  description = \"Minimum number of worker nodes\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_max_size\" {\n  description = \"Maximum number of worker nodes\"\n  type        = number\n  default     = 4\n}\n\nvariable \"ecr_repository_name\" {\n  description = \"ECR repository name for the application image\"\n  type        = string\n  default     = \"eks-python-weather-app\"\n}\n\nvariable \"secret_name\" {\n  description = \"Secrets Manager secret name that stores the OpenWeatherMap API key\"\n  type        = string\n  default     = \"/python-weather-app/api-key\"\n}\n\nvariable \"create_secret\" {\n  description = \"If true, create the Secrets Manager secret metadata (does not set secret value). If false, the secret must already exist.\"\n  type        = bool\n  default     = false\n}\n\nvariable \"secret_kms_key_id\" {\n  description = \"Optional KMS key ARN/ID for Secrets Manager secret encryption. Leave null to use aws/secretsmanager managed key.\"\n  type        = string\n  default     = null\n}\n\nvariable \"tags\" {\n  description = \"Tags applied to all resources\"\n  type        = map(string)\n  default = {\n    Project = \"python-weather-app\"\n  }\n}\n"
    },
    {
      "name": "locals.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n\n  # /24s for subnets\n  public_subnets  = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 8, 100 + i)]\n  private_subnets = [for i, az in local.azs : cidrsubnet(var.vpc_cidr, 8, i)]\n\n  cluster_name = \"${var.name}-eks\"\n}\n"
    },
    {
      "name": "network.tf",
      "content": "module \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"6.6.0\"\n\n  name = \"${var.name}-vpc\"\n  cidr = var.vpc_cidr\n\n  azs             = local.azs\n  public_subnets  = local.public_subnets\n  private_subnets = local.private_subnets\n\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  enable_nat_gateway     = true\n  one_nat_gateway_per_az = true\n\n  # Required for EKS + AWS Load Balancer Controller\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = \"1\"\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = \"1\"\n  }\n\n  tags = var.tags\n}\n"
    },
    {
      "name": "ecr.tf",
      "content": "resource \"aws_ecr_repository\" \"app\" {\n  name                 = var.ecr_repository_name\n  image_tag_mutability = \"MUTABLE\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n\n  encryption_configuration {\n    encryption_type = \"AES256\"\n  }\n\n  force_delete = false\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"app\" {\n  repository = aws_ecr_repository.app.name\n\n  policy = jsonencode({\n    rules = [\n      {\n        rulePriority = 1\n        description  = \"Keep last 30 images\"\n        selection = {\n          tagStatus   = \"any\"\n          countType   = \"imageCountMoreThan\"\n          countNumber = 30\n        }\n        action = {\n          type = \"expire\"\n        }\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "secrets.tf",
      "content": "resource \"aws_secretsmanager_secret\" \"api_key\" {\n  count = var.create_secret ? 1 : 0\n\n  name                   = var.secret_name\n  kms_key_id              = var.secret_kms_key_id\n  recovery_window_in_days = 7\n\n  tags = var.tags\n}\n\n# If the secret already exists, look it up so we can reference its ARN in IAM policies.\ndata \"aws_secretsmanager_secret\" \"api_key\" {\n  count = var.create_secret ? 0 : 1\n\n  name = var.secret_name\n}\n\nlocals {\n  api_secret_arn = var.create_secret ? aws_secretsmanager_secret.api_key[0].arn : data.aws_secretsmanager_secret.api_key[0].arn\n}\n"
    },
    {
      "name": "eks.tf",
      "content": "module \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"21.15.1\"\n\n  name               = local.cluster_name\n  kubernetes_version = var.kubernetes_version\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  endpoint_public_access       = var.cluster_endpoint_public_access\n  endpoint_public_access_cidrs = var.cluster_endpoint_public_access_cidrs\n  endpoint_private_access      = true\n\n  enable_irsa = true\n\n  enabled_log_types = [\"api\", \"audit\", \"authenticator\"]\n\n  addons = {\n    coredns    = {}\n    kube-proxy = {}\n    vpc-cni    = {}\n  }\n\n  eks_managed_node_groups = {\n    default = {\n      name           = \"default\"\n      instance_types = var.node_instance_types\n\n      min_size     = var.node_min_size\n      max_size     = var.node_max_size\n      desired_size = var.node_desired_size\n\n      # Allow pulling from ECR, writing logs, etc.\n      iam_role_additional_policies = {\n        AmazonEC2ContainerRegistryReadOnly = \"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\"\n        CloudWatchAgentServerPolicy        = \"arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy\"\n      }\n    }\n  }\n\n  tags = var.tags\n}\n"
    },
    {
      "name": "iam_irsa.tf",
      "content": "data \"aws_iam_policy_document\" \"alb_controller_assume\" {\n  statement {\n    actions = [\"sts:AssumeRoleWithWebIdentity\"]\n\n    principals {\n      type        = \"Federated\"\n      identifiers = [module.eks.oidc_provider_arn]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${module.eks.oidc_provider}:sub\"\n      values   = [\"system:serviceaccount:kube-system:aws-load-balancer-controller\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${module.eks.oidc_provider}:aud\"\n      values   = [\"sts.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"alb_controller\" {\n  name               = \"AmazonEKSLoadBalancerControllerRole-${module.eks.cluster_name}\"\n  assume_role_policy = data.aws_iam_policy_document.alb_controller_assume.json\n\n  tags = var.tags\n}\n\n# NOTE: This uses a broad AWS managed policy for simplicity.\n# For production least-privilege, replace with the official controller IAM policy JSON.\nresource \"aws_iam_role_policy_attachment\" \"alb_controller\" {\n  role       = aws_iam_role.alb_controller.name\n  policy_arn = \"arn:aws:iam::aws:policy/ElasticLoadBalancingFullAccess\"\n}\n\n# App IRSA role for Secrets Manager read\n\ndata \"aws_iam_policy_document\" \"app_assume\" {\n  statement {\n    actions = [\"sts:AssumeRoleWithWebIdentity\"]\n\n    principals {\n      type        = \"Federated\"\n      identifiers = [module.eks.oidc_provider_arn]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${module.eks.oidc_provider}:sub\"\n      values   = [\"system:serviceaccount:${var.environment}:secret-service-account\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${module.eks.oidc_provider}:aud\"\n      values   = [\"sts.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"app_secrets\" {\n  name               = \"${var.name}-app-secrets-${var.environment}\"\n  assume_role_policy = data.aws_iam_policy_document.app_assume.json\n\n  tags = var.tags\n}\n\ndata \"aws_iam_policy_document\" \"app_secrets\" {\n  statement {\n    sid = \"ReadWeatherApiKeySecret\"\n\n    actions = [\n      \"secretsmanager:GetSecretValue\",\n      \"secretsmanager:DescribeSecret\"\n    ]\n\n    resources = [local.api_secret_arn]\n  }\n}\n\nresource \"aws_iam_policy\" \"app_secrets\" {\n  name   = \"${var.name}-app-secrets-${var.environment}\"\n  policy = data.aws_iam_policy_document.app_secrets.json\n\n  tags = var.tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"app_secrets\" {\n  role       = aws_iam_role.app_secrets.name\n  policy_arn = aws_iam_policy.app_secrets.arn\n}\n"
    },
    {
      "name": "k8s_addons.tf",
      "content": "resource \"helm_release\" \"secrets_store_csi\" {\n  name       = \"csi-secrets-store\"\n  namespace  = \"kube-system\"\n  repository = \"https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts\"\n  chart      = \"secrets-store-csi-driver\"\n  version    = \"1.4.5\"\n\n  values = [\n    yamlencode({\n      syncSecret = {\n        enabled = true\n      }\n    })\n  ]\n\n  depends_on = [module.eks]\n}\n\n# AWS provider for Secrets Store CSI Driver\n# The installer YAML contains multiple documents, so we apply them separately.\nlocals {\n  secrets_store_aws_provider_docs = [\n    for d in split(\"\\n---\\n\", trimspace(file(\"${path.module}/manifests/aws-provider-installer.yaml\"))) :\n    yamldecode(d)\n  ]\n}\n\nresource \"kubernetes_manifest\" \"secrets_store_aws_provider\" {\n  for_each = { for idx, doc in local.secrets_store_aws_provider_docs : idx => doc }\n\n  manifest = each.value\n\n  depends_on = [helm_release.secrets_store_csi]\n}\n\nresource \"helm_release\" \"aws_load_balancer_controller\" {\n  name       = \"aws-load-balancer-controller\"\n  namespace  = \"kube-system\"\n  repository = \"https://aws.github.io/eks-charts\"\n  chart      = \"aws-load-balancer-controller\"\n  version    = \"1.7.2\"\n\n  values = [\n    yamlencode({\n      clusterName = module.eks.cluster_name\n      region      = var.aws_region\n      vpcId       = module.vpc.vpc_id\n      serviceAccount = {\n        create = false\n        name   = \"aws-load-balancer-controller\"\n      }\n    })\n  ]\n\n  depends_on = [kubernetes_manifest.aws_load_balancer_controller_sa]\n}\n"
    },
    {
      "name": "k8s_app.tf",
      "content": "resource \"kubernetes_namespace_v1\" \"prod\" {\n  metadata {\n    name = var.environment\n  }\n\n  depends_on = [module.eks]\n}\n\nresource \"kubernetes_service_account\" \"app\" {\n  metadata {\n    name      = \"secret-service-account\"\n    namespace = kubernetes_namespace_v1.prod.metadata[0].name\n\n    annotations = {\n      \"eks.amazonaws.com/role-arn\" = aws_iam_role.app_secrets.arn\n    }\n  }\n}\n\nresource \"kubernetes_manifest\" \"aws_load_balancer_controller_sa\" {\n  manifest = {\n    apiVersion = \"v1\"\n    kind       = \"ServiceAccount\"\n    metadata = {\n      name      = \"aws-load-balancer-controller\"\n      namespace = \"kube-system\"\n      annotations = {\n        \"eks.amazonaws.com/role-arn\" = aws_iam_role.alb_controller.arn\n      }\n      labels = {\n        \"app.kubernetes.io/component\" = \"controller\"\n        \"app.kubernetes.io/name\"      = \"aws-load-balancer-controller\"\n      }\n    }\n  }\n\n  depends_on = [module.eks]\n}\n\nresource \"kubernetes_manifest\" \"secret_provider_class\" {\n  manifest = {\n    apiVersion = \"secrets-store.csi.x-k8s.io/v1\"\n    kind       = \"SecretProviderClass\"\n    metadata = {\n      name      = \"aws-secrets\"\n      namespace = kubernetes_namespace_v1.prod.metadata[0].name\n    }\n    spec = {\n      provider = \"aws\"\n      secretObjects = [\n        {\n          secretName = \"api-token\"\n          type       = \"Opaque\"\n          data = [\n            {\n              objectName = \"api\"\n              key        = \"api-key\"\n            }\n          ]\n        }\n      ]\n      parameters = {\n        objects = <<-EOT\n          - objectName: ${var.secret_name}\n            objectType: secretsmanager\n            objectAlias: api\n        EOT\n      }\n    }\n  }\n\n  depends_on = [\n    kubernetes_namespace_v1.prod,\n    helm_release.secrets_store_csi,\n    kubernetes_manifest.secrets_store_aws_provider\n  ]\n}\n\nresource \"kubernetes_deployment\" \"app\" {\n  metadata {\n    name      = \"python-app\"\n    namespace = kubernetes_namespace_v1.prod.metadata[0].name\n    labels = {\n      app = \"python-app\"\n    }\n  }\n\n  spec {\n    replicas = 2\n\n    selector {\n      match_labels = {\n        app = \"python-app\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"python-app\"\n        }\n      }\n\n      spec {\n        service_account_name = kubernetes_service_account.app.metadata[0].name\n\n        container {\n          name  = \"python-weather-app\"\n          image = \"${aws_ecr_repository.app.repository_url}:latest\"\n\n          port {\n            container_port = 5000\n          }\n\n          env {\n            name = \"API_KEY\"\n            value_from {\n              secret_key_ref {\n                name = \"api-token\"\n                key  = \"api-key\"\n              }\n            }\n          }\n\n          volume_mount {\n            name       = \"python-app-secrets\"\n            mount_path = \"/mnt/secrets\"\n            read_only  = true\n          }\n        }\n\n        volume {\n          name = \"python-app-secrets\"\n\n          csi {\n            driver    = \"secrets-store.csi.k8s.io\"\n            read_only = true\n            volume_attributes = {\n              secretProviderClass = \"aws-secrets\"\n            }\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [kubernetes_manifest.secret_provider_class]\n}\n\nresource \"kubernetes_service\" \"app\" {\n  metadata {\n    name      = \"python-app-service\"\n    namespace = kubernetes_namespace_v1.prod.metadata[0].name\n  }\n\n  spec {\n    selector = {\n      app = kubernetes_deployment.app.metadata[0].labels.app\n    }\n\n    port {\n      port        = 80\n      target_port = 5000\n      protocol    = \"TCP\"\n    }\n\n    type = \"NodePort\"\n  }\n}\n\nresource \"kubernetes_ingress_v1\" \"app\" {\n  metadata {\n    name      = \"python-app-ingress\"\n    namespace = kubernetes_namespace_v1.prod.metadata[0].name\n\n    annotations = {\n      \"kubernetes.io/ingress.class\"           = \"alb\"\n      \"alb.ingress.kubernetes.io/scheme\"      = \"internet-facing\"\n      \"alb.ingress.kubernetes.io/target-type\" = \"instance\"\n    }\n  }\n\n  spec {\n    ingress_class_name = \"alb\"\n\n    rule {\n      http {\n        path {\n          path      = \"/\"\n          path_type = \"Prefix\"\n\n          backend {\n            service {\n              name = kubernetes_service.app.metadata[0].name\n              port {\n                number = 80\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [helm_release.aws_load_balancer_controller]\n}\n"
    },
    {
      "name": "manifests/aws-provider-installer.yaml",
      "content": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-provider-aws\n  namespace: kube-system\n  labels:\n    app: csi-secrets-store-provider-aws\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store-provider-aws\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store-provider-aws\n    spec:\n      serviceAccountName: csi-secrets-store-provider-aws\n      containers:\n        - name: provider-aws\n          image: public.ecr.aws/aws-secrets-manager/secrets-store-csi-driver-provider-aws:1.0.r2-58-gf3b0b2a-2023.10.13.21.15\n          imagePullPolicy: IfNotPresent\n          args:\n            - --provider-volume=/etc/kubernetes/secrets-store-csi-providers\n          volumeMounts:\n            - name: providervol\n              mountPath: /etc/kubernetes/secrets-store-csi-providers\n      volumes:\n        - name: providervol\n          hostPath:\n            path: /etc/kubernetes/secrets-store-csi-providers\n            type: DirectoryOrCreate\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: csi-secrets-store-provider-aws\n  namespace: kube-system\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"region\" {\n  value = var.aws_region\n}\n\noutput \"vpc_id\" {\n  value = module.vpc.vpc_id\n}\n\noutput \"eks_cluster_name\" {\n  value = module.eks.cluster_name\n}\n\noutput \"eks_cluster_endpoint\" {\n  value = module.eks.cluster_endpoint\n}\n\noutput \"ecr_repository_url\" {\n  value = aws_ecr_repository.app.repository_url\n}\n\noutput \"secret_arn\" {\n  value = local.api_secret_arn\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region = \"us-east-1\"\nname        = \"python-weather\"\nenvironment = \"prod\"\n\n# If you already created the secret via AWS CLI (as in the README), keep this false.\ncreate_secret = false\n\n# Optional: restrict EKS API endpoint access\ncluster_endpoint_public_access       = true\ncluster_endpoint_public_access_cidrs = [\"0.0.0.0/0\"]\n"
    }
  ]
}