{
  "files": [
    {
      "name": "versions.tf",
      "content": "terraform {\n  required_version = \">= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 6.28\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~> 3.0\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~> 3.1\"\n    }\n    tls = {\n      source  = \"hashicorp/tls\"\n      version = \"~> 4.0\"\n    }\n  }\n}\n"
    },
    {
      "name": "provider.tf",
      "content": "provider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = merge(\n      {\n        \"Project\"     = var.project_name\n        \"Environment\" = var.environment\n        \"ManagedBy\"   = \"terraform\"\n      },\n      var.tags\n    )\n  }\n}\n\n# These providers are configured after the EKS cluster is created.\nprovider \"kubernetes\" {\n  host                   = module.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n  token                  = data.aws_eks_cluster_auth.this.token\n}\n\nprovider \"helm\" {\n  kubernetes = {\n    host                   = module.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n    token                  = data.aws_eks_cluster_auth.this.token\n  }\n}\n"
    },
    {
      "name": "variables.tf",
      "content": "variable \"project_name\" {\n  description = \"Project/name prefix used for resources.\"\n  type        = string\n  default     = \"wd-prediction\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, prod).\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"aws_region\" {\n  description = \"AWS region.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR for the VPC.\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"az_count\" {\n  description = \"Number of AZs to use (2 or 3).\"\n  type        = number\n  default     = 2\n  validation {\n    condition     = var.az_count >= 2 && var.az_count <= 3\n    error_message = \"az_count must be 2 or 3.\"\n  }\n}\n\nvariable \"cluster_version\" {\n  description = \"EKS Kubernetes version.\"\n  type        = string\n  default     = \"1.29\"\n}\n\nvariable \"node_instance_types\" {\n  description = \"EKS managed node group instance types.\"\n  type        = list(string)\n  default     = [\"t3.medium\"]\n}\n\nvariable \"node_desired_size\" {\n  description = \"Desired number of worker nodes.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_min_size\" {\n  description = \"Minimum number of worker nodes.\"\n  type        = number\n  default     = 2\n}\n\nvariable \"node_max_size\" {\n  description = \"Maximum number of worker nodes.\"\n  type        = number\n  default     = 4\n}\n\nvariable \"app_namespace\" {\n  description = \"Kubernetes namespace for the application.\"\n  type        = string\n  default     = \"wd-prediction\"\n}\n\nvariable \"app_replicas\" {\n  description = \"Number of application replicas (pods).\"\n  type        = number\n  default     = 6\n}\n\nvariable \"app_image\" {\n  description = \"Container image for the app. Use an ECR image URI for production.\"\n  type        = string\n  default     = \"yash5090/wd-prediction:latest\"\n}\n\nvariable \"app_container_port\" {\n  description = \"Container port exposed by the app.\"\n  type        = number\n  default     = 5000\n}\n\nvariable \"service_port\" {\n  description = \"Kubernetes Service port.\"\n  type        = number\n  default     = 5000\n}\n\nvariable \"enable_ecr\" {\n  description = \"Whether to create an ECR repository for the application image.\"\n  type        = bool\n  default     = true\n}\n\nvariable \"ecr_repository_name\" {\n  description = \"ECR repository name (if enable_ecr=true).\"\n  type        = string\n  default     = \"wd-prediction\"\n}\n\nvariable \"tags\" {\n  description = \"Additional tags to apply to AWS resources.\"\n  type        = map(string)\n  default     = {}\n}\n"
    },
    {
      "name": "locals.tf",
      "content": "data \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nlocals {\n  name = \"${var.project_name}-${var.environment}\"\n\n  azs = slice(data.aws_availability_zones.available.names, 0, var.az_count)\n\n  # Derive /24 subnets from the VPC CIDR.\n  public_subnet_cidrs  = [for i in range(var.az_count) : cidrsubnet(var.vpc_cidr, 8, i)]\n  private_subnet_cidrs = [for i in range(var.az_count) : cidrsubnet(var.vpc_cidr, 8, i + 10)]\n}\n"
    },
    {
      "name": "network.tf",
      "content": "resource \"aws_vpc\" \"this\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = local.name\n  }\n}\n\nresource \"aws_internet_gateway\" \"this\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name}-igw\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  for_each = { for idx, az in local.azs : az => idx }\n\n  vpc_id                  = aws_vpc.this.id\n  availability_zone       = each.key\n  cidr_block              = local.public_subnet_cidrs[each.value]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name                     = \"${local.name}-public-${each.key}\"\n    \"kubernetes.io/role/elb\" = \"1\"\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  for_each = { for idx, az in local.azs : az => idx }\n\n  vpc_id            = aws_vpc.this.id\n  availability_zone = each.key\n  cidr_block        = local.private_subnet_cidrs[each.value]\n\n  tags = {\n    Name                              = \"${local.name}-private-${each.key}\"\n    \"kubernetes.io/role/internal-elb\" = \"1\"\n  }\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name}-public-rt\"\n  }\n}\n\nresource \"aws_route\" \"public_internet\" {\n  route_table_id         = aws_route_table.public.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  gateway_id             = aws_internet_gateway.this.id\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  for_each = aws_subnet.public\n\n  subnet_id      = each.value.id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_eip\" \"nat\" {\n  for_each = aws_subnet.public\n\n  domain = \"vpc\"\n\n  tags = {\n    Name = \"${local.name}-nat-eip-${each.key}\"\n  }\n}\n\nresource \"aws_nat_gateway\" \"this\" {\n  for_each = aws_subnet.public\n\n  allocation_id = aws_eip.nat[each.key].id\n  subnet_id     = each.value.id\n\n  tags = {\n    Name = \"${local.name}-nat-${each.key}\"\n  }\n\n  depends_on = [aws_internet_gateway.this]\n}\n\nresource \"aws_route_table\" \"private\" {\n  for_each = aws_subnet.private\n\n  vpc_id = aws_vpc.this.id\n\n  tags = {\n    Name = \"${local.name}-private-rt-${each.key}\"\n  }\n}\n\nresource \"aws_route\" \"private_nat\" {\n  for_each = aws_route_table.private\n\n  route_table_id         = each.value.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.this[each.key].id\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  for_each = aws_subnet.private\n\n  subnet_id      = each.value.id\n  route_table_id = aws_route_table.private[each.key].id\n}\n"
    },
    {
      "name": "ecr.tf",
      "content": "resource \"aws_ecr_repository\" \"app\" {\n  count = var.enable_ecr ? 1 : 0\n\n  name                 = var.ecr_repository_name\n  image_tag_mutability = \"MUTABLE\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n\n  encryption_configuration {\n    encryption_type = \"AES256\"\n  }\n\n  tags = {\n    Name = \"${local.name}-ecr\"\n  }\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"app\" {\n  count      = var.enable_ecr ? 1 : 0\n  repository = aws_ecr_repository.app[0].name\n\n  policy = jsonencode({\n    rules = [\n      {\n        rulePriority = 1\n        description  = \"Keep last 30 images\"\n        selection = {\n          tagStatus   = \"any\"\n          countType   = \"imageCountMoreThan\"\n          countNumber = 30\n        }\n        action = {\n          type = \"expire\"\n        }\n      }\n    ]\n  })\n}\n"
    },
    {
      "name": "eks.tf",
      "content": "data \"aws_iam_policy_document\" \"eks_cluster_assume\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n    principals {\n      type        = \"Service\"\n      identifiers = [\"eks.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"eks_cluster\" {\n  name               = \"${local.name}-eks-cluster-role\"\n  assume_role_policy = data.aws_iam_policy_document.eks_cluster_assume.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"eks_cluster_AmazonEKSClusterPolicy\" {\n  role       = aws_iam_role.eks_cluster.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"eks_cluster_AmazonEKSServicePolicy\" {\n  role       = aws_iam_role.eks_cluster.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSServicePolicy\"\n}\n\ndata \"aws_iam_policy_document\" \"eks_node_assume\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ec2.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"eks_node\" {\n  name               = \"${local.name}-eks-node-role\"\n  assume_role_policy = data.aws_iam_policy_document.eks_node_assume.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"eks_node_AmazonEKSWorkerNodePolicy\" {\n  role       = aws_iam_role.eks_node.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"eks_node_AmazonEKS_CNI_Policy\" {\n  role       = aws_iam_role.eks_node.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"eks_node_AmazonEC2ContainerRegistryReadOnly\" {\n  role       = aws_iam_role.eks_node.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\"\n}\n\nresource \"aws_iam_instance_profile\" \"eks_node\" {\n  name = \"${local.name}-eks-node-profile\"\n  role = aws_iam_role.eks_node.name\n}\n\nresource \"aws_security_group\" \"eks_cluster\" {\n  name        = \"${local.name}-eks-cluster-sg\"\n  description = \"EKS cluster security group\"\n  vpc_id      = aws_vpc.this.id\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name}-eks-cluster-sg\"\n  }\n}\n\nresource \"aws_security_group\" \"eks_nodes\" {\n  name        = \"${local.name}-eks-nodes-sg\"\n  description = \"EKS worker nodes security group\"\n  vpc_id      = aws_vpc.this.id\n\n  ingress {\n    description = \"Node to node\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    self        = true\n  }\n\n  ingress {\n    description     = \"Control plane to nodes\"\n    from_port       = 0\n    to_port         = 0\n    protocol        = \"-1\"\n    security_groups = [aws_security_group.eks_cluster.id]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${local.name}-eks-nodes-sg\"\n  }\n}\n\nresource \"aws_eks_cluster\" \"this\" {\n  name     = \"${local.name}-eks\"\n  role_arn = aws_iam_role.eks_cluster.arn\n  version  = var.cluster_version\n\n  vpc_config {\n    subnet_ids              = concat([for s in aws_subnet.public : s.id], [for s in aws_subnet.private : s.id])\n    security_group_ids      = [aws_security_group.eks_cluster.id]\n    endpoint_public_access  = true\n    endpoint_private_access = false\n  }\n\n  enabled_cluster_log_types = [\"api\", \"audit\", \"authenticator\", \"controllerManager\", \"scheduler\"]\n\n  depends_on = [\n    aws_iam_role_policy_attachment.eks_cluster_AmazonEKSClusterPolicy,\n    aws_iam_role_policy_attachment.eks_cluster_AmazonEKSServicePolicy\n  ]\n\n  tags = {\n    Name = \"${local.name}-eks\"\n  }\n}\n\nresource \"aws_eks_node_group\" \"default\" {\n  cluster_name    = aws_eks_cluster.this.name\n  node_group_name = \"${local.name}-ng\"\n  node_role_arn   = aws_iam_role.eks_node.arn\n  subnet_ids      = [for s in aws_subnet.private : s.id]\n\n  instance_types = var.node_instance_types\n  capacity_type  = \"ON_DEMAND\"\n\n  scaling_config {\n    desired_size = var.node_desired_size\n    min_size     = var.node_min_size\n    max_size     = var.node_max_size\n  }\n\n  update_config {\n    max_unavailable = 1\n  }\n\n  depends_on = [\n    aws_iam_role_policy_attachment.eks_node_AmazonEKSWorkerNodePolicy,\n    aws_iam_role_policy_attachment.eks_node_AmazonEKS_CNI_Policy,\n    aws_iam_role_policy_attachment.eks_node_AmazonEC2ContainerRegistryReadOnly\n  ]\n\n  tags = {\n    Name = \"${local.name}-ng\"\n  }\n}\n\ndata \"aws_eks_cluster_auth\" \"this\" {\n  name = aws_eks_cluster.this.name\n}\n\n# OIDC provider for IRSA (used by AWS Load Balancer Controller)\ndata \"tls_certificate\" \"eks\" {\n  url = aws_eks_cluster.this.identity[0].oidc[0].issuer\n}\n\nresource \"aws_iam_openid_connect_provider\" \"eks\" {\n  url             = aws_eks_cluster.this.identity[0].oidc[0].issuer\n  client_id_list  = [\"sts.amazonaws.com\"]\n  thumbprint_list = [data.tls_certificate.eks.certificates[0].sha1_fingerprint]\n\n  tags = {\n    Name = \"${local.name}-eks-oidc\"\n  }\n}\n\n# Expose a small module-like interface for providers.tf\nmodule \"eks\" {\n  source = \"./modules/eks_outputs\"\n\n  cluster_endpoint                   = aws_eks_cluster.this.endpoint\n  cluster_certificate_authority_data = aws_eks_cluster.this.certificate_authority[0].data\n  cluster_name                       = aws_eks_cluster.this.name\n}\n"
    },
    {
      "name": "alb_controller.tf",
      "content": "# AWS Load Balancer Controller (ALB/NLB) installed via Helm.\n# This enables creating ALBs from Kubernetes Ingress resources.\n\nresource \"kubernetes_namespace_v1\" \"app\" {\n  metadata {\n    name = var.app_namespace\n  }\n\n  depends_on = [aws_eks_node_group.default]\n}\n\ndata \"aws_iam_policy_document\" \"alb_controller_assume\" {\n  statement {\n    actions = [\"sts:AssumeRoleWithWebIdentity\"]\n\n    principals {\n      type        = \"Federated\"\n      identifiers = [aws_iam_openid_connect_provider.eks.arn]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${replace(aws_iam_openid_connect_provider.eks.url, \"https://\", \"\")}:sub\"\n      values   = [\"system:serviceaccount:kube-system:aws-load-balancer-controller\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${replace(aws_iam_openid_connect_provider.eks.url, \"https://\", \"\")}:aud\"\n      values   = [\"sts.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"alb_controller\" {\n  name               = \"${local.name}-alb-controller\"\n  assume_role_policy = data.aws_iam_policy_document.alb_controller_assume.json\n}\n\n# AWS-managed policy for the controller\nresource \"aws_iam_role_policy_attachment\" \"alb_controller\" {\n  role       = aws_iam_role.alb_controller.name\n  policy_arn = \"arn:aws:iam::aws:policy/AWSLoadBalancerControllerIAMPolicy\"\n}\n\nresource \"kubernetes_service_account_v1\" \"alb_controller\" {\n  metadata {\n    name      = \"aws-load-balancer-controller\"\n    namespace = \"kube-system\"\n    annotations = {\n      \"eks.amazonaws.com/role-arn\" = aws_iam_role.alb_controller.arn\n    }\n    labels = {\n      \"app.kubernetes.io/name\" = \"aws-load-balancer-controller\"\n    }\n  }\n\n  depends_on = [aws_eks_node_group.default]\n}\n\nresource \"helm_release\" \"aws_load_balancer_controller\" {\n  name       = \"aws-load-balancer-controller\"\n  repository = \"https://aws.github.io/eks-charts\"\n  chart      = \"aws-load-balancer-controller\"\n  namespace  = \"kube-system\"\n\n  values = [yamlencode({\n    clusterName = aws_eks_cluster.this.name\n    region      = var.aws_region\n    vpcId       = aws_vpc.this.id\n    serviceAccount = {\n      create = false\n      name   = kubernetes_service_account_v1.alb_controller.metadata[0].name\n    }\n  })]\n\n  depends_on = [kubernetes_service_account_v1.alb_controller]\n}\n"
    },
    {
      "name": "k8s_app.tf",
      "content": "resource \"kubernetes_deployment_v1\" \"app\" {\n  metadata {\n    name      = \"wd-prediction\"\n    namespace = kubernetes_namespace_v1.app.metadata[0].name\n    labels = {\n      app = \"wd-prediction\"\n    }\n  }\n\n  spec {\n    replicas = var.app_replicas\n\n    selector {\n      match_labels = {\n        app = \"wd-prediction\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"wd-prediction\"\n        }\n      }\n\n      spec {\n        container {\n          name              = \"wd-prediction\"\n          image             = var.app_image\n          image_pull_policy = \"Always\"\n\n          port {\n            container_port = var.app_container_port\n          }\n\n          resources {\n            requests = {\n              cpu    = \"50m\"\n              memory = \"64Mi\"\n            }\n            limits = {\n              cpu    = \"250m\"\n              memory = \"256Mi\"\n            }\n          }\n\n          liveness_probe {\n            http_get {\n              path = \"/\"\n              port = var.app_container_port\n            }\n            initial_delay_seconds = 10\n            period_seconds        = 10\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/\"\n              port = var.app_container_port\n            }\n            initial_delay_seconds = 5\n            period_seconds        = 5\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [helm_release.aws_load_balancer_controller]\n}\n\nresource \"kubernetes_service_v1\" \"app\" {\n  metadata {\n    name      = \"wd-prediction\"\n    namespace = kubernetes_namespace_v1.app.metadata[0].name\n    labels = {\n      app = \"wd-prediction\"\n    }\n  }\n\n  spec {\n    selector = {\n      app = \"wd-prediction\"\n    }\n\n    port {\n      port        = var.service_port\n      target_port = var.app_container_port\n      protocol    = \"TCP\"\n    }\n\n    type = \"ClusterIP\"\n  }\n\n  depends_on = [kubernetes_deployment_v1.app]\n}\n\n# Internet-facing ALB via Ingress (recommended over Service type LoadBalancer for ALB)\nresource \"kubernetes_ingress_v1\" \"app\" {\n  metadata {\n    name      = \"wd-prediction\"\n    namespace = kubernetes_namespace_v1.app.metadata[0].name\n\n    annotations = {\n      \"kubernetes.io/ingress.class\"            = \"alb\"\n      \"alb.ingress.kubernetes.io/scheme\"       = \"internet-facing\"\n      \"alb.ingress.kubernetes.io/target-type\"  = \"ip\"\n      \"alb.ingress.kubernetes.io/listen-ports\" = \"[{\\\"HTTP\\\":80}]\"\n    }\n  }\n\n  spec {\n    rule {\n      http {\n        path {\n          path      = \"/\"\n          path_type = \"Prefix\"\n\n          backend {\n            service {\n              name = kubernetes_service_v1.app.metadata[0].name\n              port {\n                number = var.service_port\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [helm_release.aws_load_balancer_controller]\n}\n"
    },
    {
      "name": "outputs.tf",
      "content": "output \"vpc_id\" {\n  value = aws_vpc.this.id\n}\n\noutput \"eks_cluster_name\" {\n  value = aws_eks_cluster.this.name\n}\n\noutput \"eks_cluster_endpoint\" {\n  value = aws_eks_cluster.this.endpoint\n}\n\noutput \"ecr_repository_url\" {\n  value       = var.enable_ecr ? aws_ecr_repository.app[0].repository_url : null\n  description = \"ECR repository URL (if created).\"\n}\n\noutput \"app_ingress_hostname\" {\n  description = \"ALB DNS name created by the AWS Load Balancer Controller (once provisioned).\"\n  value       = try(kubernetes_ingress_v1.app.status[0].load_balancer[0].ingress[0].hostname, null)\n}\n"
    },
    {
      "name": "terraform.tfvars",
      "content": "aws_region   = \"us-east-1\"\nproject_name = \"wd-prediction\"\nenvironment  = \"dev\"\n\n# Keep DockerHub image by default; switch to your ECR image URI after pushing.\napp_image = \"yash5090/wd-prediction:latest\"\n"
    },
    {
      "name": "modules/eks_outputs/main.tf",
      "content": "variable \"cluster_endpoint\" {\n  type = string\n}\n\nvariable \"cluster_certificate_authority_data\" {\n  type = string\n}\n\nvariable \"cluster_name\" {\n  type = string\n}\n\noutput \"cluster_endpoint\" {\n  value = var.cluster_endpoint\n}\n\noutput \"cluster_certificate_authority_data\" {\n  value = var.cluster_certificate_authority_data\n}\n\noutput \"cluster_name\" {\n  value = var.cluster_name\n}\n"
    },
    {
      "name": "README.md",
      "content": "# Terraform: EKS + ALB (AWS Load Balancer Controller) + sample app\n\nThis Terraform creates:\n- VPC (public/private subnets across 2 AZs) + IGW + NAT gateways\n- EKS cluster + managed node group\n- (Optional) ECR repository\n- AWS Load Balancer Controller (Helm)\n- Kubernetes namespace + Deployment (replicas=6) + Service + Ingress (internet-facing ALB)\n\n## Usage\n\n```bash\ncd ai_tf\nterraform init\nterraform validate\nterraform plan\nterraform apply\n```\n\nAfter apply, check output `app_ingress_hostname` for the ALB DNS name.\n\n## Notes\n- The repo manifests use `Service type: LoadBalancer` with ALB annotations. On AWS, ALB is typically created via **Ingress** + AWS Load Balancer Controller. This Terraform uses that recommended pattern.\n- For production, push your image to ECR and set `app_image` to the ECR image URI.\n"
    }
  ]
}