data.aws_vpc.default: Reading...
data.aws_ami.al2023: Reading...
data.aws_vpc.default: Read complete after 0s [id=vpc-dc152f7fef7d97ec4]
data.aws_subnets.default: Reading...
data.aws_subnets.default: Read complete after 0s [id=us-east-1]
data.aws_ami.al2023: Read complete after 3s [id=ami-07c1fa5792ef8fe27]

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.kafka_host will be created
  + resource "aws_instance" "kafka_host" {
      + ami                                  = "ami-07c1fa5792ef8fe27"
      + arn                                  = (known after apply)
      + associate_public_ip_address          = true
      + availability_zone                    = (known after apply)
      + disable_api_stop                     = (known after apply)
      + disable_api_termination              = (known after apply)
      + ebs_optimized                        = (known after apply)
      + enable_primary_ipv6                  = (known after apply)
      + force_destroy                        = false
      + get_password_data                    = false
      + host_id                              = (known after apply)
      + host_resource_group_arn              = (known after apply)
      + iam_instance_profile                 = (known after apply)
      + id                                   = (known after apply)
      + instance_initiated_shutdown_behavior = (known after apply)
      + instance_lifecycle                   = (known after apply)
      + instance_state                       = (known after apply)
      + instance_type                        = "t3.small"
      + ipv6_address_count                   = (known after apply)
      + ipv6_addresses                       = (known after apply)
      + key_name                             = (known after apply)
      + monitoring                           = (known after apply)
      + outpost_arn                          = (known after apply)
      + password_data                        = (known after apply)
      + placement_group                      = (known after apply)
      + placement_group_id                   = (known after apply)
      + placement_partition_number           = (known after apply)
      + primary_network_interface_id         = (known after apply)
      + private_dns                          = (known after apply)
      + private_ip                           = (known after apply)
      + public_dns                           = (known after apply)
      + public_ip                            = (known after apply)
      + region                               = "us-east-1"
      + secondary_private_ips                = (known after apply)
      + security_groups                      = (known after apply)
      + source_dest_check                    = true
      + spot_instance_request_id             = (known after apply)
      + subnet_id                            = "subnet-df6a4aba86b0933a1"
      + tags                                 = {
          + "Name" = "test-kafka-host"
        }
      + tags_all                             = {
          + "Managed" = "terraform"
          + "Name"    = "test-kafka-host"
          + "Project" = "test-kafka"
        }
      + tenancy                              = (known after apply)
      + user_data                            = <<-EOT
            #!/bin/bash
            set -euxo pipefail
            
            dnf -y update
            dnf -y install docker
            systemctl enable --now docker
            
            # Install docker compose plugin
            mkdir -p /usr/local/lib/docker/cli-plugins
            curl -L "https://github.com/docker/compose/releases/download/v2.24.6/docker-compose-linux-x86_64" -o /usr/local/lib/docker/cli-plugins/docker-compose
            chmod +x /usr/local/lib/docker/cli-plugins/docker-compose
            
            mkdir -p /opt/test-kafka
            cat > /opt/test-kafka/docker-compose.yml <<'YAML'
            version: "3"
            
            services:
              zookeeper:
                image: confluentinc/cp-zookeeper:7.3.0
                container_name: zookeeper
                environment:
                  ZOOKEEPER_CLIENT_PORT: 2181
                  ZOOKEEPER_TICK_TIME: 2000
                networks:
                  - kafka-network
            
              broker:
                image: confluentinc/cp-kafka:7.3.0
                container_name: broker
                depends_on:
                  - zookeeper
                ports:
                  - "9093:9093"
                environment:
                  KAFKA_BROKER_ID: 1
                  KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
                  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
                  # Advertise the instance public IP for the host listener
                  KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker:9092,PLAINTEXT_INTERNAL://broker:29092,PLAINTEXT_HOST://$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4):9093"
                  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
                  KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
                  KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
                networks:
                  - kafka-network
            
              kafka-ui:
                image: provectuslabs/kafka-ui
                container_name: kafka-ui
                ports:
                  - "8080:8080"
                restart: always
                environment:
                  KAFKA_CLUSTERS_0_NAME: local
                  KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:9092
                  KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
                depends_on:
                  - broker
                  - zookeeper
                networks:
                  - kafka-network
            
              proxy-manager:
                image: 'jc21/nginx-proxy-manager:latest'
                restart: unless-stopped
                ports:
                  - '80:80'
                  - '81:81'
                  - '443:443'
                volumes:
                  - ./data:/data
                  - ./letsencrypt:/etc/letsencrypt
                networks:
                  - kafka-network
            
            networks:
              kafka-network:
                driver: bridge
            YAML
            
            cd /opt/test-kafka
            docker compose up -d
        EOT
      + user_data_base64                     = (known after apply)
      + user_data_replace_on_change          = false
      + vpc_security_group_ids               = (known after apply)

      + capacity_reservation_specification (known after apply)

      + cpu_options (known after apply)

      + ebs_block_device (known after apply)

      + enclave_options (known after apply)

      + ephemeral_block_device (known after apply)

      + instance_market_options (known after apply)

      + maintenance_options (known after apply)

      + metadata_options {
          + http_endpoint               = "enabled"
          + http_protocol_ipv6          = "disabled"
          + http_put_response_hop_limit = (known after apply)
          + http_tokens                 = "optional"
          + instance_metadata_tags      = (known after apply)
        }

      + network_interface (known after apply)

      + primary_network_interface (known after apply)

      + private_dns_name_options (known after apply)

      + root_block_device (known after apply)
    }

  # aws_security_group.kafka_host will be created
  + resource "aws_security_group" "kafka_host" {
      + arn                    = (known after apply)
      + description            = "Security group for single-node Kafka docker host"
      + egress                 = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + from_port        = 0
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "-1"
              + security_groups  = []
              + self             = false
              + to_port          = 0
                # (1 unchanged attribute hidden)
            },
        ]
      + id                     = (known after apply)
      + ingress                = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = "Kafka UI"
              + from_port        = 8080
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "tcp"
              + security_groups  = []
              + self             = false
              + to_port          = 8080
            },
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = "Kafka external listener (as in docker-compose 9093)"
              + from_port        = 9093
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "tcp"
              + security_groups  = []
              + self             = false
              + to_port          = 9093
            },
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = "Nginx Proxy Manager Admin"
              + from_port        = 81
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "tcp"
              + security_groups  = []
              + self             = false
              + to_port          = 81
            },
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = "Nginx Proxy Manager HTTP"
              + from_port        = 80
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "tcp"
              + security_groups  = []
              + self             = false
              + to_port          = 80
            },
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = "Nginx Proxy Manager HTTPS"
              + from_port        = 443
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "tcp"
              + security_groups  = []
              + self             = false
              + to_port          = 443
            },
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = "SSH"
              + from_port        = 22
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "tcp"
              + security_groups  = []
              + self             = false
              + to_port          = 22
            },
        ]
      + name                   = (known after apply)
      + name_prefix            = "test-kafka-sg-"
      + owner_id               = (known after apply)
      + region                 = "us-east-1"
      + revoke_rules_on_delete = false
      + tags_all               = {
          + "Managed" = "terraform"
          + "Project" = "test-kafka"
        }
      + vpc_id                 = "vpc-dc152f7fef7d97ec4"
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + instance_id     = (known after apply)
  + kafka_bootstrap = (known after apply)
  + kafka_ui_url    = (known after apply)
  + public_ip       = (known after apply)
aws_security_group.kafka_host: Creating...
aws_security_group.kafka_host: Creation complete after 0s [id=sg-416f15257a97923f7]
aws_instance.kafka_host: Creating...
aws_instance.kafka_host: Still creating... [00m10s elapsed]
aws_instance.kafka_host: Creation complete after 15s [id=i-1d748fe0ee2d54671]

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

Outputs:

instance_id = "i-1d748fe0ee2d54671"
kafka_bootstrap = "54.214.52.17:9093"
kafka_ui_url = "http://54.214.52.17:8080"
public_ip = "54.214.52.17"
